{
  "results": [
    {
      "metadata": {
        "title": "Opening the black box of deep learning",
        "authors": [
          "Dian Lei",
          "Xiaoxiao Chen",
          "Jianfei Zhao"
        ],
        "abstract": "The great success of deep learning shows that its technology contains profound truth, and understanding its internal mechanism not only has important implications for the development of its technology and effective application in various fields, but also provides meaningful insights into the understanding of human brain mechanism. At present, most of the theoretical research on deep learning is based on mathematics. This dissertation proposes that the neural network of deep learning is a physical system, examines deep learning from three different perspectives: microscopic, macroscopic, and physical world views, answers multiple theoretical puzzles in deep learning by using physics principles. For example, from the perspective of quantum mechanics and statistical physics, this dissertation presents the calculation methods for convolution calculation, pooling, normalization, and Restricted Boltzmann Machine, as well as the selection of cost functions, explains why deep learning must be deep, what characteristics are learned in deep learning, why Convolutional Neural Networks do not have to be trained layer by layer, and the limitations of deep learning, etc., and proposes the theoretical direction and basis for the further development of deep learning now and in the future. The brilliance of physics flashes in deep learning, we try to establish the deep learning technology based on the scientific theory of physics.",
        "published": "2018-05-22T02:12:33Z",
        "arxiv_id": "1805.08355v1",
        "categories": [
          "cs.LG",
          "stat.ML"
        ],
        "pdf_url": "http://arxiv.org/pdf/1805.08355v1",
        "pdf_file": "data/pdfs/1805.08355v1.pdf",
        "pdf_filename": "1805.08355v1.pdf"
      },
      "processing_info": {
        "processed_at": "2025-09-26T06:32:44.262732",
        "is_large_pdf": true,
        "sections_found": 6,
        "tables_found": 0,
        "images_found": 10
      },
      "sections_text": {
        "Abstract": "The great success of deep learning shows that its technology contains profound truth, and understanding its internal mechanism not only has important implications for the development of its technology and effective application in various \ufb01elds, but also provides meaningful insights into the understanding of human brain mechanism. At present, most of the theoretical research on deep learning is based on mathematics. This dissertation proposes that the neural network of deep learning is a physical system, examines deep learning from three different perspectives: microscopic, macroscopic, and physical world views, answers multiple theoretical puzzles in deep learning by using physics principles. For example, from the perspective of quantum mechanics and statistical physics, this dissertation presents the calculation methods for convolution calculation, pooling, normalization, and Restricted Boltzmann Machine, as well as the selection of cost functions, explains why deep learning must be deep, what characteristics are learned in deep learning, why Convolutional Neural Networks do not have to be trained layer by layer, and the limitations of deep learning, etc., and proposes the theoretical direction and basis for the further development of deep learning now and in the future. The brilliance of physics \ufb02ashes in deep learning, we try to establish the deep learning technology based on the scienti\ufb01c theory of physics. School of Mechatronics Engineering and Automation, Shanghai University, Shanghai 200072, China",
        "Introduction": "Deep learning is the main representative of the breakthrough in arti\ufb01cial intelligence today, it has reached nearly human level in image classi\ufb01cation , speech recognition , natural language processing and so on. The method of deep learning is developing rapidly, which almost subverts all branches of computer vision \ufb01eld. However, the fundamental problem of deep learning at present is the lack of theoretical research on its internal principles, and there is no accepted theoretical explanation, namely, the so-called black box problem: Why use such a deep model in deep learning? Why is deep learning successful? What\u2019s the key inside? The lack of theoretical basis has led to the academic community being unable to explain the fundamental reason for the success of deep learning. The theoretical basis is not clear, and we simply do not know from what angle to look at it. The black box model is purely based on data without considering the physical laws of the model, it lacks the ability to adhere to mechanistic understandings of the underlying physical processes. Hence, even if the model achieves high accuracy but it lacks of theoretical support, it cannot be used as a basis for subsequent scienti\ufb01c developments . We must not rely solely on intuition designed algorithmic structures and several empirically tried examples to prove the general validity of an algorithm. This research method has the potential to learn false modes from non-generic representations of data, the explanatory nature of the model is very low, and the resulting research results are dif\ufb01cult to pass on in the long term. As people\u2019s new ideas have been replaced by more and more complex model architectures, which are almost invisible under the weight of layers of models, calls for attention to the explanatory nature of machine learning are also getting higher. Therefore, we need to thoroughly understand the entire system operation of deep learning. We need to explain what the most fundamental problems are in the \ufb01eld of deep learning and whether arXiv:1805.08355v1 [cs.LG] May these fundamental issues are mature enough to be accurately described in mathematical and physical languages. The great success of deep learning shows that its technology contains profound truth, but the most widely understood way is mathematical analysis, so far, very little attention has been paid to its scienti\ufb01c issues. However, purely mathematical explanations may lead to misdirection. For example, the neural network is mathematically trying to approximate any function. In mathematics, it has been proved that a single-layer neural network can approximate any function if it is long enough, this viewpoint has greatly hindered the development of neural networks, this is why most people in the past neglected multi-layer networks for a long time and without studying in depth. Only a small number of people such as Yann LeCun, Geoffrey Hinton, and Yoshua Bengio still insist on research in multi-layer neural networks . Therefore, from the great successes achieved in deep learning, it is far from enough to explain deep learning in mathematics, and the technology of deep learning needs to be based on scienti\ufb01c theory. As deep learning has made breakthroughs in many aspects such as images, phonetics, and text, methods based on deep learning are increasingly being applied in various other \ufb01elds, for example, recently effective in solving many-body quantum physics problems has also been proved. Therefore, the theory of deep learning methods must re\ufb02ect some objective laws of the real world. obviously the most basic and universal theory is quantum physics and statistical physics. What is science? Physics is the most perfect science that has been developed so far. Just as most engineering disciplines are based on physics, the engineering foundation for deep learning now and in the future will be physics. We need to describe the deep learning concept model in the language of physics, so that we can scienti\ufb01cally guide the development and design of deep learning. From this we say that the key to the current and future success of arti\ufb01cial intelligence depends not only on the mathematical calculation, but also on the laws of physics. The theory of deep learning requires physics. The data in the information world is divided into two different types of data: one is symbolic data, which is designated by our humans; the other is physical data, which objectively re\ufb02ects the data of the real world, any actual data set we care about (whether it is a natural image or a voice signal, etc.) is physical data. Reference shows that the reason why neural networks can perform classi\ufb01cation tasks well is that these physical data x follow some simple physical laws and models can be generated with relatively few free parameters: for example, they may exhibit symmetry, locality, or a simple form as an exponent of a low-order polynomial; and symbolic data, such as \u201dvariable y=cat\u201d is speci\ufb01ed by humans, in this case the symmetry or polynomial is meaningless, and they are not related to physics. However, the probability distribution of non-physical data y can be obtained by Bayes\u2019 theorem using the physical characteristics of x. In the reference , a Physics-guided Neural Networks (PGNN) is proposed, which combines the scienti\ufb01c knowledge of physics-based models with the deep learning. The PGNN leverages the output of physics-based model simulations along with observational features to generate predictions using a neural network architecture. Reference shows that deep learning is intimately related to one of the most important and successful techniques in theoretical physics, the renormalization group (RG). Reference using DBM and RBM to represent quantum many-body states illustrates why the depth of neural networks in the quantum world is so important, revealing the close relationship between deep neural networks and quantum many-body problems. Reference establishes a mapping of tensor network (TN) based on quantum mechanics and neural network in deep learning. Reference mentions that people have found more and more connections between basic physics and arti\ufb01cial intelligence, such as Restricted Boltzmann Machine and spin systems, deep neural networks and renormalization groups; the effectiveness of machine learning allows people to think about the deeper connection between physics and machine learning, and perhaps it can help us gain insights into intelligence and the nature of the universe. The research of the above reference mainly takes the neural network as a computational tool, or as a method to solve the quantum many-body problem. This dissertation studies the arti\ufb01cial deep neural network as a real physical system, considers that the neural network model is a real physical model. The goal of deep learning training is to obtain the neural network system model which accords with the physical laws by the interaction or response between the neural network system and the input physical information. Because the deep neural network is a physical system, its trained model and its evolution in training must meet the laws of physics. This dissertation analyzes the principles of physics embodied in deep learning from three different perspectives: microscopic, macroscopic, and world view, and describes deep learning with physics language, aiming to provide theoretical guidance and basis for further study and future development direction, and tries to establish the technology of deep learning based on the scienti\ufb01c theory of physics. A microscopic view of deep learning The biggest rule of the universe is that the world is made up of microscopic particles such as atoms, electrons and photons, which obey quantum mechanics. Quantum mechanics is the science of studying the motion law of the microscopic particles in the material world, so the neural network model of deep learning as a physical system requires that the model must be governed by quantum mechanics. The following explains deep learning from the basic principles of quantum mechanics. The human brain neural network is composed of atoms, the number of billions of neurons is the same, and the computational methods of the human brain should be similar. The neural network, as an interactive quantum many-body system, determines the deep learning system to be described by the wave function. The coordinate operator, momentum operator (corresponding translation operator), angular momentum operator (corresponding rotation operator), energy operator, and spin operator in the neural network are the most basic and important physical quantity or mechanical quantity operator. 2. The physical meaning of neurons Information has both physical and symbolic meanings, so neurons also have two meanings: 1) physical, 2) symbolic mappings. Now discuss the meaning of its physics. In this dissertation, the \ufb01rst hypothesis is that the neuron is the scattering source of the quasi-particle wave and the superposition of receiving the quasi-particle wave. First look at a classic physics experiment\u2014Young\u2019s double slit experiment. Figure 1: Young\u2019s double slit experiment. As shown in Figure 1, the electrons are diffracted through the aperture a, and then diffracted and interfered by b and c. The bright diffraction fringes and patches at F indicate that there is a greater probability of electrons appearing there, and the dark part is there is little or no chance of the appearance of electrons. This dissertation holds that neurons act as electron diffraction interference. When we look at a neuron as a physical unit, the neuron is a scattering potential well that causes scattering of quasiparticles (perhaps this scattering originates from the quantum effect in the microtubules of the neurons, perhaps the electron-phonon coherence coupling in the biological system, perhaps some other kind of elementary excitation). Therefore, the output after the input of the neuron calculation is like the scattering output of the electrons through the circular hole, and the law is determined by the quantum physics theorem. The physical meaning of neurons indicates that, as white light can be scattered as red, orange, yellow, green, cyan, blue, violet, it is a natural classi\ufb01er, calculator. In the Young\u2019s double slit experiment, whatever the input is light, or electrons, polarized electrons, neutrons, and any particle including atomic and subatomic levels will cause diffraction and interference effects. In the same way, the physical meaning of neurons indicates that neurons are inherently capable of discriminating characterizations and are inherently capable of excellent generalization. The structure of Young\u2019s double slit experiment provides the foundation for a universal quantum neural network. The physical model of neurons assumed in this dissertation is: The input of neurons is a multichannel wave function, for example, the input image is a wave function of multiple pixel points, and the photon (quasi-particle) wave function is superimposed to become the new scattering source output. The state value of the neuron is the number of quasiparticles (probability) of excitation after superposition, if you visualize multiple or large numbers of neurons, you see images of the same nature as the interference diffraction experiment\u0142streaks and patches. Figure 2: Neuron physical model diagram. The fundamental of this model is that the neuron is a physical model, which re\ufb02ects the probability of its state value, and the related theories and deep learning techniques discussed later in this dissertation can con\ufb01rm the correctness of its hypothesis. 2.",
        "Methodology": "Although deep learning has achieved great success in many applications, there are still many limitations: for example, it needs a lot of data, the vulnerability of the algorithm etc. Why is the neural network easily disturbed by the input of small disturbances? From the physical model of deep neural network in this paper, we can see that on the one hand this is a physical problem, behind which we have not found new physical phenomena or new physical modes; On the other hand, labeling does not match the actual physical characteristics, such as cross-entropy, the two distributions cannot be approximated, or they are approached in a group of training data, it does not mean that the test data can match nonexistent labels, especially the deception problem. Therefore, the key to the vulnerability of the model is the limitation of human understanding. According to the physical world view of solving problems, providing anti-classi\ufb01cation is a direction worthy of study. 4. Causality and Correlation At present, deep learning pays attention to relevance instead of causality, and uses joint probability distribution to replace traditional theorems and laws. The theoretical foundation of deep learning methods lies in the representation and transformation of statistical probability distributions. It is consistent with the physical model of the deep neural network in this paper. That is, the state of the microscopic particle is completely described by the wave function \u03c8 . After the wave function is determined, all the characteristics of the system can be obtained, the average value of any mechanical quantity and its measurement possible value and the corresponding probability distribution are also completely determined. However, in practice, a mathematical model of causality derived from statistical data will be comprehensively used. For example, these models can be used to establish a causal relationship between smoking and cancer, or to analyze the risks of a construction project, and so on. Can these mathematical models be extended to the microscopic world dominated by quantum mechanics? Can it be incorporated into the deep learning quantum physics model? Since quantum mechanics itself has many strange features, for example, if two or more quantum systems are entangled with each other, it is dif\ufb01cult to deduce whether the statistical correlation between them is causal. The concept of causal information actually exceeds statistical relevance. For example, we can compare these two sentences: \u201dThe number of cars is related to the amount of air pollution\u201d and \u201dThe car causes air pollution.\u201d The \ufb01rst sentence is a statistical statement, and the latter sentence is a causal statement. Causality differs from relevance because it tells us how the system will change under intervention. In statistics, causal models can be used to extract causality from the empirical data of complex systems. However, there is only one component in a system of quantum physics\u0142the wave function \u03c8 , so mathematical models that use causality derived from statistical data cannot be applied, including Bayesian inference. John-Mark Allen of Oxford University in the United Kingdom proposed a generalized quantum causal model based on Reichenbach\u2019s principle of common reason , successfully combining causal intervention and Bayesian inference into a model.",
        "Discussion": "There are various interpretations of convolutional neural networks, but according to the above quantum physics model, CNN can be perfectly interpreted. The interpretation is fundamental and deterministic, it will inspire the architectural design of deep convolutional networks. (1) When the inner product of the convolution is represented by the norm and the angle: \u2225 \u03c9 \u2225 \u2225 x \u2225 cos( \u03b8 ( \u03c9,x ) ) , the trained inner product of the convolutional neural network can be decoupled to \ufb01nd the relationship between norm and angle in the feature map . Figure 6: CNN learned features are naturally decoupled.Figure courtesy: If the convolution of spherical coordinates is used, the relationship between the norm and angle in the feature map is more obvious: Figure 7: 2D feature visualization on MNIST dataset with natural training.Figure courtesy: The \ufb01gure shows that the angles represent semantic/label differences, and the feature norm represents within-class differences. This result can be explained in our model. It can be seen from (Equation 14) that the general action potential U (r) is only related to r , i.e. U (r) = U ( r ) . So the convolution kernel is related to the norm and has nothing to do with the angle, the CNN feature image is related to the angle. The above experiments verify the correctness of the physical model of the convolutional neural network. (2) The number of convolution kernels is related to the color of the image. The input requirement in the scattering equation(Equation 8) is a monochromatic wave, that is, the convolution kernel(Equation 16) is related to the wavelength of the input wave, and different wavelength should have different convolution kernel K mn . Applied to the color image, convolution neural network should have different convolution kernel for different colors image. For example, they can be composed of three kinds of convolution kernels: red, green, and blue. Of course, they can also be composed of multiple kernels such as red, orange, yellow, green, blue, and purple. (3) The number of convolution kernels is also related to the polarization direction of the incident wave. It can be seen from(Equation 16, 17) that even if the image is monochromatic, the convolution kernels of different z are different. So even if the input is a black-andwhite image, multiple feature mapping layers (multiple convolution kernels) are needed, just as white light contains light of all colors, and random monochromatic light also contains polarized light of all polarization directions. If the input is an electron, the number of convolution cores is related to the spin direction. In a comparable size, the number of feature map layers is much larger than the convolutional window size. (4) The reason of partial receptive \ufb01elds is not because the pixels are usually highly correlated in neighboring regions. The convolution kernel sharing of feature layer is not due to translation invariance, they are due to the limited scope of the action potential U ( r \u2032 ) of the neuron, that is, the coordinate x \u2032 , y \u2032 in the convolution kernel (Equation 16) is outside the range of action potential. Therefore, the summation of the x \u2032 , y \u2032 in (Equation 17) does not require full space, i.e.the CNN should not be fully connected but partial connection. For the same feature mapping layer, all the neuron potentials U ( r \u2032 ) are the same, so the convolution kernels of all the sliding window convolutions of the same feature mapping layer are the same or share one, which explains from the scienti\ufb01c theory that the fundamental reason for the success of CNN is the important characteristic of CNN: partial receptive \ufb01elds + weight sharing. In the actual application of CNN, the convolution kernel size (that is, the convolution window size) is often 3x3, 5x5, 9x9 and so on, scattering is mainly concentrated in the incident direction, so the window size is too large to be meaningful. However, if the 1* size of the convolution kernel is used, the interference effect will also be poor. In addition, considering the symmetry of K , convolution kernel size is generally used odd. (5) The purpose of pooling operations is not only to reduce the size of the output eigenvectors. (Equation 15) is the intensity of a neuron, and the image formed by all the neurons of a convolutional feature layer is an interference diffraction pattern. Because the coherence of the wave is strong in some places and weak in some places and not even in some places, and those \u201dbright\u201d neurons will be the scattering sources of the subsequent convolutions, so each convolutional layer must be pooling. That is, in the convolution window area, the \u201dbright\u201d neurons must be selected according to the intensity values of the neurons in each convolution layer feature layer, which is also the physical reason why the biological neuron can either output or not output even if it has a signal input. Obviously, pooling is an important computing component. In the early years, many of the studies based on convolution architecture used average pooling, now they are replaced by Max Pooling. From our model we can see that in practical application, because the window size is not large, it is reasonable to select one of the most bright neurons, that is, to adopt the max pooling method. It is also seen from here that the pooling is of decisive importance to the initial convolution layer, but as the number of layers increases, the interferogram sharpens and bright points become less, so the effect of pooling is weakened, which is the same as the result of the reference . Pooling can also be explained by the renormalization group in Section3.4. (6) The convolution kernel of different layer is not same, because each of the \u201dbrightest\u201d neuron positions represents the coherence of the corresponding convolution window image, which is related to the symmetry of the image and the structure of neural network. After pooling, the spacing as a new scattering source is different, so subsequent convolution kernels will also be different. That is, except for the same feature mapping layer, convolution kernels of each feature map layer of the convolution layer are different. (7) Coherence is the most important condition for multilayer CNN. In our model, the purpose of convolution is to create the entanglement of each pixel in the image under the action of neurons, thus forming the interference diffraction fringes or patches according to the spatial translation structure. According to the quantum mechanics, this is a coherence phenomenon caused by the superposition principle of waves. The total intensity after interference superposition is not necessarily equal to the sum of the intensity of the sub-beams, may be more strong or may be equal to under the interference. The important condition of coherence is the coherent wave. There are two ways to produce coherent wave, the \ufb01rst one is to ensure that the monochrome of the wave and the phase of each wave of the \ufb01xed, so need multi-layer convolution; the second is the interference of oneself and oneself, so need multi-layer convolution, generally need at least or more. Figure 8: Interfering with oneself causes CNN to require multiple layers of convolutional layers. If we understand from the biological neural network, the wavelength of the natural color of the physicist\u2019s world changes monotonously from red to purple, but the system of human perception of color is closed-loop, such as the combination of red light and purple light is understood as the monochromatic magenta color. However, does not physically exist with a single physical wavelength of light corresponding to the color, but the human perception system fusion understands as a single color. Therefore, the convolution neural network must be fused or transformed after the input scattering (decomposition) must be multilayered. (8) Convolution is not the extraction of human knowledge such as image edges or colors, the convolution is the physical law and does not require human prior knowledge. From (Equation 2) to know the image gradient is obtained after the translation operation, so for the \ufb01rst feature layer of the image we can see that it re\ufb02ects the edge of the image. But as the subsequent continuous pooling and convolution, feature layer image will become more and more dif\ufb01cult to understand and abstract compared to the original layer. However, in our model, the convolution image is a diffraction stripe or patch image after destructive interference or constructive interference, which is the superposition of the same or coherent wave. That is, the images are decomposed and classi\ufb01ed by the same coherent attribute. The wave of the same phase has a destructive interference and the opposite phase has a constructive interference, and the interference diffraction patterns will effectively deconstruct the entire information of the incident image. And this coherent property is the symmetry of the image, according to quantum mechanics, the physical quantity described by the symmetry is the wave vector. It can also be said that CNN is to measure the wave vector of the image, because it is the XY plane convolution of the image, i.e. the measurement of the momentum p x , p y in the x, y direction. According to quantum mechanics, the z directional angular momentum operator is de\ufb01ned as: \u02c6 l z = x \u02c6 p y \u2212 y \u02c6 p x , so it also detects angular momentum or rotational symmetry around the z direction. That\u2019s to say, a trained CNN measures the translational symmetry of the x, y direction of the image or the rotational symmetry of the z direction through the translational operation and interaction of the image, is classi\ufb01ed as the interference diffraction fringes or patch image that we see. The feature map layer is effectively classi\ufb01ed according to the symmetry, and then the whole connection layer is mapped, which can effectively recognize the image. In summary, the above research shows that LeCun\u2019s most famous contribution, the convolutional neural network, is entirely based on prior knowledge and that the idea of not requiring human structured knowledge is completely correct. CNN is based on the scienti\ufb01c theory, so it is the best method in image recognition. CNN is a physical model, so it is very successful in the processing of physical data such as images, videos, sounds, condensed matter physics, etc., but the performance is worse than other models when processing the strong subjectivity of symbolic modeling. For example, no matter how much data is input, it is impossible to train a model that can read product descriptions and generate an appropriate code base . 2.2. Signi\ufb01cance of classi\ufb01cation layers in CNN The convolutional layer is followed by a classi\ufb01cation layer whose meaning maps the mechanical characteristics learned in the convolution layer to human symbols (marks). The signi\ufb01cance of the classi\ufb01cation layer is expressed in: \u2022 On the signi\ufb01cance of the classi\ufb01cation layer, the \ufb01rst is mathematics. In order to effectively apply the ability of neural network that can approximate arbitrary functions mathematically, the classi\ufb01cation layer must be fully connected. \u2022 The classifying layer in neural network is also physical. In our model, the neuron is a probability wave. The output of the last layer\u2019s activation function must be guaranteed to meet the normalized requirement, generally, the softmax function with a clear physical meaning is used. The activation function is shown in Section 2.5. \u2022 The classi\ufb01cation must have generalization and must obey the laws of statistical physics and must cooperate with entropy. The content of entropy is shown in Section 3.2. 2.2. Development prospects of CNN (1) According to the neuron scattering theory, strictly speaking, the convolutional neural network should be extended to the complex number \ufb01eld so that it can use the wave function with phase information. Thus, the input image is the intensity, and it should be squared root when used as a wave function, which is equivalent to the fact part: \u03c8 ( x, y ) = I ( x, y ) However, in the actual calculation of CNN, the calculation on the complex number \ufb01eld may not be signi\ufb01cant. In Equation 10, when we compute S , we need to square \u03c8 , and | \u03c8 | is proportional to the intensity of the image. The calculation of S in the real \ufb01eld will appear negative, but subsequent Relu recti\ufb01cation guarantees that the output is positive. It still conforms to the model where the value of the neuron is the intensity value, the signi\ufb01cance of max pooling is to \ufb01nd the brightest neurons. In short, if the convolution is calculated in the complex number \ufb01eld, the square root is computed \ufb01rst, and then the square is computed, which is equivalent to repeating computation. And if the convolution is calculated in the real \ufb01eld, input do not square root, output also do not square, the Relu recti\ufb01cation function guarantees that no negative number will appear. By reducing the repetition calculation and saving the calculation amount, the calculation error can be reduced. There is no big difference between the calculated effect on the real \ufb01eld and the strict complex number \ufb01eld. (2) Choosing the appropriate convolution kernel is crucial for obtaining the most signi\ufb01cant and important information contained in the input signal. This allows the model to make better inferences about the content of the signal. The goal of this transformation is to change the data in a way that is more easily separated by the classi\ufb01er. According to Equation 16, a better model is designed using the convolutional features, such as better coordinates: cylinder coordinates or spherical coordinates of CNN . (3) The training of CNN based on quantum scattering theory obtains a large amount of input information, but the \ufb01nal classi\ufb01cation only occupies a small part of the information. These are correct and objective re\ufb02ections of the input information, it is easy to drown in the training process. This is undoubtedly a waste of valuable prior probabilities that can be used to migrate large-scale network knowledge into small-scale networks. Therefore, making full use of this information or data migration learning in other \ufb01elds is also a topic worthy of study. (4) Multilayer CNN can not only perceive the translational symmetry and rotational symmetry of input, but also transform and perceive the fusion of various combinations of colors. In addition, it should also can transform and perceive the polarization direction of light. That is, CNN can perceive very rich three-dimensional scenes and behavioral information from static two-dimensional images. The geometry school will laugh : how can an image calculate three-dimensional, which is mathematically impossible. It doesn\u2019t make any sense mathematically, but it makes sense physically! Human beings can perceive three-dimensions from two-dimensional images, and deep convolution neural networks can extract 2.5-dimensional information from two-dimensional images. This is the quantum effect: White light can be decomposed into red, orange, yellow, green, cyan, blue and violet through neuronal interaction or coupling or entanglement, and random monochromatic light can be decomposed into various polarized light. According to the physical model above, a lot of new information can be found from the polarization information, such as stereo information, like the principle of stereoscopic \ufb01lm. This is an important prediction of the deep convolution neural network in this dissertation. (5) The CNN discussed above is to classify the spatial symmetry of the image by spatially translating and interacting with neurons. After the above measurement, the state after the collapse is measured as the new environment of Hamiltonian to state a new round of evolution. If the incident wave changes, such as the time dependent dispersion of the packet, the visual retention, or the Hamiltonian contains time, then it will be a Schr \u00a8 odinger equation that contained time. At this time Equation is time-containing, the green function is divided into the delayed Green function and the advanced Green function, which can be computed to predict the short future by or to recall a brief past. For time translation operations, according to quantum mechanics, the conserved quantity of time translation invariance is energy. Through the convolution of time translation, it is also possible to classify the energy properties of the input information. And the scattering of neurons contains time, so it will be an important research direction and may explain the important functions of visual retention, visual prediction and memory. (6) The convolution neural network based on quantum scattering theory is expected to compute the internal properties of the biological neurons and to gain more understanding of the functions of the biological neurons and the human brain. (7) CNN is supervised training, according to the above theory, it can be used in unsupervised pre-training and training. (8) In our neural network model, all the neuron cells of CNN form an image of a grid cell and a location cell, which is very similar to the image of the biological grid cell and position cell. It will be an important research direction to combine CNN with LSTM to achieve navigation like the brain grid cells. 2.",
        "25. It is used in deep learning applications to measure the degree to which the model distribution": "approximates the unknown distribution. Therefore, entropy plays an important role in deep learning, it has become the objective function of the selection and adjustment of the parameters of the deep learning model: \u2022 How the neural network adjusts parameters, in which direction the parameters are adjusted, the basis is the entropy of the random variables. \u2022 How to determine the conditions for the physical balance and stability of the neural network, the basis is the entropy of the system. For example, the entropy of an isolated equilibrium system must be maximum. \u2022 Entropy allows us to precisely de\ufb01ne \u201d correlation \u201d and extract features from massive data. 3.2. Application of entropy in cost function According to statistical physics, a macroscopic state with a steady state and balance is a state where the number of microscopic states is maximum (i.e. the entropy is maximum). This is the physical basis for the selection of the cost function. The deep learning neural network discussed above are divided into two parts. The former is the neural networks that conforms to the laws of physics, such as each convolution layers of CNN, not only the characteristics of the trained convolution layer have physical signi\ufb01cance, each of the conditions in the training also has physical signi\ufb01cance. Because it is calculated according to the physical equations, except that this microscopic state does not correspond to the \ufb01nal trained macroscopic state, or the number of microscopic states that the \ufb01nal trained macroscopic state has is very small (entropy is small). The latter part is the classi\ufb01cation of neural networks, such as a convolution layer that then maps human symbols (labels) to their physical characteristics. This is a distribution of two completely different concepts, so the cross-entropy of the model\u2019s output (physical) and the training target (labeled) should be used as a cost function to approach the real physical model. The magic of the wonderful combination of classi\ufb01cation problems and cross-entropy is that even if the cross-entropy on the test set is over-\ufb01tted, the classi\ufb01cation error will not be over\ufb01t . For the regression problem, it is the same kind of problem, so the mean square error is often used as the objective function or the cost function, which is equivalent to the general entropy maximum. KL divergence is closely related to cross entropy, but it does not include the entropy of the model, it re\ufb02ects the difference between the two distributions. Unlike the use of cross entropy, the KL divergence is used when there is no more physical distribution. These analyses show the powerful power of statistical physics in understanding deep learning. 3. Understanding deep learning from the concept of master equations The evolution equation of the Markov process probability distribution is the master equation, which is one of the most important equations in statistical physics because it is almost universally applicable. The Markov process is a process in which most of the memory effects can be omitted during the evolution process. When the system evolution of a random variable occurs, the transfer process will occur between different values of the random variables, by transferring the probability of the system changes in a given state until the system reaches a \ufb01nal equilibrium state. In deep learning, one of the simplest examples of the Markov process is the Markov chain. The Markov chain is de\ufb01ned by a random state X t and a transition distribution T ( X t + | X t ) . The transition distribution T is a probability distribution showing the probability of a random transfer to X t + in the case of a given state X t . Running a Markov chain is the process of constantly updating the state X t based on the value X t + of the transition distribution T . Among them, the probability distribution of the system state at time t + is only related to the state at time t , and has nothing to do with the state before t . 3. Understanding deep learning from the concept of renormalization group David Schwab and Pankaj Mehta found that the Deep Belief Network (DBN) invented by Hinton resembled the renormalization in physics in a speci\ufb01c case, which means that the details of the physical system are obtained in a coarse-graining manner to calculate its overall state. When Schwab and Mehta applied DBN to a magnetic model at the critical point (when the system is fractal and selfsimilar at any scale), they found that the network automatically uses a reorganization-like process to discover the state of the model. This discovery is shocking, as the biophysicist Ilya Nemenman commented, it shows that extracting related features in the context of statistical physics and extracting related features in the context of deep learning are not just similar, but they are completely the same.\u201d . The renormalization group is a mathematical tool for examining changes in the physical system at different length scales. The details of the physical system are physically obtained in a coarsegrained manner to calculate its overall state. The important feature of this method is that it is independent of the system type. Each key step in the renormalization group method is based on the main characteristics of the system, rather than putting the system into the framework we are familiar with, and then adjusting the parameters . The standard renormalization process in statistical physics is equivalent to the feature extraction process of supervised learning in depth learning. The information is transmitted layer by layer and eventually converges to the theoretical boundary (\ufb01xed points). The purpose of the renormalization group method is to obtain new features, and to ensure that the Hamiltonian function forms are unchanged under the new scale of renormalization. Figure 9: The pooling operation in convolution neural network. For example, the pooling operation (pooling layer) in CNN is based on the main characteristics of the system and uses the max pooling method to integrate the feature points in the small neighborhood according to self-similarity to obtain new features. As shown in Figure 9, the pooling layer uses the max pooling (where the size of the \ufb01ltering core is 2* and the step size is 2) to fuse a feature with an input size of 4* and retains only the largest feature point in the area, then the characteristic size after the pooling operation is 2*2, and the pooling layer plays a role of dimensionality reduction. It has been proved that there is a one-to-one mapping relationship between RBM-based deep neural networks and variational renormalization groups. The paper illustrates the mapping relationship by analyzing the DNN and numerical two-dimensional Ising model of a one-dimensional Ising model, and it \ufb01nds that these DNNs self-realize a coarse graining process, i.e. Kadanoff block renormalization. The results show that deep learning may adopt a generalized renormalization group class scheme to learn relevant features from the data. The paper proved that deep learning is closely related to the renormalization group, one of the most important and successful technologies in theoretical physics. A physical world view of deep learning 4. The interpretability of deep learning The interpretability of deep learning models can be divided into the following categories: (1) Feature attribution VS Internal logic: The former maps the behavior of the model back to the original set of input features (or arti\ufb01cially creates optional input features). In the complex decision-making process of the model, the larger the in\ufb02uence of the characteristics will be assigned to the larger weight, the structure of human knowledge plays a decisive role in this model; The latter argues that: In the process of obtaining the \ufb01nal answer of the model, it is the abstract role of the physical meaning of the model itself and the internal working logic, rather than human structural knowledge. Obviously, the interpretation of deep learning in this dissertation belongs to the latter. This paper analyzes deep learning from the internal logic according to the principle of physics, while most of the papers use the former method to explain deep learning. (2) Simulation acquires knowledge VS Introspection acquires knowledge: Knowledge based on simulation means that we obtain an understanding of our own model by generating some form of simulation data, capture how the model represents these data points for understanding; Introspection acquires knowledge comes from the \ufb01xed orientation of the model and use them to gain knowledge without having to simulate the former. Obviously, the interpretation of deep learning in this dissertation belongs to the latter, while most papers belong to the former, the focus of their interpretation is to visualize the characteristics of deep learning. However, this dissertation holds that the deep neural network data has high dimensional data characteristics, and human beings cannot understand the visual characteristics of high-dimensional data. According to quantum statistical physics, a system with s classical degrees of freedom, the dynamic state of the system is determined by the wave function: \u03c8 \u03c3 \u03c3 , \u00b7\u00b7\u00b7 ( q , q , \u00b7 \u00b7 \u00b7 q s , t ) Where q is the classical coordinate and \u03c3 is the non-classical degree of freedom. People think that deep learning is incomprehensible. It is precisely because it uses the \u03c8 to characterize the macroscopic nature, which cannot be understood through visualization, nor can it be understood through mathematics. Deep learning is the interpretation of observed data using the dynamic characteristics of microscopic layers that are not observed by humans or that are not intuitively understood. 4. Locality One of the deepest principles of physics is locality, that is, things directly affect their surroundings. Locality is a relative concept, usually referring to the scope and degree of in\ufb02uence of a physical quantity. Locality has two effects: (1) Short-range effect: The interaction is only a nearby function, ignoring the effect of the remote, that is, the effect of the remote is averaged or canceled. For example, it has been explained before that during the operation of the Markov chain, the system state at the current moment is only related to the state at the previous moment, has nothing to do with the state before the previous moment, that is, the short-range effect. (2) Local coupling: The local roles of each regions are coupled and then coupled as localization. Scale changes, renormalization, long procedures, strong correlation, and coarse-graining. For example, pooling in CNN has already been described in the previous section. By using max pooling, similar features of neighboring regions are merged (that is, processes that are locally coupled), thereby achieving the effect of dimensionality reduction. 4. Symmetry Symmetry and conservation law are the basic laws of nature. Symmetry can not only reduce the number of parameters, but also reduce the computational complexity. See the convolutional neural network under the symmetry (translation invariance) we introduced in Section 2.2. Whenever Hamiltonian obeys a certain symmetry, that is, invariable under some transformation, the number of independent parameters required to describe it decreases further. The most important mechanical quantities of atoms are momentum and angular momentum, so the corresponding translation and rotation transformations are the most important and basic operations. For example, many probability distributions are constant in the case of translation and rotation. If the system has translational symmetry, then the state after the translation operation differs from the original state by a maximum of one phase factor, that is, the difference between the input state and the output state mainly appears as a phase shift. The input wave function can be labeled by the wave vector, and the physical meaning of the wave vector is momentum, which re\ufb02ects the spatial symmetry of the system. The state with translational symmetry is the eigenstate of the momentum operator, and the momentum represented by the wave vector is the corresponding eigenvalue. Therefore, the process of learning the eigenvalue and the eigenvalue is the process of obtaining the wave vector. 4. Conjugacy and Duality Conjugacy is the amount of pairing. For example, in physics: pressure and volume, temperature and entropy, intensity and extension are conjugate quantities, in mathematics: real and imaginary numbers, transposed conjugates of matrix, and so on. Duality is the correspondence between the different physical theories that lead to the same physical results, such as, there is a reaction force with acting force, there are holes with electrons. These are the important organizations of physics, and they are related to each other and to each other in physical relations. This worldview is also used in deep learning. Here are two examples: (1) Stochastic gradient descent algorithm using momentum Although random gradient descent is a very popular optimization method in the training process, the learning process is sometimes very slow, and even cannot found the best point. The basic physical idea to solve this problem is to introduce conjugates and use duality to solve this problem. The cost function has a gradient g , there is \ufb02ow (or velocity or momentum), so the introduction of the momentum variable v . The gradient of the cost function is seen as a force that pushes the cost function to accelerate downhill and the momentum increases; if there is only this kind of force, the optimization process can never stop, so we need to add another force or gradient (called the viscous resistance) to make the cost function converge to a minimum; but the minimum may not be the smallest, so wo need to increase a momentum, let him out of the local minimum, so as to achieve the overall optimal. Update the algorithm as follows: v \u2190 \u03b1\u03bd \u2212 \u03b5g \u03b8 \u2190 \u03b8 + \u03bd As shown in Figure 10, the contour depicts a quadratic loss function (Hessian matrix with illconditioned conditions). The red path across the pro\ufb01le represents the path followed by the momentum learning rule, which minimizes the function. We draw an arrow at each step of the path, indicating the step the gradient will take at that point. We can see that the quadratic objective function of a pathological condition looks like a long and narrow valley or a canyon with a steep edge. The momentum passes right through the gorge, while ordinary gradient steps waste time moving around the narrow axis of the canyon . Figure 10: Stochastic gradient descent algorithm using momentum. Figure courtesy: (2) Annealing and tempering Temperature and entropy are conjugate quantities, when the temperature equals 0, the entropy equals 0(minimum); the temperature in\ufb01nity is the most chaotic, the model becomes uniform distribution. Using the temperature in the Boltzmann distribution, tempering: The Markov chain temporarily samples from a high temperature distribution and returns to sampling at unit temperature. Annealing: The Markov chain temporarily samples from a low temperature distribution and returns to sampling at unit temperature to \ufb01nd the best among the different peaks. However, it is necessary to pay attention to the existence of a critical temperature. Most of the models used for prediction in deep learning generally use the softmax activation function to assign probability distributions to tags. The reference mentions that, in the image classi\ufb01cation problem, we divide the pictures into cats, dogs, and tigers three kinds. In a training, the probability of the three types is [0.0010, 0.0001, 0.9989], and the one-hot code of [0, 0, 1] is obtained as the classi\ufb01cation result (hard-target). However, the intrinsic link between cats and tigers can easily be overwhelmed during training. This is undoubtedly a waste of valuable a priori probabilities that can be used to transfer large-scale network knowledge into small-scale networks. In order to make full use of the correlation between such class categories, we need to change the probability distribution in some way to make it more smooth. In the reference, Hinton further modi\ufb01ed the softmax function: q i = exp( z i /T ) j exp( z j /T ) When the temperature T = in the equation, it degenerates into the traditional softmax function; when T is in\ufb01nite, the result approaches /C , that is, the probabilities on all classes approach to equal; when T > , we can obtain the soft target label. By increasing the temperature T, the mapping curve of the softmax layer will be smoother, so the probability mapping of the instances will be more concentrate and the goal will be \u201dsoft\u201d. Therefore, in order to make full use of the correlation between such class categories, the method of changing the probability distribution is to increase T . 4. Hierarchy One of the most striking features of the physical world is its hierarchy. Spatially, it is an object hierarchy: elementary particles form atoms, then form molecules, cells, organisms, planets, the solar system, galaxies, and so on. Complex structures are usually layered and created through a series of simple steps. The observables of world are inherently hierarchical and cannot be commutative. The main reason for the success of deep learning is the hierarchical nature of neural networks (deep neural networks). In order to extract uncomplicated features, a multi-layer neural network is required to stack simple networks and then effectively implement the generation process through layering and combination. Multilayer networks provide layer-by-layer abstract channels from low to high levels. 4.",
        "Conclusion": "At present, the research on the internal theory of deep learning is very scarce, and the successful application of deep learning and the limitations of its existing technology further illustrate the importance of studying its internal technical mechanism from a scienti\ufb01c perspective. Only knowing why to do it can transform existing methods or means from a deeper level. This is the scienti\ufb01c way of thinking. Based on the principles of physics, this paper interprets the deep learning techniques from three different perspectives: microscopic, macroscopic, and physical world perspectives. Inspired by the biological neural network, a new neuron physics model was proposed. Based on this, it explains the success of deep learning well, and fully reveals the internal mechanism of deep learning by scienti\ufb01c methods. A good theory can not only explain existing experiments, but also predict new phenomena and technologies. Therefore, this dissertation also proposes the direction of further research in deep learning. Some of the main conclusions of this paper are as follows: (1) The deep neural network is a physical system, and its architecture and algorithm should conform to the principles of physics. The technical foundation for deep learning is physics, especially quantum physics and quantum statistical physics. (2) In this dissertation, the physical meaning of neurons in deep neural network is proposed: its output value is the distribution of quasi-particles. (3) Two physical models of deep neural networks are proposed in this paper, one is pure ensemble deep neural network and the other is hybrid ensemble deep neural network. The former learning model corresponds to a quantum measurement of a microscopic state, such as CNN; the latter corresponds to a microscopically statistically averaged macroscopic state, such as RBM. (4) The physical model of neurons in CNN is a quantum superposition of a quasi-particle incident wave (Figure 1) and is excited by the output. This excitation may be the elastic scattering caused by the incident wave (exit only includes the incident wave), or inelastic scattering (exit also includes internal new excited states), or various possible actions such as chemical reactions (exit only includes new quasiparticles). It obeys quantum mechanics. According to the superposition principle of quantum mechanics, the excitation output of a neuron is related not only to the intensity of incident quasi-particles in other neurons, but also to their coherence, and to their polarization direction or spin. (5) The input of the deep learning network is treated as a wave function, and the image is also a wave. The state of the neuron is also expressed by a wave function. If the measured neuron is the number or probability of excited quasi-particles, the value of a layer of neurons in the neural network is a probability distribution. The deep learning operator should be performed on the complex number \ufb01eld, but because the activation function is ReLU, the computational difference in the real number domain may not be large. (6) Under such a physical model, the convolutional neural network algorithm is exactly the same as the quantum calculation method for measuring the number of quasi-particles excited by neurons, so that it can perfectly explain the technology of each important components of a convolutional neural network algorithm (convolution, recti\ufb01cation, activation, pooling, etc.) The purpose of convolution is to measure the number or probability of quasiparticles excited by each neuron. The convolution kernel is related to the Hamiltonian interaction potential of neurons. All neurons present an interference diffraction pattern stripes and patches. That is, the deep convolutional neural network can measure the input wave vector or momentum, and its computational model can decompose white light into monochromatic light and decompose random-direction vibration into single-direction polarization. Therefore, the physical model of this paper can explain deep learning technology and success. This physical model shows that the deep convolutional neural network has natural learning ability and cognitive ability, and the model learns the ability to characterize the input micromechanical quantities, so it is reusable and can be applied across \ufb01elds. (7) The basis for parameter adjustment and optimization in the deep learning classi\ufb01cation training process is the entropy in statistical physics, which is the number of microscopic states corresponding to the corresponding macroscopic state. Different types of training models should choose different cost functions according to the meaning of entropy, for example, the convolutional neural network model should use cross entropy as the objective function (cost function). (8) A large number of operators, techniques, and methods in deep learning are related to the principles of physics such as energy, entropy, renormalization techniques, and translation operations; they are also related to physical world views such as symmetry, conjugacy, locality, hierarchy, etc. The research in this paper shows that there are physics glimmers everywhere in deep learning. Deep learning techniques can be based on scienti\ufb01c theories. From the principles of physics, this dissertation presents the calculation methods for convolution calculation, pooling, normalization, and RBM, as well as the selection of cost functions, explains why deep learning must be deep, what characteristics are learned in deep learning, why convolutional neural networks do not have to be trained layer by layer, and the limitations of deep learning, etc. The physical model proposed in this paper can not only explain the successful technology of existing deep learning, but also predict many researchable directions and topics, such as positional neurons (these are in the research stage, and still need to be experimentally veri\ufb01ed). There is a striking homogeneity in the appearance and structure of the human cerebral cortex. In other words, the cerebral cortex uses the same calculations to accomplish all its functions. All the intelligence that humans exhibit (vision, auditory, physical movement...) are based on a uni\ufb01ed set of algorithms. The deep learning technology is also based on a uni\ufb01ed algorithm and is supported by physical theories. It will have a broad prospect for development."
      },
      "sections_summary": {
        "Abstract": "[Skipped - Large PDF]",
        "Introduction": "[Skipped - Large PDF]",
        "Methodology": "[Skipped - Large PDF]",
        "Discussion": "[Skipped - Large PDF]",
        "25. It is used in deep learning applications to measure the degree to which the model distribution": "[Skipped - Large PDF]",
        "Conclusion": "[Skipped - Large PDF]"
      },
      "tables": [],
      "images": [
        "processed/images/1805.08355v1_page3_img0.png",
        "processed/images/1805.08355v1_page4_img0.png",
        "processed/images/1805.08355v1_page4_img1.png",
        "processed/images/1805.08355v1_page5_img0.png",
        "processed/images/1805.08355v1_page5_img1.png",
        "processed/images/1805.08355v1_page9_img0.png",
        "processed/images/1805.08355v1_page9_img1.png",
        "processed/images/1805.08355v1_page11_img0.png",
        "processed/images/1805.08355v1_page19_img0.png",
        "processed/images/1805.08355v1_page22_img0.png"
      ],
      "status": "completed",
      "json_file": "processed/compiled/1805.08355v1_compiled.json"
    },
    {
      "metadata": {
        "title": "Concept-Oriented Deep Learning",
        "authors": [
          "Daniel T Chang"
        ],
        "abstract": "Concepts are the foundation of human deep learning, understanding, and knowledge integration and transfer. We propose concept-oriented deep learning (CODL) which extends (machine) deep learning with concept representations and conceptual understanding capability. CODL addresses some of the major limitations of deep learning: interpretability, transferability, contextual adaptation, and requirement for lots of labeled training data. We discuss the major aspects of CODL including concept graph, concept representations, concept exemplars, and concept representation learning systems supporting incremental and continual learning.",
        "published": "2018-06-05T15:50:30Z",
        "arxiv_id": "1806.01756v1",
        "categories": [
          "cs.AI"
        ],
        "pdf_url": "http://arxiv.org/pdf/1806.01756v1",
        "pdf_file": "data/pdfs/1806.01756v1.pdf",
        "pdf_filename": "1806.01756v1.pdf"
      },
      "processing_info": {
        "processed_at": "2025-09-26T06:33:27.988112",
        "is_large_pdf": false,
        "sections_found": 16,
        "tables_found": 31,
        "images_found": 0
      },
      "sections_text": {
        "Daniel T. Chang ( \u5f20\u9075)": "IBM (Retired) dtchang43@gmail.com Abstract: Concepts are the foundation of human deep learning, understanding, and knowledge integration and transfer. We propose concept-oriented deep learning (CODL) which extends (machine) deep learning with concept representations and conceptual understanding capability. CODL addresses some of the major limitations of deep learning: interpretability, transferability, contextual adaptation, and requirement for lots of labeled training data. We discuss the major aspects of CODL including concept graph, concept representations, concept exemplars, and concept representation learning systems supporting incremental and continual learning.",
        "1.1 Human Deep Learning": "In human learning, deep learning is an approach that involves the critical analysis of new topics and facts, linking them to already known concepts or forming new concepts, and leads to long term retention of concepts so that they can be used for problem solving in new situations. Deep learning promotes understanding and application for life. This is in contrast to surface learning which is the rote acceptance of facts and memorization as isolated and unlinked facts. It leads to superficial retention of facts and does not promote understanding or long term retention of knowledge. The major characteristics of deep learning are: aiming for understanding, focusing on concepts, and relating new and previous knowledge. According to the Bloom\u2019s taxonomy , there are four types of knowledge: factual, conceptual, procedural and metacognitive, and six levels of cognitive processes: remember, understand, apply, analyze, evaluate and create. Factual knowledge, such as topics and facts, is locked in time, place, and/or situation. Factual knowledge does not promote understanding. Concepts (e.g., dog) are general ideas derived or inferred from facts. They are abstract and broad, represented by different instances that share common attributes, universal in application, and timeless. Conceptual knowledge is required for understanding and provides the framework for relating new and previous knowledge. The ultimate goal of learning is knowledge transfer . Factual knowledge doesn't transfer, but conceptual understanding does. Conceptual understanding is built by abstracting \u201cup\u201d from factual knowledge or examples to understand concepts and the relationships among concepts. Whenever we try to apply our insights from one situation to another we are always abstracting to the conceptual level before our knowledge helps us unlock the new situation. When tasks remain similar to one another, this is known as low-road transfer. To transfer knowledge to dissimilar tasks requires high-road transfer which involves highly generalized concepts. A deep foundation of facts or surface learning is key for deep learning and knowledge transfer. Synergistic thinking, which involves the interaction between the factual and conceptual levels of thinking, is essential for deep learning.",
        "1.2 Machine Deep Learning": "In machine learning, deep learning has more than one definition. A useful, though narrow, definition is: deep learning is neural networks with a large number of layers and parameters in one of four fundamental network architectures: unsupervised pretrained networks, convolutional neural networks, recurrent neural networks, and recursive neural networks Automatic feature extraction is one of the major facets, and great advantages, that deep learning has. Deep learning is more broadly defined as feature representation learning in [5, 6]. It uses machine learning to discover not only the mapping from feature representations to output but also the feature representations themselves. To learn features that best represent data, the goal is to separate the factors of variation that explain the data. Deep learning does this by learning successive layers of increasingly meaningful feature representations. The \u2018deep\u2019 in deep learning stands for this idea of deep layers of feature representations. Deep learning is therefore layered feature representation learning. These layered feature representations are generally learned via neural networks. Deep learning has achieved near-human accuracy levels in various types of classification and prediction tasks including images, text, speech, and video data. However, the current technology of deep learning is largely at the level of surface learning, not deep learning, in human learning, focusing on rote memorization of factual knowledge in the form of feature representations. A deep-learning model [6, 7] is just a chain of simple, continuous geometric transformations mapping one data manifold into another. Anything that needs reasoning is out of reach for deep-learning models. There are other major limitations as well. Firstly, the knowledge learned using deep-learning models cannot be transferred because, as discussed earlier, factual knowledge (feature representations) doesn't transfer, but conceptual understanding does. Secondly, deeplearning models are difficult to understand or interpret . This is to be expected since, as discussed earlier, factual knowledge (feature representations) does not promote understanding. Conceptual knowledge is required for understanding. As a result of the first two limitations, deep-learning models cannot leverage contextual knowledge. They are developed in isolation, within the narrow confine of the specific training data used, and do not support contextual adaptation . Lastly, but not the least, deep-learning models require lots of labeled data for training, which can be hard to come by. This is not surprising since deep learning relies on rote memorization of feature representations to perform classification and prediction tasks. It has no conceptual understanding of the data.",
        "1.3 Goal and Outline": "From the above discussions it should be apparent that conceptual knowledge learning and conceptual understanding are needed to elevate machine deep learning toward the level of human deep learning. We propose Concept-Oriented Deep Learning (CODL) as a general approach to achieve that goal. CODL is an extension of (machine) deep learning. It extends feature representation learning with concept representation learning and it adds the conceptual understanding capability to deep learning. The major aspects of CODL include: concept graph, concept representations, concept exemplars, and concept representation learning systems. These are discussed in the following sections. The last section provides the summary and conclusion.",
        "2 Concept Graph": "The Big Book of Concepts states that \u201cConcepts are the glue that holds our mental world together.\u201d Without concepts, there would be no mental world. As discussed earlier, concepts (e.g., dog) are general ideas derived or inferred from facts. They are abstract and broad, represented by different instances that share common attributes. A concept may contain a set of attributes that describe the concept and a set of sub-concepts that are components of the concept. Concepts may also be related by relationships. The most common relationships include isA relationships. Concepts and categories go together . That is, whatever the concept is, there is a category of things that would be described by it. For material things (objects), \u2018category\u2019 is usually referred to as \u2018class\u2019; for abstract things (entities), \u2018category\u2019 is commonly referred to as \u2018type\u2019. Thus, concepts denote categories, classes or types, and instances denote things, objects or entities. Microsoft Concept Graph [10, 11] aims to give machines \"common-sense computing capabilities\" and an awareness of a human's mental world, which is underpinned by concepts. Microsoft Concept Graph is built upon Probase, which uses the world as its model. The concept graph in Probase is automatically learned from billions of web pages and years' worth of search logs. The core taxonomy of Microsoft Concept Graph contains over 5. million concepts. Microsoft Concept Graph also has a large data space (each concept contains a set of instances or sub-concepts), a large attribute space (each concept is described by a set of attributes), and a large relationship space (e.g., \"isA\", \"locatedIn\"). The Microsoft Concept Tagging Model [ \u2013 16], a part of Microsoft Concept Graph, maps text entities into concepts with some probabilities, which may depend on the context texts of the entities. Given an input text entity, it returns a ranked list of concepts. Each concept on the list has a probability denoting the possibility of the text entity belonging to this concept. Besides, some common measures for conceptualization (e.g., Typicality) are provided simultaneously. CODL uses Microsoft Concept Graph as the common / background conceptual knowledge base and the framework for conceptual understanding, due to its probabilistic nature and extensive scope. Microsoft Concept Graph plays an important role in CODL. Its usage in CODL is discussed in the following sections. However, CODL is not limited to using Microsoft Concept Graph as the common / background conceptual knowledge base. Other comparable system can be used as such.",
        "3 Concept Representations": "In deep learning, feature representations are generally learned as a blob of ungrouped features. However, an increasing number of visual applications nourish from inferring knowledge from imagery which requires scene understanding. Semantic segmentation is a task that paves the way towards scene understanding. Deep semantic segmentation uses deep learning for semantic segmentation. Deep semantic segmentation makes dense predictions inferring labels for every pixel. It can be carried out at three different levels: Class segmentation: each pixel is labeled with the class of its enclosing object or region Instance segmentation: separate labels for different instances of the same class Part segmentation: decomposition of already segmented classes into their component sub-classes CODL extends and generalizes deep semantic segmentation. In CODL, feature representations are always learned semantically segmented in a concept-oriented manner. Concept orientation means that each feature representation is associated with a concept, an instance or an attribute. These concepts, instances and attributes form a concept graph. In addition, the concept graph are generally linked to Microsoft Concept Graph, thus leveraging and integrating with the common conceptual knowledge and conceptual understanding capability provided by Microsoft Concept Graph. A concept representation consists of a concept, its instances and attributes, and all the feature representations associated with the concept and its instances and attributes. If a concept has sub-concepts, its concept representation also consists of the concept representations of its sub-concepts. Concept representations, therefore, are the same as concept-oriented feature representations, but provide a different view. The latter is data driven and provides a bottom-up view starting from feature representations; the former is concept driven and provides a top-down view starting from concepts. Due to the focus on concepts instead of low-level feature representations, concept representations provide the proper view to work with in CODL.",
        "3.1 Supervised Concept Representation Learning": "Concept representations can be learned using supervised learning. Similar to deep semantic segmentation , discussed above, it can be carried out at different levels: Concept level: each feature representation is labeled with the concept that owns the feature Instance level: separate labels for different instances of the same concept Attribute level: separate labels for different attributes of the same concept Component level: decomposition of already learned concept representations into their sub-concept representations The concept, instance and attribute names used for labeling should be taken from Microsoft Concept Graph, if available. This provides direct link to Microsoft Concept Graph to leverage its common conceptual knowledge and conceptual understanding capability.",
        "4 Concept Exemplars": "As is the case for deep semantic segmentation, it can be difficult to gather and create labeled concept representation datasets to use for training in supervised learning. Due to the semantically-segmented nature of concepts, a good alternative is to use concept exemplars. A concept exemplar set is a set of one or more typical instances of a concept, possibly augmented with instances generated from the typical instances using identity-preserving transformations. As an example, for image objects the identitypreserving transformations typically include: scaling, translation, rotation, contrast and color. Each concept is associated with at most one concept exemplar set. With concept exemplars one can use supervised concept representation learning, as discussed earlier, or unsupervised concept representation learning, as discussed below. Concept exemplars can facilitate incremental and continual learning, to be discussed later.",
        "4.1 Unsupervised Concept Representation Learning": "Exemplar-CNN is an approach for training a convolutional network using only unlabeled data. It trains the network to discriminate between a set of surrogate classes. Each surrogate class is formed by applying a set of transformations to a randomly sampled \u2019seed\u2019 image patch. The resulting feature representations are not task specific. They are generic and provide robustness to the transformations that have been applied during training. The applied transformations thus define the invariance properties that are to be learned by the network. Unsupervised concept representation learning uses the same approach as Exemplar-CNN. In CODL, concept exemplars play the role of surrogate classes, and identity-preserving transformations that of applied transformations, in Exemplar-CNN. Whereas surrogate classes are based on randomly sampled \u2019seed\u2019 image patches, concept exemplars are based on semantically distinct, typical instances of concepts. Therefore, we expect unsupervised concept representation learning based on concept exemplars to result in generic, transferable concept representations.",
        "5 Concept Representation Learning Systems": "Concept representation learning systems provide the platforms and tools for use in CODL. They support supervised concept representation learning as well as unsupervised concept representation learning based on concept exemplars. They also provide access to the common / background conceptual knowledge base, such as Microsoft Concept Graph. The following are major aspects of concept representation learning systems which are important for the success of CODL and its application.",
        "5.1 Incremental and Continual Learning": "In real-world scenarios, concepts and their associated data are almost always collected in an incremental manner. As such, incremental and continual learning is a critical aspect of CODL. A good concept representation learning system must accommodate new concepts and their associated data that it is exposed to and gradually expands its capacity to predict increasing number of new concepts. Doing incremental learning using deep neural network faces inherent technical challenges. Neural networks embed feature extraction and classification within the same model. This gives rise to the so-called \u201ccatastrophic forgetting / interference\" problem which refers to the destruction / modification of existing feature representations learned from earlier data, when the model is exclusively trained with data of new concepts. Therefore, the challenge is to be able to incrementally and continually learn over time by accommodating new concepts and their data while retaining previously learned concept representations. There are various approaches for incremental and continual learning that mitigate, to different extents, catastrophic interference. The regularization approaches alleviate catastrophic interference by imposing constraints on the update of the neural weights. The dynamic architecture approaches change architectural properties in response to new concepts and their data, either by dynamically accommodating novel neural resources or by re-training with an increased number of neurons or network layers. A good approach to use in CODL is that of iCaRL (incremental classifier and representation learning), which is a dynamic architecture approach. The approach allows learning in a concept-incremental way: only the training data for a small number of concepts has to be present at the same time and new concepts can be added progressively. Concept-incremental learning has the following properties: it is trainable from a data stream in which examples of different concepts appear at intermittent times, at any time it provides a competitive multi-concept classifier for all the concepts learned so far, and it does not require storing all training data or retraining already-learned concepts whenever new data becomes available. The main components that enable simultaneous learning of concept representations and concept classifiers in the concept-incremental manner are: concept representation learning using knowledge distillation and prototype rehearsal, concept exemplar selection / learning based on herding, and concept classification by the nearest mean of concept exemplars. These are discussed below. Prior to that we note that the deep learning network is used only for concept representation learning and concept exemplar selection, not for classifying new data, which is done using concept classifiers based on concept exemplars. The concept representation learning scheme, using knowledge distillation, addresses the \u201ccatastrophic forgetting / interference\u201d problem of incremental and continual learning. The use of concept exemplars, for concept classifiers, avoids the other problem: storing of all training data.",
        "Concept Representation Learning": "Whenever data for new concepts arrive, the concept representations and concept exemplar sets are updated. Firstly, the network outputs for the existing concepts are stored. Secondly, an augmented training set is constructed, consisting of the (newly available) training examples for the new concepts together with the concepts exemplar sets for the existing concepts. Finally, the deep learning network is trained / updated by minimizing a loss function to output the correct concept indicators for new concepts (classification loss), and for old concepts, to reproduce the scores stored in the first step (distillation loss). The classification loss enables improvements of the concept representations that allow classifying the new concepts well; the distillation loss ensures that the discriminative information learned for existing concepts is not lost while training for the new concepts.",
        "Concept Exemplars Selection / Learning": "Concept exemplars selection is required for each concept only once, when it is first learned and its training data is available. For each concept, concept exemplars are selected and stored iteratively until the target number is met. In each step of the iteration, one more example of the training set is added to the concept exemplar set, namely the one that causes the average feature vector over all concept exemplars to best approximate the average feature vector over all training examples. Thus, the concept exemplar set is a prioritized list, with concept exemplars earlier in the list being more important. The concept exemplar set may be augmented using identity-preserving transformations, as discussed earlier. Concept Classification Based on Concept Exemplars For concept classification, a nearest-mean-of-concept-exemplars classification strategy is used. To predict a concept label for a new sample, it first computes a prototype vector for each concept by computing the average feature vector of all concept exemplars for the concept. It then computes the feature vector of the sample that should be classified and assigns the concept label with the most similar prototype. The concept prototypes automatically change whenever the concept representations change, making the classifier robust against changes of the concept representations (as new concepts are learned)",
        "5.2 Concept Taxonomy and Basic-Level Concepts": "Concept taxonomy is one particular kind of concept organization: the hierarchical structure of concepts with each branch being a sequence of progressively larger concepts in which each concept includes all the previous ones. Different levels of concepts reflect different levels of abstraction, which associate with different attributes. These taxonomic concepts are important for thought and communication. In a concept taxonomy, the concepts that are higher in the hierarchy are superordinate to the lower-level concepts; the lower-level concepts are subordinate to the higher-level ones. The only relationship allowed between concepts in the hierarchy is the set inclusion relationship: the set of instances of a superordinate concept (e.g., dog) includes the set of instances of its subordinate concept (e.g., bull dog). The set inclusion relationship is called the \u2018\u2018isA\u2019\u2019 relationship, which is asymmetric and transitive. The transitivity of concept relationship in the hierarchy leads to a similar transitivity of attribute ascription, called attribute inheritance. Every attribute of a concept is also an attribute of the concept\u2019s subordinates. By being able to locate a concept in its proper place in the concept taxonomy, one can learn a considerable amount about the concept, e.g., its superordinates and inherited attributes. In CODL, this is achieved by accessing Microsoft Concept Graph, as discussed near the beginning. Clearly, this is an important ability, since it allows one to immediately access knowledge (concepts) about new objects or entities without the need to directly learn.",
        "Basic-Level Concepts": "The objects and entities that we encounter every day do not each fit into a single concept, but can be classified with a large number of different concepts. It is important to know the preferred concept by which people think about any one object or entity. Any object or entity can be thought of as being in a set of hierarchically organized concepts, i.e., a concept taxonomy, ranging from extremely general (e.g., animal) to extremely specific (e.g., bull dog). Classification at the most general level maximizes accuracy of classification. Most specific concepts, on the other hand, allow for greater accuracy in prediction. Of all the possible concepts in a concept taxonomy to which a concept belongs, a middle level of specificity, the basic level , is the most natural, preferred level at which to conceptually carve up the world. The basic level (e.g., dog) can be seen as a compromise between the accuracy of classification at a most general level and the predictive power of a most specific level. Superordinate concepts (e.g., animal) are distinctive but not informative. Subordinate concepts (e.g., bull dog) are informative but not distinctive. It is only basic-level concepts (e.g., dog) that are both informative and distinctive. Basic-level concept is important because it provides rich information with little cognitive efforts. When a person obtains the basic-level concept of an unfamiliar object or entity, she will associate the object or entity with the known attributes of the basic-level concept. Therefore, to be effective, in CODL one should focus on learning and using concept representations for basic-level concepts . Superordinate concepts are automatically \u201clearned\u201d by accessing Microsoft Concept Graph, as discussed earlier. When needed, this can be supplemented by learning and using concept representations for selective subordinate concepts.",
        "6 Summary and Conclusion": "Concepts are the foundation of human deep learning, understanding, and knowledge integration and transfer. The current technology of machine deep learning is largely at the level of surface learning in human learning, focusing on rote memorization of factual knowledge in the form of feature representations. To elevate machine deep learning toward the level of human deep learning, we proposed concept-oriented deep learning (CODL) which extends (machine) deep learning with concept representations and conceptual understanding capability. CODL leverages Microsoft Concept Graph, or something comparable, as the common / background conceptual knowledge base and the framework for conceptual understanding. In particular, concept names and concept taxonomies (isA relationships) originate from Microsoft Concept Graph. In CODL, feature representations are always learned semantically segmented in a concept-oriented manner. Concept representations are the same as concept-oriented feature representations, but from a top-down, concept-driven perspective which is the focus of CODL. It can be difficult to gather and create labeled concept representation datasets to use for training. Due to the semantically-segmented nature of concepts, a good alternative is to use concept exemplars. Concept representation learning systems provide the platforms and tools for use in CODL. They support supervised concept representation learning as well as unsupervised concept representation learning based on concept exemplars. Since, in real-world scenarios, concepts and their associated data are almost always collected in an incremental manner, a good concept representation learning system must support incremental and continual learning (using concept exemplars). Also, to be effective, in CODL one should focus on learning and using concept representations for basic-level concepts. By focusing on learning and using concept representations and concept exemplars, CODL is able to address some of the major limitations of deep learning: interpretability, transferability, contextual adaptation, and requirement for lots of labeled training data."
      },
      "sections_summary": {
        "Daniel T. Chang ( \u5f20\u9075)": "Concept-Oriented Deep Learning (CODL) is a framework that extends machine deep learning by incorporating concept representations and conceptual understanding capabilities to address limitations such as interpretability, transferability, contextual adaptation, and high labeled training data requirements.",
        "1.1 Human Deep Learning": "Deep learning in human learning involves critical analysis and linking new topics to known concepts, promoting understanding and long-term retention. It contrasts with surface learning, focusing on concepts and relationships rather than isolated facts. Key characteristics include aiming for understanding, focusing on concepts, and relating new and previous knowledge. Deep learning uses Bloom's taxonomy levels of cognitive processes, including remember, understand, apply, analyze, evaluate, and create, to build conceptual understanding that transfers knowledge across situations.",
        "1.2 Machine Deep Learning": "Deep learning in machine learning refers to neural networks with multiple layers and parameters, using automatic feature extraction and layered feature representation learning. It achieves near-human accuracy in image, text, speech, and video classification tasks but lacks reasoning ability, transferable knowledge, interpretable results, contextual understanding, and the ability to adapt to new data.",
        "1.3 Goal and Outline": "Concept-Oriented Deep Learning (CODL) is a general approach that extends machine deep learning by adding conceptual understanding capabilities. It combines feature representation learning with concept representation learning, focusing on achieving human-like deep learning through concept graphs, representations, exemplars, and learning systems.",
        "2 Concept Graph": "Concepts are abstract and broad ideas derived from facts that represent different instances sharing common attributes. They form categories, classes or types that include instances of things, objects or entities. The concept graph is a framework for giving machines \"common-sense computing capabilities\" by mapping text entities into concepts with probabilities, and provides a large taxonomy, attribute space, and relationship space to denote these concepts.",
        "3 Concept Representations": "Deep semantic segmentation uses deep learning for dense pixel-wise predictions inferring labels. It can be done at three levels: class, instance, and part segmentation. CODL extends this by using concept-oriented feature representations linked to Microsoft Concept Graph, where concepts are associated with instances, attributes, and feature representations forming a graph.",
        "3.1 Supervised Concept Representation Learning": "Concept representations can be learned using supervised learning at different levels: concept, instance, attribute, and component. The labels used for these levels should come from the Microsoft Concept Graph for leverage of its common conceptual knowledge.",
        "4 Concept Exemplars": "Concept exemplars are sets of typical instances of a concept, possibly transformed, used for training in supervised or unsupervised concept representation learning. Each concept is associated with at most one concept exemplar set, which enables incremental and continual learning.",
        "4.1 Unsupervised Concept Representation Learning": "Exemplar-CNN trains a convolutional network to discriminate between surrogate classes formed by applying transformations to seed image patches. This approach provides robustness and learns invariance properties through the applied transformations. Unsupervised concept representation learning uses a similar approach with concept exemplars, resulting in generic and transferable concept representations.",
        "5 Concept Representation Learning Systems": "Concept representation learning systems support supervised and unsupervised learning, provide access to a conceptual knowledge base, and offer tools essential for the success of Cognitive Decision Learning (CODL).",
        "5.1 Incremental and Continual Learning": "Incremental and continual learning is critical in CODL as new concepts and associated data are often collected incrementally. Deep neural networks face challenges with catastrophic forgetting, which can destroy existing feature representations learned from earlier data.\n\nTo mitigate this, various approaches like regularization and dynamic architecture methods are used. iCaRL is a dynamic approach that allows learning in a concept-incremental way by accommodating new concepts and retaining previously learned representations.\n\nKey components of iCaRL include: concept representation learning using knowledge distillation, prototype rehearsal, and concept exemplar selection. These enable simultaneous learning of concept representations and classifiers in a concept-incremental manner without storing all training data or retraining already-learned concepts.",
        "Concept Representation Learning": "When new data arrives, it updates concept representations and sets by:\n\n1. Storing current network outputs\n2. Creating an augmented training set with new concept examples and updated exemplar sets\n3. Training the network to minimize loss functions:\n   - Classification loss: improves concept representations for new concepts\n   - Distillation loss: preserves discriminative information for existing concepts",
        "Concept Exemplars Selection / Learning": "Concepts are initially learned by iteratively selecting concept exemplars until a target number is met. One example from the training set is added to the list at each step, which best approximates the average feature vector over all training examples. The resulting list of concept exemplars serves as a prioritized list for classification.",
        "5.2 Concept Taxonomy and Basic-Level Concepts": "Concept taxonomy is a hierarchical structure of concepts where higher-level concepts are superordinate and include subordinate ones, with attributes inheriting across relationships. The set inclusion relationship between concepts allows for attribute inheritance, enabling learning about concepts through their proper placement in the hierarchy.",
        "Basic-Level Concepts": "People use a hierarchical system of concepts to classify objects and entities, with the most general concepts (e.g., animal) being accurate but not informative, middle-level concepts (e.g., dog) providing a balance between accuracy and informativeness, and more specific concepts (e.g., bulldog) being highly predictive but not distinctive. The basic level concept is preferred as it offers rich information with minimal cognitive effort.",
        "6 Summary and Conclusion": "Concept-oriented deep learning (CODL) aims to improve machine learning by incorporating concept representations and understanding. CODL uses a common conceptual knowledge base, such as Microsoft Concept Graph, and focuses on semantically-segmented feature representations. It provides tools for supervised and unsupervised concept representation learning, supporting incremental and continual learning using concept exemplars. By leveraging basic-level concepts, CODL addresses limitations of deep learning, including interpretability, transferability, contextual adaptation, and large amounts of labeled training data."
      },
      "tables": [
        {
          "page": 1,
          "table_index": 0,
          "content": [
            [
              "Daniel T. Chang (\u5f20\u9075)"
            ],
            [
              ""
            ]
          ]
        },
        {
          "page": 1,
          "table_index": 1,
          "content": [
            [
              "Abstract: Concepts are the foundation of human deep learning, understanding, and knowledge integration and transfer. We"
            ],
            [
              "propose concept-oriented deep learning (CODL) which extends (machine) deep learning with concept representations and"
            ],
            [
              "conceptual understanding capability. CODL addresses some of the major limitations of deep learning: interpretability,"
            ],
            [
              "transferability, contextual adaptation, and requirement for lots of labeled training data. We discuss the major aspects of"
            ],
            [
              "CODL including concept graph, concept representations, concept exemplars, and concept representation learning systems"
            ],
            [
              "supporting incremental and continual learning."
            ]
          ]
        },
        {
          "page": 1,
          "table_index": 2,
          "content": [
            [
              "In human learning, deep learning [1] is an approach that involves the critical analysis of new topics and facts, linking"
            ],
            [
              "them to already known concepts or forming new concepts, and leads to long term retention of concepts so that they can be"
            ],
            [
              "used for problem solving in new situations. Deep learning promotes understanding and application for life. This is in contrast"
            ],
            [
              "to surface learning which is the rote acceptance of facts and memorization as isolated and unlinked facts. It leads to"
            ],
            [
              "superficial retention of facts and does not promote understanding or long term retention of knowledge."
            ],
            [
              "The major characteristics of deep learning are: aiming for understanding, focusing on concepts, and relating new and"
            ],
            [
              "previous knowledge. According to the Bloom\u2019s taxonomy [2], there are four types of knowledge: factual, conceptual,"
            ],
            [
              "procedural and metacognitive, and six levels of cognitive processes: remember, understand, apply, analyze, evaluate and"
            ],
            [
              "create. Factual knowledge, such as topics and facts, is locked in time, place, and/or situation. Factual knowledge does not"
            ],
            [
              "promote understanding. Concepts [3] (e.g., dog) are general ideas derived or inferred from facts. They are abstract and broad,"
            ],
            [
              "represented by different instances that share common attributes, universal in application, and timeless. Conceptual knowledge"
            ],
            [
              "is required for understanding and provides the framework for relating new and previous knowledge."
            ],
            [
              "The ultimate goal of learning is knowledge transfer [2]. Factual knowledge doesn't transfer, but conceptual"
            ],
            [
              "understanding does. Conceptual understanding is built by abstracting \u201cup\u201d from factual knowledge or examples to understand"
            ],
            [
              "concepts and the relationships among concepts. Whenever we try to apply our insights from one situation to another we are"
            ],
            [
              "always abstracting to the conceptual level before our knowledge helps us unlock the new situation. When tasks remain"
            ],
            [
              "similar to one another, this is known as low-road transfer. To transfer knowledge to dissimilar tasks requires high-road"
            ]
          ]
        },
        {
          "page": 2,
          "table_index": 0,
          "content": [
            [
              "transfer which involves highly generalized concepts. A deep foundation of facts or surface learning is key for deep learning"
            ],
            [
              "and knowledge transfer. Synergistic thinking, which involves the interaction between the factual and conceptual levels of"
            ],
            [
              "thinking, is essential for deep learning."
            ]
          ]
        },
        {
          "page": 2,
          "table_index": 1,
          "content": [
            [
              "In machine learning, deep learning has more than one definition. A useful, though narrow, definition [4] is: deep learning"
            ],
            [
              "is neural networks with a large number of layers and parameters in one of four fundamental network architectures:"
            ],
            [
              "unsupervised pretrained networks, convolutional neural networks, recurrent neural networks, and recursive neural networks"
            ],
            [
              "Automatic feature extraction is one of the major facets, and great advantages, that deep learning has."
            ],
            [
              "Deep learning is more broadly defined as feature representation learning in [5, 6]. It uses machine learning to discover"
            ],
            [
              "not only the mapping from feature representations to output but also the feature representations themselves. To learn features"
            ],
            [
              "that best represent data, the goal is to separate the factors of variation that explain the data. Deep learning does this by"
            ],
            [
              "learning successive layers of increasingly meaningful feature representations. The \u2018deep\u2019 in deep learning stands for this idea"
            ],
            [
              "of deep layers of feature representations. Deep learning is therefore layered feature representation learning. These layered"
            ],
            [
              "feature representations are generally learned via neural networks."
            ],
            [
              "Deep learning has achieved near-human accuracy levels in various types of classification and prediction tasks including"
            ],
            [
              "images, text, speech, and video data. However, the current technology of deep learning is largely at the level of surface"
            ],
            [
              "learning, not deep learning, in human learning, focusing on rote memorization of factual knowledge in the form of feature"
            ],
            [
              "representations. A deep-learning model [6, 7] is just a chain of simple, continuous geometric transformations mapping one"
            ],
            [
              "data manifold into another. Anything that needs reasoning is out of reach for deep-learning models. There are other major"
            ],
            [
              "limitations as well. Firstly, the knowledge learned using deep-learning models cannot be transferred because, as discussed"
            ],
            [
              "earlier, factual knowledge (feature representations) doesn't transfer, but conceptual understanding does. Secondly, deep-"
            ],
            [
              "learning models are difficult to understand or interpret [8]. This is to be expected since, as discussed earlier, factual"
            ],
            [
              "knowledge (feature representations) does not promote understanding. Conceptual knowledge is required for understanding."
            ],
            [
              "As a result of the first two limitations, deep-learning models cannot leverage contextual knowledge. They are developed in"
            ],
            [
              "isolation, within the narrow confine of the specific training data used, and do not support contextual adaptation [7]. Lastly,"
            ],
            [
              "but not the least, deep-learning models require lots of labeled data for training, which can be hard to come by. This is not"
            ]
          ]
        },
        {
          "page": 3,
          "table_index": 0,
          "content": [
            [
              "surprising since deep learning relies on rote memorization of feature representations to perform classification and prediction"
            ],
            [
              "tasks. It has no conceptual understanding of the data."
            ]
          ]
        },
        {
          "page": 3,
          "table_index": 1,
          "content": [
            [
              "From the above discussions it should be apparent that conceptual knowledge learning and conceptual understanding are"
            ],
            [
              "needed to elevate machine deep learning toward the level of human deep learning. We propose Concept-Oriented Deep"
            ],
            [
              "Learning (CODL) as a general approach to achieve that goal. CODL is an extension of (machine) deep learning. It extends"
            ],
            [
              "feature representation learning with concept representation learning and it adds the conceptual understanding capability to"
            ],
            [
              "deep learning. The major aspects of CODL include: concept graph, concept representations, concept exemplars, and concept"
            ],
            [
              "representation learning systems. These are discussed in the following sections. The last section provides the summary and"
            ],
            [
              "conclusion."
            ]
          ]
        },
        {
          "page": 3,
          "table_index": 2,
          "content": [
            [
              "The Big Book of Concepts [9] states that \u201cConcepts are the glue that holds our mental world together.\u201d Without"
            ],
            [
              "concepts, there would be no mental world. As discussed earlier, concepts [3] (e.g., dog) are general ideas derived or inferred"
            ],
            [
              "from facts. They are abstract and broad, represented by different instances that share common attributes. A concept may"
            ],
            [
              "contain a set of attributes that describe the concept and a set of sub-concepts that are components of the concept. Concepts"
            ],
            [
              "may also be related by relationships. The most common relationships include isA relationships."
            ],
            [
              "Concepts and categories go together [9]. That is, whatever the concept is, there is a category of things that would be"
            ],
            [
              "described by it. For material things (objects), \u2018category\u2019 is usually referred to as \u2018class\u2019; for abstract things (entities),"
            ],
            [
              "\u2018category\u2019 is commonly referred to as \u2018type\u2019. Thus, concepts denote categories, classes or types, and instances denote things,"
            ],
            [
              "objects or entities."
            ],
            [
              "Microsoft Concept Graph [10, 11] aims to give machines \"common-sense computing capabilities\" and an awareness of a"
            ],
            [
              "human's mental world, which is underpinned by concepts. Microsoft Concept Graph is built upon Probase, which uses the"
            ],
            [
              "world as its model. The concept graph in Probase is automatically learned from billions of web pages and years' worth of"
            ],
            [
              "search logs. The core taxonomy of Microsoft Concept Graph contains over 5.4 million concepts. Microsoft Concept Graph"
            ],
            [
              "also has a large data space (each concept contains a set of instances or sub-concepts), a large attribute space (each concept is"
            ],
            [
              "described by a set of attributes), and a large relationship space (e.g., \"isA\", \"locatedIn\")."
            ]
          ]
        },
        {
          "page": 4,
          "table_index": 0,
          "content": [
            [
              "The Microsoft Concept Tagging Model [11 \u2013 16], a part of Microsoft Concept Graph, maps text entities into concepts"
            ],
            [
              "with some probabilities, which may depend on the context texts of the entities. Given an input text entity, it returns a ranked"
            ],
            [
              "list of concepts. Each concept on the list has a probability denoting the possibility of the text entity belonging to this concept."
            ],
            [
              "Besides, some common measures for conceptualization (e.g., Typicality) are provided simultaneously."
            ],
            [
              "CODL uses Microsoft Concept Graph as the common / background conceptual knowledge base and the framework for"
            ],
            [
              "conceptual understanding, due to its probabilistic nature and extensive scope. Microsoft Concept Graph plays an important"
            ],
            [
              "role in CODL. Its usage in CODL is discussed in the following sections. However, CODL is not limited to using Microsoft"
            ],
            [
              "Concept Graph as the common / background conceptual knowledge base. Other comparable system can be used as such."
            ]
          ]
        },
        {
          "page": 4,
          "table_index": 1,
          "content": [
            [
              "In deep learning, feature representations are generally learned as a blob of ungrouped features. However, an increasing"
            ],
            [
              "number of visual applications nourish from inferring knowledge from imagery which requires scene understanding. Semantic"
            ],
            [
              "segmentation is a task that paves the way towards scene understanding. Deep semantic segmentation [17] uses deep learning"
            ],
            [
              "for semantic segmentation."
            ],
            [
              "Deep semantic segmentation makes dense predictions inferring labels for every pixel. It can be carried out at three"
            ],
            [
              "different levels:"
            ]
          ]
        },
        {
          "page": 4,
          "table_index": 2,
          "content": [
            [
              "\uf0b7 Class segmentation: each pixel is labeled with the class of its enclosing object or region"
            ],
            [
              "\uf0b7 Instance segmentation: separate labels for different instances of the same class"
            ],
            [
              "\uf0b7 Part segmentation: decomposition of already segmented classes into their component sub-classes"
            ]
          ]
        },
        {
          "page": 4,
          "table_index": 3,
          "content": [
            [
              "CODL extends and generalizes deep semantic segmentation. In CODL, feature representations are always learned"
            ],
            [
              "semantically segmented in a concept-oriented manner. Concept orientation means that each feature representation is"
            ],
            [
              "associated with a concept, an instance or an attribute. These concepts, instances and attributes form a concept graph. In"
            ],
            [
              "addition, the concept graph are generally linked to Microsoft Concept Graph, thus leveraging and integrating with the"
            ],
            [
              "common conceptual knowledge and conceptual understanding capability provided by Microsoft Concept Graph."
            ],
            [
              "A concept representation consists of a concept, its instances and attributes, and all the feature representations associated"
            ],
            [
              "with the concept and its instances and attributes. If a concept has sub-concepts, its concept representation also consists of the"
            ]
          ]
        },
        {
          "page": 5,
          "table_index": 0,
          "content": [
            [
              "concept representations of its sub-concepts. Concept representations, therefore, are the same as concept-oriented feature"
            ],
            [
              "representations, but provide a different view. The latter is data driven and provides a bottom-up view starting from feature"
            ],
            [
              "representations; the former is concept driven and provides a top-down view starting from concepts. Due to the focus on"
            ],
            [
              "concepts instead of low-level feature representations, concept representations provide the proper view to work with in CODL."
            ]
          ]
        },
        {
          "page": 5,
          "table_index": 1,
          "content": [
            [
              "Concept representations can be learned using supervised learning. Similar to deep semantic segmentation [17], discussed"
            ],
            [
              "above, it can be carried out at different levels:"
            ]
          ]
        },
        {
          "page": 5,
          "table_index": 2,
          "content": [
            [
              "\uf0b7 Concept level: each feature representation is labeled with the concept that owns the feature"
            ],
            [
              "\uf0b7 Instance level: separate labels for different instances of the same concept"
            ],
            [
              "\uf0b7 Attribute level: separate labels for different attributes of the same concept"
            ],
            [
              "\uf0b7 Component level: decomposition of already learned concept representations into their sub-concept"
            ],
            [
              "representations"
            ]
          ]
        },
        {
          "page": 5,
          "table_index": 3,
          "content": [
            [
              "The concept, instance and attribute names used for labeling should be taken from Microsoft Concept Graph, if available."
            ],
            [
              "This provides direct link to Microsoft Concept Graph to leverage its common conceptual knowledge and conceptual"
            ],
            [
              "understanding capability."
            ]
          ]
        },
        {
          "page": 5,
          "table_index": 4,
          "content": [
            [
              "As is the case for deep semantic segmentation, it can be difficult to gather and create labeled concept representation"
            ],
            [
              "datasets to use for training in supervised learning. Due to the semantically-segmented nature of concepts, a good alternative is"
            ],
            [
              "to use concept exemplars."
            ],
            [
              "A concept exemplar set is a set of one or more typical instances of a concept, possibly augmented with instances"
            ],
            [
              "generated from the typical instances using identity-preserving transformations. As an example, for image objects the identity-"
            ],
            [
              "preserving transformations [18] typically include: scaling, translation, rotation, contrast and color. Each concept is associated"
            ],
            [
              "with at most one concept exemplar set."
            ]
          ]
        },
        {
          "page": 6,
          "table_index": 0,
          "content": [
            [
              "With concept exemplars one can use supervised concept representation learning, as discussed earlier, or unsupervised"
            ],
            [
              "concept representation learning, as discussed below. Concept exemplars can facilitate incremental and continual learning, to"
            ],
            [
              "be discussed later."
            ]
          ]
        },
        {
          "page": 6,
          "table_index": 1,
          "content": [
            [
              "Exemplar-CNN [18] is an approach for training a convolutional network using only unlabeled data. It trains the network"
            ],
            [
              "to discriminate between a set of surrogate classes. Each surrogate class is formed by applying a set of transformations to a"
            ],
            [
              "randomly sampled \u2019seed\u2019 image patch. The resulting feature representations are not task specific. They are generic and"
            ],
            [
              "provide robustness to the transformations that have been applied during training. The applied transformations thus define the"
            ],
            [
              "invariance properties that are to be learned by the network."
            ],
            [
              "Unsupervised concept representation learning uses the same approach as Exemplar-CNN. In CODL, concept exemplars"
            ],
            [
              "play the role of surrogate classes, and identity-preserving transformations that of applied transformations, in Exemplar-CNN."
            ],
            [
              "Whereas surrogate classes are based on randomly sampled \u2019seed\u2019 image patches, concept exemplars are based on"
            ],
            [
              "semantically distinct, typical instances of concepts. Therefore, we expect unsupervised concept representation learning based"
            ],
            [
              "on concept exemplars to result in generic, transferable concept representations."
            ]
          ]
        },
        {
          "page": 6,
          "table_index": 2,
          "content": [
            [
              "Concept representation learning systems provide the platforms and tools for use in CODL. They support supervised"
            ],
            [
              "concept representation learning as well as unsupervised concept representation learning based on concept exemplars. They"
            ],
            [
              "also provide access to the common / background conceptual knowledge base, such as Microsoft Concept Graph. The"
            ],
            [
              "following are major aspects of concept representation learning systems which are important for the success of CODL and its"
            ],
            [
              "application."
            ]
          ]
        },
        {
          "page": 6,
          "table_index": 3,
          "content": [
            [
              "In real-world scenarios, concepts and their associated data are almost always collected in an incremental manner. As"
            ],
            [
              "such, incremental and continual learning [19] is a critical aspect of CODL. A good concept representation learning system"
            ],
            [
              "must accommodate new concepts and their associated data that it is exposed to and gradually expands its capacity to predict"
            ],
            [
              "increasing number of new concepts."
            ]
          ]
        },
        {
          "page": 7,
          "table_index": 0,
          "content": [
            [
              "Doing incremental learning using deep neural network faces inherent technical challenges. Neural networks embed"
            ],
            [
              "feature extraction and classification within the same model. This gives rise to the so-called \u201ccatastrophic forgetting /"
            ],
            [
              "interference\" problem [20] which refers to the destruction / modification of existing feature representations learned from"
            ],
            [
              "earlier data, when the model is exclusively trained with data of new concepts."
            ],
            [
              "Therefore, the challenge is to be able to incrementally and continually learn over time by accommodating new concepts"
            ],
            [
              "and their data while retaining previously learned concept representations. There are various approaches [19] for incremental"
            ],
            [
              "and continual learning that mitigate, to different extents, catastrophic interference. The regularization approaches alleviate"
            ],
            [
              "catastrophic interference by imposing constraints on the update of the neural weights. The dynamic architecture approaches"
            ],
            [
              "change architectural properties in response to new concepts and their data, either by dynamically accommodating novel"
            ],
            [
              "neural resources or by re-training with an increased number of neurons or network layers."
            ],
            [
              "A good approach to use in CODL is that of iCaRL [21] (incremental classifier and representation learning), which is a"
            ],
            [
              "dynamic architecture approach. The approach allows learning in a concept-incremental way: only the training data for a small"
            ],
            [
              "number of concepts has to be present at the same time and new concepts can be added progressively. Concept-incremental"
            ],
            [
              "learning has the following properties:"
            ]
          ]
        },
        {
          "page": 7,
          "table_index": 1,
          "content": [
            [
              "\uf0b7 it is trainable from a data stream in which examples of different concepts appear at intermittent times,"
            ],
            [
              "\uf0b7 at any time it provides a competitive multi-concept classifier for all the concepts learned so far, and"
            ],
            [
              "\uf0b7 it does not require storing all training data or retraining already-learned concepts whenever new data becomes"
            ],
            [
              "available."
            ]
          ]
        },
        {
          "page": 7,
          "table_index": 2,
          "content": [
            [
              "The main components [21] that enable simultaneous learning of concept representations and concept classifiers in the"
            ],
            [
              "concept-incremental manner are:"
            ]
          ]
        },
        {
          "page": 7,
          "table_index": 3,
          "content": [
            [
              "\uf0b7 concept representation learning using knowledge distillation and prototype rehearsal,"
            ],
            [
              "\uf0b7 concept exemplar selection / learning based on herding, and"
            ],
            [
              "\uf0b7 concept classification by the nearest mean of concept exemplars."
            ]
          ]
        },
        {
          "page": 8,
          "table_index": 0,
          "content": [
            [
              "Prior to that we note that the deep learning network is used only for concept representation learning and concept"
            ],
            [
              "exemplar selection, not for classifying new data, which is done using concept classifiers based on concept exemplars. The"
            ],
            [
              "concept representation learning scheme, using knowledge distillation, addresses the \u201ccatastrophic forgetting / interference\u201d"
            ],
            [
              "problem of incremental and continual learning. The use of concept exemplars, for concept classifiers, avoids the other"
            ],
            [
              "problem: storing of all training data."
            ],
            [
              "Concept Representation Learning"
            ],
            [
              "Whenever data for new concepts arrive, the concept representations and concept exemplar sets are updated. Firstly, the"
            ],
            [
              "network outputs for the existing concepts are stored. Secondly, an augmented training set is constructed, consisting of the"
            ],
            [
              "(newly available) training examples for the new concepts together with the concepts exemplar sets for the existing concepts."
            ],
            [
              "Finally, the deep learning network is trained / updated by minimizing a loss function to output the correct concept indicators"
            ],
            [
              "for new concepts (classification loss), and for old concepts, to reproduce the scores stored in the first step (distillation loss)."
            ],
            [
              "The classification loss enables improvements of the concept representations that allow classifying the new concepts well; the"
            ],
            [
              "distillation loss ensures that the discriminative information learned for existing concepts is not lost while training for the new"
            ],
            [
              "concepts."
            ],
            [
              "Concept Exemplars Selection / Learning"
            ],
            [
              "Concept exemplars selection is required for each concept only once, when it is first learned and its training data is"
            ],
            [
              "available. For each concept, concept exemplars are selected and stored iteratively until the target number is met. In each step"
            ],
            [
              "of the iteration, one more example of the training set is added to the concept exemplar set, namely the one that causes the"
            ],
            [
              "average feature vector over all concept exemplars to best approximate the average feature vector over all training examples."
            ],
            [
              "Thus, the concept exemplar set is a prioritized list, with concept exemplars earlier in the list being more important. The"
            ],
            [
              "concept exemplar set may be augmented using identity-preserving transformations, as discussed earlier."
            ],
            [
              "Concept Classification Based on Concept Exemplars"
            ],
            [
              "For concept classification, a nearest-mean-of-concept-exemplars classification strategy is used. To predict a concept"
            ],
            [
              "label for a new sample, it first computes a prototype vector for each concept by computing the average feature vector of all"
            ],
            [
              "concept exemplars for the concept. It then computes the feature vector of the sample that should be classified and assigns the"
            ],
            [
              "concept label with the most similar prototype. The concept prototypes automatically change whenever the concept\n8"
            ]
          ]
        },
        {
          "page": 9,
          "table_index": 0,
          "content": [
            [
              "representations change, making the classifier robust against changes of the concept representations (as new concepts are"
            ],
            [
              "learned)"
            ]
          ]
        },
        {
          "page": 9,
          "table_index": 1,
          "content": [
            [
              "Concept taxonomy [9] is one particular kind of concept organization: the hierarchical structure of concepts with each"
            ],
            [
              "branch being a sequence of progressively larger concepts in which each concept includes all the previous ones. Different"
            ],
            [
              "levels of concepts reflect different levels of abstraction, which associate with different attributes. These taxonomic concepts"
            ],
            [
              "are important for thought and communication."
            ],
            [
              "In a concept taxonomy, the concepts that are higher in the hierarchy are superordinate to the lower-level concepts; the"
            ],
            [
              "lower-level concepts are subordinate to the higher-level ones. The only relationship allowed between concepts in the"
            ],
            [
              "hierarchy is the set inclusion relationship: the set of instances of a superordinate concept (e.g., dog) includes the set of"
            ],
            [
              "instances of its subordinate concept (e.g., bull dog). The set inclusion relationship is called the \u2018\u2018isA\u2019\u2019 relationship, which is"
            ],
            [
              "asymmetric and transitive. The transitivity of concept relationship in the hierarchy leads to a similar transitivity of attribute"
            ],
            [
              "ascription, called attribute inheritance. Every attribute of a concept is also an attribute of the concept\u2019s subordinates."
            ],
            [
              "By being able to locate a concept in its proper place in the concept taxonomy, one can learn a considerable amount about"
            ],
            [
              "the concept, e.g., its superordinates and inherited attributes. In CODL, this is achieved by accessing Microsoft Concept"
            ],
            [
              "Graph, as discussed near the beginning. Clearly, this is an important ability, since it allows one to immediately access"
            ],
            [
              "knowledge (concepts) about new objects or entities without the need to directly learn."
            ],
            [
              "Basic-Level Concepts"
            ],
            [
              "The objects and entities that we encounter every day do not each fit into a single concept, but can be classified with a"
            ],
            [
              "large number of different concepts. It is important to know the preferred concept by which people think about any one object"
            ],
            [
              "or entity."
            ],
            [
              "Any object or entity can be thought of as being in a set of hierarchically organized concepts, i.e., a concept taxonomy,"
            ],
            [
              "ranging from extremely general (e.g., animal) to extremely specific (e.g., bull dog). Classification at the most general level"
            ],
            [
              "maximizes accuracy of classification. Most specific concepts, on the other hand, allow for greater accuracy in prediction. Of"
            ],
            [
              "all the possible concepts in a concept taxonomy to which a concept belongs, a middle level of specificity, the basic level [9],"
            ]
          ]
        },
        {
          "page": 10,
          "table_index": 0,
          "content": [
            [
              "is the most natural, preferred level at which to conceptually carve up the world. The basic level (e.g., dog) can be seen as a"
            ],
            [
              "compromise between the accuracy of classification at a most general level and the predictive power of a most specific level."
            ],
            [
              "Superordinate concepts (e.g., animal) are distinctive but not informative. Subordinate concepts (e.g., bull dog) are"
            ],
            [
              "informative but not distinctive. It is only basic-level concepts (e.g., dog) that are both informative and distinctive. Basic-level"
            ],
            [
              "concept is important because it provides rich information with little cognitive efforts. When a person obtains the basic-level"
            ],
            [
              "concept of an unfamiliar object or entity, she will associate the object or entity with the known attributes of the basic-level"
            ],
            [
              "concept."
            ],
            [
              "Therefore, to be effective, in CODL one should focus on learning and using concept representations for basic-level"
            ],
            [
              "concepts [11]. Superordinate concepts are automatically \u201clearned\u201d by accessing Microsoft Concept Graph, as discussed"
            ],
            [
              "earlier. When needed, this can be supplemented by learning and using concept representations for selective subordinate"
            ],
            [
              "concepts."
            ]
          ]
        },
        {
          "page": 10,
          "table_index": 1,
          "content": [
            [
              "Concepts are the foundation of human deep learning, understanding, and knowledge integration and transfer. The current"
            ],
            [
              "technology of machine deep learning is largely at the level of surface learning in human learning, focusing on rote"
            ],
            [
              "memorization of factual knowledge in the form of feature representations. To elevate machine deep learning toward the level"
            ],
            [
              "of human deep learning, we proposed concept-oriented deep learning (CODL) which extends (machine) deep learning with"
            ],
            [
              "concept representations and conceptual understanding capability."
            ],
            [
              "CODL leverages Microsoft Concept Graph, or something comparable, as the common / background conceptual"
            ],
            [
              "knowledge base and the framework for conceptual understanding. In particular, concept names and concept taxonomies (isA"
            ],
            [
              "relationships) originate from Microsoft Concept Graph. In CODL, feature representations are always learned semantically"
            ],
            [
              "segmented in a concept-oriented manner. Concept representations are the same as concept-oriented feature representations,"
            ],
            [
              "but from a top-down, concept-driven perspective which is the focus of CODL. It can be difficult to gather and create labeled"
            ],
            [
              "concept representation datasets to use for training. Due to the semantically-segmented nature of concepts, a good alternative"
            ],
            [
              "is to use concept exemplars."
            ],
            [
              "Concept representation learning systems provide the platforms and tools for use in CODL. They support supervised"
            ],
            [
              "concept representation learning as well as unsupervised concept representation learning based on concept exemplars. Since,"
            ]
          ]
        },
        {
          "page": 11,
          "table_index": 0,
          "content": [
            [
              "in real-world scenarios, concepts and their associated data are almost always collected in an incremental manner, a good"
            ],
            [
              "concept representation learning system must support incremental and continual learning (using concept exemplars). Also, to"
            ],
            [
              "be effective, in CODL one should focus on learning and using concept representations for basic-level concepts."
            ],
            [
              "By focusing on learning and using concept representations and concept exemplars, CODL is able to address some of the"
            ],
            [
              "major limitations of deep learning: interpretability, transferability, contextual adaptation, and requirement for lots of labeled"
            ],
            [
              "training data."
            ]
          ]
        }
      ],
      "images": [],
      "status": "completed",
      "json_file": "processed/compiled/1806.01756v1_compiled.json"
    },
    {
      "metadata": {
        "title": "Deep learning research landscape & roadmap in a nutshell: past, present   and future -- Towards deep cortical learning",
        "authors": [
          "Aras R. Dargazany"
        ],
        "abstract": "The past, present and future of deep learning is presented in this work. Given this landscape & roadmap, we predict that deep cortical learning will be the convergence of deep learning & cortical learning which builds an artificial cortical column ultimately.",
        "published": "2019-07-30T16:57:38Z",
        "arxiv_id": "1908.02130v1",
        "categories": [
          "cs.NE",
          "cs.LG"
        ],
        "pdf_url": "http://arxiv.org/pdf/1908.02130v1",
        "pdf_file": "data/pdfs/1908.02130v1.pdf",
        "pdf_filename": "1908.02130v1.pdf"
      },
      "processing_info": {
        "processed_at": "2025-09-26T06:33:40.094376",
        "is_large_pdf": false,
        "sections_found": 2,
        "tables_found": 0,
        "images_found": 2
      },
      "sections_text": {
        "Abstract": "The past, present and future of deep learning is presented in this work. Given this landscape & roadmap, we predict that deep cortical learning will be the convergence of deep learning & cortical learning which builds an arti\ufb01cial cortical column ultimately. Past: Deep learning inspirations Deep learning horizon, landscape and research roadmap in nutshell is presented in this \ufb01gure . The historical development and timeline of deep learning & neural network is separately illustrated Figure 1: Deep learning research landscape & roadmap: past, present, future. The future is highlighted as deep cortical learning. in \ufb01gure . The Origin of neural nets [ WR17 ] is thoroughly reviewed in terms of the evolutionary history of deep learning models. Vernon Mountcastle discovery of cortical columns in somatosensory cortex [ Mou97 ] was a breakthrough in brain science. The big bang was the discovery of Hubel & Wiesel of simple cells and complex cell in visual cortex [ HW59 ] which won the Nobel prize for this discovery in 1981. This work was heavily founded on Vernon Mountcastle discovery of cortical columns in somatosensory cortex [ Mou97 ]. After the discovery of Hubel & Wiesel, Fukushima proposed a pattern recognition architecture based on the simple cell and complex cell discovery, known as NeoCognitron [ FM82 ]. In this work, a deep neural network was proposed using simple cell layer and complex cell layer repeatedly. In 80s and maybe a bit earlier backpropagation have been proposed by multiple people but the \ufb01rst time it was well-explained and applied for learning neural nets was done by Hinton and his colleagues in [ RHW86 ]. arXiv:1908.02130v1 [cs.NE] Jul Figure 2: Neural nets origin, timeline & history made by Favio Vazquez Present: Deep learning by LeCun, Bengio and Hinton Convolutional nets was invented by LeCun [ LBD + ] which led to deep learning conspiracy which also started by the three founding fathers of the \ufb01eld: LeCun, Bengio and Hinton [ LBH15 ]. The main hype in deep learning happened in when the state-of-the-art result in Imagenet classi\ufb01cation and TIMIT speech recognition task were dramatically reduced using an end-to-end deep convolutional network [ KSH12 ] and deep belief net [ HDY + ]. The power of deep learning is scalability and the ability to learn in an end-to-end fashion. In this sense, deep learning architectures are capable of learning big datasets such as Imagenet [ KSH12 , GDG + ] and TIMIT using multiple GPUs in an end-to-end fashion meaning directly from raw inputs, all the way the desired outputs. Alexnet [ KSH12 ] used two GPUs for Imagenet classi\ufb01cation which is a very big dataset of images, almost 1. million images of size 215x215. Kaiming He et al. [ GDG + ] proposed a highly scalable approach for training on Image using",
        "256 GPUs for almost an hour which shows an amazingly powerful approach based stochastic": "gradient descent for applying big cluster of GPUs on huge datasets. Very many application domains have been revolutionized using deep learning architectures such as image classi\ufb01cations [ KSH12 ], machine translation [ WSC + , JSL + ], speech recognition [ HDY + ], and robotics [ MKS + ]. The Nobel Prize in Physiology or Medicine was given to John O\u2019Keefe, May-Britt Moser and Edvard I. Moser \u201cfor their discoveries of cells that constitute a positioning system in the brain.\u201d [ Bur14 ]. This study of cognitive neuroscience shed light on how the world is represented within the brain. Hinton\u2019s Capsule network [ SFH17 ] and Hawkins\u2019 cortical learning algorithm [ HAD11 ] are highly inspired by this Nobel-prize winning work [ Bur14 ]. Future: Brain-plausible deep learning & cortical learning algorithms The main direction and inclination in the deep learning for future is the ability to bridge the gap between the cortical architecture and deep learning architectures, speci\ufb01cally convolutional nets. In this quest, Hinton proposed capsule network [ SFH17 ] as an e\ufb00ort to get rid of pooling layers and replace it with capsules which are highly inspired bu cortical mini-columns in cortical columns and layers and include the location information or pose information of parts. Another important quest in deep learning is understanding the biological root of learning in our brain, speci\ufb01cally in our cortex. Backpropagation is not biologically inspired and plausible. Hinton and the other founding fathers of deep learning have been trying to understand how backprop might be feasible biologically in brain. Feedback alignment [ LCTA16 ] and spike time-dependent plasticity or STDP-based backprop [ BSR + ] are some of the works which have been done by Timothy Lillicrap, Blake Richards, and Hinton in order to model backprop biologically based on the pyramidal neuron in the cortex. In the far future, the main goal should be the merge of two very independent quest to build cortical structure in our brain: The \ufb01rst one is heavily target by the big and active deep learning community; The second one is targeted independently and neuroscienti\ufb01cally by Numenta and Geo\ufb00 Hawkins [ HAD11 ]. These people argue that the cortical structure and our neocortex is the main source of our intelligence and for building a true intelligent machine, we should be able to reconstruct the cortex and to do so, we should \ufb01rst focus more on the cortex and understand what cortex is made out of. Finale: Deep cortical learning as the merge of deep learning and cortical learning By merging deep learning and cortical learning, a very more focused and detailed architectures, named deep cortical learning might be created. We might be able to understand and reconstruct the cortical structure with much more accuracy and have a better idea what the true intelligence is and how arti\ufb01cial general intelligence or AGI might be reproducible. Deep cortical learning might be the algorithm behind one cortical column in the neocortex."
      },
      "sections_summary": {
        "Abstract": "The past and future of deep learning are connected to the concept of cortical columns in the brain, which were first discovered by Vernon Mountcastle. The development of deep learning models was influenced by this discovery, with notable milestones including:\n\n- The proposal of simple cell layers and complex cell layers by Fukushima (NeoCognitron)\n- The use of backpropagation in neural networks by Hinton and colleagues\n- The invention of convolutional nets by LeCun\n\nThe present state of deep learning is characterized by its scalability and ability to learn from large datasets, with notable achievements including:\n\n- State-of-the-art results in ImageNet classification and TIMIT speech recognition tasks\n- The use of end-to-end deep convolutional networks and multiple GPUs for training on large datasets\n\nThe future of deep learning is predicted to be the convergence of deep learning and cortical learning, resulting in artificial cortical columns.",
        "256 GPUs for almost an hour which shows an amazingly powerful approach based stochastic": "Gradient descent can apply big clusters of GPUs to large datasets. Deep learning has revolutionized many domains, including image classification, machine translation, and speech recognition. Nobel Prize winners John O'Keefe and May-Britt Moser discovered brain cells that represent spatial positioning. Future directions in deep learning aim to bridge the gap between cortical architecture and deep networks, with proposed solutions like capsule networks and feedback alignment. A new goal is to merge deep learning with cortical learning to create \"deep cortical learning,\" potentially leading to more accurate understanding of intelligence and artificial general intelligence (AGI)."
      },
      "tables": [],
      "images": [
        "processed/images/1908.02130v1_page1_img0.png",
        "processed/images/1908.02130v1_page2_img0.png"
      ],
      "status": "completed",
      "json_file": "processed/compiled/1908.02130v1_compiled.json"
    }
  ],
  "summary": {
    "total_papers": 3,
    "topic": "deep learning",
    "processing_time": "0:01:00"
  }
}