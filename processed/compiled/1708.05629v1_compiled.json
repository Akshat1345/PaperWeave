{
  "metadata": {
    "title": "Learning to Transfer",
    "authors": [
      "Ying Wei",
      "Yu Zhang",
      "Qiang Yang"
    ],
    "abstract": "Transfer learning borrows knowledge from a source domain to facilitate learning in a target domain. Two primary issues to be addressed in transfer learning are what and how to transfer. For a pair of domains, adopting different transfer learning algorithms results in different knowledge transferred between them. To discover the optimal transfer learning algorithm that maximally improves the learning performance in the target domain, researchers have to exhaustively explore all existing transfer learning algorithms, which is computationally intractable. As a trade-off, a sub-optimal algorithm is selected, which requires considerable expertise in an ad-hoc way. Meanwhile, it is widely accepted in educational psychology that human beings improve transfer learning skills of deciding what to transfer through meta-cognitive reflection on inductive transfer learning practices. Motivated by this, we propose a novel transfer learning framework known as Learning to Transfer (L2T) to automatically determine what and how to transfer are the best by leveraging previous transfer learning experiences. We establish the L2T framework in two stages: 1) we first learn a reflection function encrypting transfer learning skills from experiences; and 2) we infer what and how to transfer for a newly arrived pair of domains by optimizing the reflection function. Extensive experiments demonstrate the L2T's superiority over several state-of-the-art transfer learning algorithms and its effectiveness on discovering more transferable knowledge.",
    "published": "",
    "arxiv_id": "1708.05629v1",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1708.05629v1",
    "pdf_file": "data/pdfs/1708.05629v1.pdf",
    "pdf_filename": "1708.05629v1.pdf"
  },
  "processing_info": {
    "processed_at": "2025-10-28T10:16:15.478394",
    "sections_found": 140,
    "tables_found": 10,
    "images_found": 15
  },
  "sections_text": {
    "Qiang Yang ‡": "Department of Computer Science, Hong Kong University of Science and Technology, Hong Kong yweiad ∗ ,zhangyu † ,qyang ‡ @cse.ust.hk",
    "Abstract": "Transfer learning borrows knowledge from a source domain to facilitate learning in a target domain. Two primary issues to be addressed in transfer learning are what and how to transfer. For a pair of domains, adopting different transfer learning algorithms results in different knowledge transferred between them. To discover the optimal transfer learning algorithm that maximally improves the learning per- formance in the target domain, researchers have to exhaustively explore all existing transfer learning algorithms, which is computationally intractable. As a trade-off, a sub-optimal algorithm is selected, which requires considerable expertise in an ad- hoc way. Meanwhile, it is widely accepted in educational psychology that human beings improve transfer learning skills of deciding what to transfer through meta- cognitive reﬂection on inductive transfer learning practices. Motivated by this, we propose a novel transfer learning framework known as Learning to Transfer (L2T) to automatically determine what and how to transfer are the best by leveraging previous transfer learning experiences. We establish the L2T framework in two stages: 1) we ﬁrst learn a reﬂection function encrypting transfer learning skills from experiences; and 2) we infer what and how to transfer for a newly arrived pair of domains by optimizing the reﬂection function. Extensive experiments demonstrate the L2T’s superiority over several state-of-the-art transfer learning algorithms and",
    "Introduction": "Inspired by human beings’ capabilities to transfer knowledge across tasks, transfer learning aims to leverage knowledge from a source domain to improve the learning performance or minimize the number of labeled examples required in a target domain. It is of particular signiﬁcance when tackling tasks with limited labeled examples. Transfer learning has proved its wide applicability in, such as image classiﬁcation [ 15 ], sentiment classiﬁcation [ 4 ], dialog systems [ 18 ] and urban computing [ 27 ]. Three key research issues in transfer learning, pointed by Pan and Yang, are when to transfer, how to transfer, and what to transfer. Once transfer learning from a source domain is considered to beneﬁt a target domain (when to transfer), an algorithm (how to transfer) should discover the shared knowledge to be transferred across domains (what to transfer). Different algorithms are likely to discover different parts of transferable knowledge, and thereby lead to uneven transfer learning effectiveness which is evaluated by the performance improvement after transfer learning is conducted. To achieve the optimal performance improvement for a pair of source and target domains, researchers may try tens to hundreds of transfer learning algorithms covering instance [ 6 ], parameter [ 25 ], and feature [ 20 ] based algorithms. This brute-force exploration is computationally expensive and practically impossible. As a tradeoff, a sub-optimal improvement is usually obtained from a heuristically selected algorithm, which unfortunately requires considerable expertise in an ad-hoc and unsystematic manner. Exploring different algorithms is not the only way to better determine what to transfer and thereby improve transfer learning effectiveness. Previous transfer learning experiences do also help, which has been widely accepted in educational psychology [ 3 , 16 ]. Human beings sharpen transfer learning skills for deciding what to transfer by conducting meta-cognitive reﬂection on thorough and diverse transfer learning experiences. For example, children who are good at playing chess may transfer",
    "arXiv:1708.05629v1  [cs.AI]  18 Aug 2017": "mathematical skills, reading skills, visuospatial skills, and decision making skills learned from chess to solve arithmetic problems, to comprehend reading materials, to solve pattern matching puzzles, and to play basketball, respectively. At a later age, it will be easier for them to decide to transfer mathematical and decision making skills learned from chess, rather than reading and visuospatial skills, to market investment. Unfortunately, all existing transfer learning algorithms transfer from",
    "scratch and ignore previous transfer learning experiences.": "Motivated by this, we propose a novel transfer learning framework called Learning to Transfer (L2T). The key idea of the L2T framework is to enhance transfer learning effectiveness by leveraging previous transfer learning experiences to automatically determine what and how to transfer are the best for a pair of source and target domains of interest. To achieve the goal, we establish the L2T framework in two stages. During the ﬁrst stage, we encode each transfer learning experience into three components including a pair of source and target domains, transferred knowledge parameterized as shared latent feature factors (i.e., what to transfer between them), and performance improvement. We learn from all experiences a reﬂection function which maps a pair of domains and the transferred knowledge between them to the corresponding performance improvement. The reﬂection function, therefore, is believed to encrypt the transfer learning skills for deciding what and how to transfer. In the second stage, the knowledge to be transferred between a newly arrived pair of domains is optimized so that the value of the learned reﬂection function, matching to the performance improvement, is maximized. The contribution of this paper is that we propose a novel transfer learning framework which opens a new door to improve transfer learning effectiveness by taking advantages of previous transfer learning experiences. The L2T can discover more transferable knowledge across domains in a systematic and automatic fashion without requiring considerable expertise, which is also evidenced in comprehensive empirical studies showing the L2T’s superiority over state-of-the-art transfer learning algorithms.",
    "Transfer Learning": "To successfully conduct transfer learning, one of the most critical research issues identiﬁed in [ 19 ] is to decide what and how to transfer. Parameters [ 25 , 28 ], instances [ 6 ], or latent feature factors [ 20 ] can be transferred between domains. A few works [ 25 , 28 ] transfer parameters from source domains to a target domain as regularizers of SVM-based models. In [ 6 ], a basic learner in a target domain is boosted by borrowing the most useful instances from a source domain. Different techniques capable of extracting transferable latent feature factors between domains have been investigated extensively. These techniques include manually selected pivot features [ 4 ], dimension reduction [ 1 , 2 , 20 ], collective matrix factorization [ 14 ], dictionary learning and sparse coding [ 21 , 31 ], manifold learning [ 8 , 9 ], and deep learning [ 15 , 26 , 30 ]. Unlike L2T, all existing studies in transfer learning transfer from scratch, i.e., only considering the source domain and target domain of interest but ignoring previous transfer learning experiences. Since any existing transfer learning algorithm mentioned above could be applied in a transfer learning experience, L2T",
    "Lifelong Learning": "Assuming a new learning task to lie in the same environment as training tasks, learning to learn [ 24 ] or meta-learning [ 17 ] transfers knowledge shared among the training tasks to the new task. Ruvolo and Eaton considered lifelong learning as an online meta-learning. Though L2T and lifelong learning both aim to continuously improve a learning system by leveraging histories, L2T differs from them in that each task we consider is a transfer learning task rather than a traditional learning task. Therefore, we learn transfer learning skills instead of task-sharing knowledge.",
    "Learning to Transfer": "We begin by ﬁrst introducing the proposed L2T framework. Then we detail the two steps involved in the framework, i.e., learning transfer learning skills from previous transfer learning experiences and applying those skills to infer what and how to transfer for a future pair of source and target domains.",
    "The L2T Framework": "A L2T agent previously conducted transfer learning several times, and kept a record of N e transfer learning experiences (see step (1) in Figure 1). We deﬁne each transfer learning experience as E e = ( S e , T e , a e , l e ) in which S e = { X s",
    "e , y s": "e } and T e = { X t",
    "e , y t": "e } denote a source domain and a",
    "target domain, respectively. X ∗": "e ∈ R n ∗ e × m represents the feature matrix if either domain has n ∗ e",
    "2": "n s n t n s ,n t",
    "source or target domain. y ∗": "e ∈Y ∗ e denotes the vector of labels with the length being n ∗ le . The number of target labeled examples is much smaller than that of source labeled examples, i.e., n t le ≪ n s le . We focus on the setting X s e = X t e and Y s e ̸ = Y t e for each pair of domains. a e ∈A = { a 1 , · · · , a N a } denotes a transfer learning algorithm randomly selected from the set A containing N a base algorithms. Suppose that what to transfer inferred by the algorithm a e can be parameterized as W e . Finally, each transfer learning experience is labeled with the performance improvement ratio l e = p st e /p t e where p t e is the learning performance (e.g., classiﬁcation accuracy) in T e without transfer on a test dataset and p st e is the learning performance in T e after transferring knowledge from S e on the same test dataset. Performance improvement (1) Previous transfer learning experiences (2) Learn transfer learning skills (3) Optimize what and how to transfer for a future pair of source and target domains 1 1 ,   e e N N    *",
    "W": "f ( S N e +1 , T N e +1 , W ; β ∗ , λ ∗ , µ ∗ , b ∗ ) + γ 2 ∥ W ∥ 2 F = arg min W ( β ∗ ) T ˆd W + λ ∗ ( β ∗ ) T ˆQ W β ∗ + µ ∗ 1 ( β ∗ ) T τ W + γ 2 ∥ W ∥ 2 F , (3) where ∥· ∥ F denotes the matrix Frobenius norm and γ 2 controls the complexity of W . The ﬁrst and second terms in problem (3) can be calculated as ( β ∗ ) T ˆ d W = Nk X k =1 β ∗ k \u0014 1 ( n s ) 2 n s X i,i ′ =1",
    "f": "1 a e N a ( )",
    "(   )": "(2) (3) ) , , ( max arg",
    "to learn a function f such": "that f ( S e , T e , W e ) approx-",
    "transfer learning skills -": "what and how to transfer can maximize the improvement ratio given a pair of source and target domains. Whenever a new pair of domains ⟨S N e +1 , T N e +1 ⟩ arrives, the L2T agent can identify the optimal knowledge to be transferred for this new pair, which is contained in W ∗ N e +1 , by maximizing",
    "Parameterizing What to Transfer": "Adopting different algorithms for one pair of source and target domains brings different what to transfer between them. To learn the reﬂection function with what to transfer as one input, we have to uniformly parameterize “what to transfer” for all algorithms in the base algorithm set A . In this work, we consider A to contain algorithms transferring only single-level latent feature factors, because other existing parameter-based and instance-based algorithms cannot address the transfer learning setting we focus on (i.e., X e s = X e t and Y e s ̸ = Y e t ). Though limited parameter-based algorithms [ 25 , 28 ] can transfer across domains in heterogeneous label spaces, they can only handle binary classiﬁcation problems. Deep neural network based algorithms [ 15 , 26 , 30 ] transferring latent feature factors in a hierarchy are left for our future research. As a consequence, what to transfer can be parameterized with a latent feature factor matrix W , which we will elaborate in the following. Latent feature factor based algorithms for the transfer learning setting mentioned above aim to learn domain-invariant feature factors across domains. Consider classifying dog pictures as a source domain and cat pictures as a target domain. The domain-invariant feature factors could include eyes, mouth, tails, etc. Re-characterized with the latent feature factors which are more descriptive, a target domain is expected to achieve better performance with less labeled examples. What to transfer, in this case, is these shared feature factors across domains. According to different ways of extracting the domain-invariant feature factors, existing latent feature factor based algorithms can be categorized into two groups, i.e., common latent space based algorithms and manifold ensemble based algorithms.",
    "Common latent space based algorithms": "This line of algorithms, including but not limited to TCA , LSDT , and DIP , assumes that the domain-invariant feature factors lie in a single shared latent space. We denote by ϕ the function mapping the original feature representation into the latent space. If ϕ is linear, it can be represented as an embedding matrix W ∈ R m × u where u is the dimensionality of the latent space. Therefore, we can parameterize the latent space, what to transfer we focus on, with W which describes the u latent feature factors. Otherwise, if ϕ is nonlinear, the latent space can still be parameterized with W . Although a nonlinear ϕ is not explicitly speciﬁed in most cases such as LSDT using sparse coding, transformed target instances in the",
    "e = ϕ ( X t": "e ) ∈ R n t e × u are always available. Consequently, we can infer the similarity metric matrix [ 5 ] in the latent space, i.e., G ∈ R m × m , according to X t",
    "e ( Z t": "e ) T . The",
    "e ) T [( X t": "e ) T ] † where ( X t e ) † is the psudo-inverse of X t e . By performing LDL decomposition on G = LDL T , we infer the latent feature factor matrix W = LD 1 / 2 .",
    "Initiated by Gopalan et al., manifold ensemble algorithms": "consider that a source and a target domain share multiple subspaces (of the same dimension) as points on the Grassmann manifold between them. The representation of a target domain on u domain- invariant latent factors turns to Z t ( n u ) e",
    "= [ ϕ 1 ( X t": "e ) , · · · , ϕ n u ( X t e )] ∈ R n t e × n u u , if n u subspaces on the manifold are sampled. When all continuous subspaces on the manifold are considered, i.e., n u →∞ , Gong et al. proved that Z t ( ∞ ) e",
    "( Z t ( ∞ )": "e",
    "e G ( X t": "e ) T where G is the similarity metric matrix. For computational details of G , please refer to [ 8 ]. W = LD 1 / 2 , therefore, is also qualiﬁed to represent the latent feature factors distributed in a series of subspaces on a manifold.",
    "Learning from Experiences": "The goal here is to learn a reﬂection function f such that f ( S e , T e , W e ) can approximate l e for all experiences e ∈{ 1 , · · · , N e } . The improvement ratio l e is closely related to two aspects: 1) the difference between a source and a target domain in the shared latent space, and 2) the discriminative ability of a target domain in the latent space. The smaller difference guarantees more overlap between domains in the latent space, which signiﬁes more transferable latent feature factors and higher improvement ratios as a result. The more discriminative ability of a target domain in the latent space is also vital to improve performances. Therefore, we build f to take both aspects into consideration. The difference between a source and a target domain We follow [ 1 , 20 ] and adopt the maximum mean discrepancy (MMD) [ 11 ] to measure the difference between a source and a target domain. By mapping two domains into the reproducing kernel Hilbert space (RKHS), MMD empirically evaluates the distance between the means of instances from a source domain and a target domain: ˆ d 2",
    "e W e ) =": "1 n s e n s e X i =1",
    "ei W e ) − 1": "n t e n t e X j =1",
    "ej W e )": "2 H = 1 ( n s e ) 2 n s e X i,i ′ =1",
    "ei ′ W e )": "+ 1 ( n t e ) 2 n t e X j,j ′ =1",
    "ej ′ W e ) −": "2 n s e n t e n s e ,n t e X i,j =1",
    "ej W e ) ,": "(1) where φ maps from the u -dimensional latent space to the RKHS H and K ( · , · ) = ⟨ φ ( · ) , φ ( · ) ⟩ is the kernel function. Using different nonlinear mappings φ (or equivalently different kernels K ) leads to different MMD distances and thereby different values of f . Therefore, learning the reﬂection function f is equivalent to ﬁnding out the optimal φ (or K ) such that the MMD distance can well characterize the improvement ratio l e for all pairs of domains. Considering the difﬁculty of directly deﬁning and learning φ , we learn the optimal K alternatively. Inspired by multiple kernel MMD [ 11 ], we parameterize K as a combination of N k candidate PSD kernels, i.e., K = P N k k =1 β k K k where β k ≥ 0 , ∀ k , and learn the combination coefﬁcients β = [ β 1 , · · · , β N k ] instead. As a result, the",
    "e W e ) = P N k": "k =1 β k ˆ d 2",
    "e W e , X t": "e W e ) = E x s e x s ′",
    "ˆd e = [ ˆ d 2": "e (1) , · · · , ˆ d 2 e ( N k ) ] with ˆ d 2 e ( k ) computed using the k -th kernel K k . In this paper, we consider N k RBF kernels K k ( a , b ) = exp ( −∥ a − b ∥ 2 /δ k ) with different bandwidths by varying values of δ k . Unfortunately, the MMD only measuring the distance between the means of domains is insufﬁcient to measure the difference between two domains. The distance variance among all pairs of instances across domains is also required to fully characterize the difference, because a pair of domains with a small MMD but high variance still have a small overlap. According to [ 11 ], Equation (1) is actually the empirical estimation of d 2",
    "e , x t ′": "e ) where h k 1 is calculated using the k 1 -th kernel. Due to unknown data distributions of either source or target domains, we empirically estimate Q e to be ˆ Q e which is detailed in the supplementary material due to page limit.",
    "e W e , x s ′": "e W e ) + K ( x t",
    "e W e , x t ′": "e W e ) −K ( x s ′",
    "e W e ) .": "Consequently, the distance variance, σ 2 e , equals σ 2",
    "e x t e x t ′": "e",
    ".": "To be consistent with the MMD characterized with N k candidate kernels, we can also rewrite σ 2 e =",
    "Q e": "= cov ( h ) =   σ e (1 , 1) · · · σ e (1 ,N k ) · · · · · · · · · σ e ( N k , 1) · · · σ e ( N k ,N k )   .",
    "Each element": "σ e ( k 1 ,k 2 ) = cov ( h k 1 , h k 2 ) = E [( h k 1 − E h k 1 )( h k 2 − E h k 2 )] .",
    "The discriminative ability of a target domain": "Considering the lack of labeled data in a target domain, we resort to unlabeled data to evaluate the discriminative ability instead of using labelled data as usual. The principles of the unlabeled discriminant criterion are two-fold: 1) similar instances should also be neighbours after being embedded into the latent space; and 2) dissimilar instances should be far away. We adopt the unlabeled discriminant criterion proposed in ,",
    "e S N": "e W e ) / tr ( W T",
    "where S L": "e = P n t e j,j ′ =1 H jj ′ ( n t e ) 2 ( x t",
    "ej − x t": "ej ′ ) T , the non-local scatter covariance matrix, enforces the second principle. τ e also depends on the kernel used, since different kernels indicate different neighbour information and different degrees of similarity between neigh- boured instances. With τ e ( k ) obtained from the k -th kernel K k , the unlabeled discriminant criterion τ e can be written as τ e = P N k k =1 β k τ e ( k ) = β T τ e where τ e = [ τ e (1) , · · · , τ e ( N k ) ] .",
    "ej , x t": "ej ′ ) − H jj ′ ( n t e ) 2",
    "ej ∈N r ( x t": "ej ′ ) and",
    "ej ′ ∈N r ( x t": "ej ) 0 , otherwise .",
    "x t": "ej is the j -th instance in X t e , and tr ( · ) denotes the trace of a square matrix. If x t",
    "ej and x t": "ej ′ are mutual r -nearest neighbours to each other, the value of H jj ′ equals that of the kernel function K ( · , · ) . By maximizing the unlabeled discriminant criterion τ e , the local scatter covariance matrix guarantees",
    "the ﬁrst principle, while S N": "e = P n t e j,j ′ =1",
    "The optimization problem": "Combining the two aspects abovementioned to model the reﬂection function f , we ﬁnally formulate the optimization problem as follows, β ∗ , λ ∗ , µ ∗ , b ∗ = arg min",
    "β ,λ,µ,b": "N e X e =1 L h \u0012 β T ˆ d e + λ β T ˆ Q e β + µ",
    "β T τ e": "+ b, 1 l e \u0013 + γ 1 R ( β , λ, µ, b ) , s.t. β k ≥ 0 , ∀ k ∈{ 1 , · · · , N k } , λ ≥ 0 , µ ≥ 0 , (2) where 1 /f = β T ˆ d e + λ β T ˆ Q e β + µ β T τ e + b and L h ( · ) is the Huber regression loss [ 13 ] constraining the value of f to be as close to 1 /l e as possible. γ 1 controls the complexity of the parameters. Minimizing the difference between domains, including the MMD β T ˆ d e and the distance variance β T ˆ Q e β , and meanwhile maximizing the discriminant criterion β T τ e in the target domain will contribute a large performance improvement ratio l e (i.e., a small 1 /l e ). λ and µ balance the importance of the three terms in f , and b is the bias term.",
    "Inferring What to Transfer": "Once the L2T agent has learned the reﬂection function f ( S , T , W ; β ∗ , λ ∗ , µ ∗ , b ∗ ) , it can take advantage of the function to infer the optimal what to transfer, i.e., the latent feature factor matrix W , for a newly arrived pair of source domain S N e +1 and target domain T N e +1 . The optimal latent feature factor matrix W ∗ should maximize the value of f . To this end, we optimize the following",
    "i ′ W ) +": "1 ( n t ) 2 n t X j,j ′ =1",
    "j ′ W ) −": "2 n s n t n s ,n t X i,j =1",
    "j W )": "\u0015 , ( β ∗ ) T ˆ Q W β ∗ = 1 n 2 − 1 n X i,i ′ =1 N k X k =1 \u001a β ∗ k \u0014",
    "i W , x s": "i ′ W ) + K k ( x t",
    "i W , x t": "i ′ W ) − 2 K k ( x s",
    "i ′ W )": "\u0013\u0015 2",
    "tr ( W T S L": "k W ) . We optimize the non-convex problem (3) w.r.t W by employing a conju- gate gradient method in which the gradient is listed in the supplementary material due to page limit.",
    "Experiments": "In this section, we empirically test the performance of the proposed L2T framework.",
    "Datasets": "We evaluate the L2T framework on two image datasets, Caltech-256 [ 12 ] and Sketches [ 7 ]. Caltech-256, collected from Google Images, contains a total of 30,607 images in 256 categories. The Sketches dataset, however, consists of 20,000 unique sketches by human beings that are evenly distributed over 250 different categories. There is an overlap between the 256 categories in Caltech- 256 and the 250 categories in Sketches, e.g., “backpack” and “horse”. Obviously, the Caltech-256 images lie in a different distribution from the Sketches, so that we can regard one of them as the source domain and the other as the target domain. We construct each pair of source and target domains by randomly sampling three categories from Caltech-256 as the source domain and randomly sampling three categories from Sketches as the target domain, which we give an example in the supplementary material. Consequently, there are 20 , 000 / 250 × 3 = 720 examples in the target domain of each pair. In total, we generate 1,000 training pairs for transfer learning experiences, 500 validation pairs to determine hyperparameters of the reﬂection function, and 500 testing pairs to evaluate the reﬂection function. We characterize each image from both datasets using 4,096-dimensional features extracted by a convolutional neural network pre-trained by the ImageNet dataset.",
    "Baselines and Evaluation Metrics": "We compare the proposed L2T framework with the following nine baseline algorithms, including one without transfer learning and the other eight feature-based transfer learning algorithms in two categories, i.e., common latent space and manifold ensemble. The Original builds a model using labeled data in the target domain only. The common latent space based algorithms are listed as follows. The TCA [ 20 ] learns transferable components across domains on which the embeddings of two domains have the minimum MMD. The ITL [ 23 ] learns a common subspace where instances from both domains are distributed not only similarly but also discriminatively via optimizing an information-theoretic metric. The graph co-regularized matrix factorization proposed in [ 14 ], denoted as CMF , extracts a common subspace in which geometric structures within each domain and across domains are preserved. The LSDT [ 31 ] learns a common subspace where instances in a target domain can be sparsely reconstructed by the combined source and target instances. The self-taught learning ( STL ) [ 21 ] learns a dictionary from a source domain and obtains enriched representations of target instances based on the learned dictionary. The DIP [ 1 ] and SIE [ 2 ] learn a domain-invariant projection which can minimize the MMD and the Hellinger distance between domains, respectively. The GFK [ 8 ], a manifold ensemble based algorithm, embeds a source and a target domain onto a Grassmann manifold and projections in an inﬁnite number of subspaces along the manifold are integrated to represent the target domain. The eight feature- based transfer learning algorithms are also the base transfer learning algorithms used to generate experiences in Section 3.2. Based on feature representations obtained by different algorithms, we use the nearest-neighbor classiﬁer to perform three-class classiﬁcation for the target domain. We use the classiﬁcation accuracy on the test data of the target domain as an evaluation metric. Since target domains are at different levels of difﬁculty, accuracies are incomparable for different pairs of domains. To evaluate the L2T on different pairs of source and target domains, we adopt the performance improvement ratio deﬁned in Section 3.1 as another evaluation metric.",
    "120": "The number of labeled examples in a target domain",
    "Figure 2: Average performance improvement ratio comparison": "over 500 testing pairs of source and target domains.",
    "kernels with the bandwidth δ k in the": "range of [2 − 8 η : 2 0 . 5 η : 2 8 η ] where",
    "η =": "1 n s n t P n s ,n t",
    "j W ∥ 2": "2 following the median trick [ 10 ]. As Figure 2 shows, on average the proposed L2T framework outper- forms the baselines up to 10% when varying the number of labeled samples in the target domain. As the number of labeled examples in a target domain used for building the classiﬁer increases from 3 to 120, the performance improvement ratio becomes smaller because the classiﬁcation accuracy without",
    "L2T": "(f) caculator / straw / french-horn → doorknob / palm-tree / scissors Figure 3: Classiﬁcation accuracies on six pairs of source and target domains. transfer tends to increase. The baseline algorithms behave differently. The transferable knowledge learned by LSDT helps a target domain a lot when training examples are scarce, while GFK performs poorly until training examples become more. STL is almost the worst baseline because it learns a dictionary from the source domain only but ignores the target domain. It runs at a high risk of failure especially when two domains are distant. DIP and SIE, which minimize the MMD and Hellinger distance between domains subject to manifold constraints, are competent. Note that we have run the paired t -test between L2T and each baseline with all the p -values on the order of 10 − 12 , concluding",
    "that the L2T is signiﬁcantly superior.": "We also randomly select six of the 500 testing pairs and compare classiﬁcation accuracies by different algorithms for each pair in Figure 3. The performance of all baselines varies from pair to pair. Among all the baseline methods, TCA performs the best when transferring between domains in Figure 3a and LSDT is the most superior in Figure 3c. However, L2T consistently outperforms the baselines on all the settings. For some pairs, e.g., Figures 3a, 3c and 3f, the three classes in the target domains are comparably easy to tell apart, hence the Original without transfer can achieve even better results than some transfer learning algorithms. In this case, L2T still improves by discovering the best transferable knowledge from the source domain, especially when the number of labeled examples is small (see Figure 3c and 3f). If two domains are very related, e.g., the source with “galaxy” and “saturn” and the target with “sun” in Figure 3a, L2T even ﬁnds out more transferable knowledge and",
    "Varying the Experiences": "We further investigate how transfer learning experiences used to learn the reﬂection function inﬂuence the performance of L2T. In this experiment, we evaluate on 50 randomly sampled pairs out of the 500 testing pairs in order to efﬁciently investigate a wide range of cases in the following. The sampled set is unbiased and sufﬁcient to characterize such inﬂuence, evidenced by the asymptotic consistency of the average performance improvement ratio on the 500 pairs in Figure 2 and the 50 pairs in the last line of Table 1. First, we ﬁx the number of transfer learning experiences to be 1,000 and vary the set of base transfer learning algorithms. The results are shown in Table 1. Even with experiences generated by single base algorithm, e.g., ITL or DIP, the L2T can still learn a reﬂection function that signiﬁcantly better ( p -value < 0.05) decides what to transfer than using ITL or DIP directly. With more base algorithms involved, the transfer learning experiences are more informative to cover more situations of source-target pairs and the knowledge transferred between them. As a result, the L2T learns a better reﬂection function and thereby achieves higher performance improvement ratios. Second, we ﬁx the set of base algorithms to include all the",
    "7": "Table 1: The performance improvement ratios by varying different approaches used to generate transfer learning experiences. For example, “ITL+L2T” denotes the L2T learning from experiences generated by ITL only, and the second line of results for “ITL+L2T” is the p -value compared to ITL. # of labeled examples 3 15 30 45 60 75 90 105 120 TCA 1.0181 1.0024 0.9965 0.9973 0.9941 0.9933 0.9938 0.9927 0.9928 ITL 1.0188 1.0248 1.0250 1.0254 1.0250 1.0224 1.0232 1.0224 1.0224 CMF 0.9607 1.0203 1.0224 1.0218 1.0190 1.0158 1.0144 1.0142 1.0125 LSDT 1.0828 1.0168 0.9988 0.9940 0.9895 0.9867 0.9854 0.9834 0.9837 GFK 0.9729 1.0180 1.0232 1.0243 1.0246 1.0219 1.0239 1.0229 1.0225 STL 0.9973 0.9771 0.9715 0.9713 0.9715 0.9694 0.9705 0.9693 0.9693 DIP 1.0875 1.0633 1.0518 1.0465 1.0425 1.0372 1.0365 1.0343 1.0317 SIE 1.0745 1.0579 1.0485 1.0448 1.0412 1.0359 1.0359 1.0334 1.0318 ITL + L2T 1.1210 1.0737 1.0577 1.0506 1.0456 1.0398 1.0394 1.0361 1.0359 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0002 0.0002 DIP + L2T 1.1605 1.0927 1.0718 1.0620 1.0562 1.0500 1.0483 1.0461 1.0451 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 (LSDT/GFK /SIE) + L2T 1.1660 1.0973 1.0746 1.0652 1.0573 1.0506 1.0485 1.0451 1.0429 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 (TCA/ITL/CMF/GFK /LSDT/SIE/) + L2T 1.1712 1.0954 1.0707 1.0607 1.0529 1.0469 1.0449 1.0421 1.0416 0.0000 0.0000 0.0001 0.0001 0.0106 0.0019 0.0002 0.0047 0.0106 all + L2T 1.1872 1.1054 1.0795 1.0699 1.0616 1.0551 1.0531 1.0500 1.0502 eight baselines and vary the number of transfer learning experiences used for training. As shown in Figure 4, the average performance improvement ratio achieved by L2T tends to increase as the number of labeled examples in the target domain decreases, and more importantly it increases as the number of experiences increases. This lays the foundation for further conducting L2T in an online manner which can gradually assimilate transfer learning experiences and continuously improve.",
    "n u m": "b e r o f l a b e l e d",
    "i n": "t a r g e t d o m",
    "M": "D + D i s c r i m",
    "D i s c r i m": "i n a n t + V a r i a n c e",
    "1 2 0": "[ 2 - 1 2 : 2 1 2 [ 2 - 1 0 : 2 1 0",
    "[ 2 - 4 : 2 4": "D i f f e r e n t k e r n e l s",
    "Varying the Reﬂection Function": "We also study the inﬂuence of different conﬁgurations of the reﬂection function on the performance of L2T. First, we vary the components to be considered in building the reﬂection function f as shown in Figure 5. Considering single type, either MMD, variance, or the discriminant criterion, brings inferior performance and even negative transfer. L2T taking all the three factors into consideration outperforms the others, demonstrating that the three components are all necessary and mutually reinforcing. With all the three components included, we plot values of the learned β ∗ in the supplementary material. Second, we change different kernels used. In Figure 6, we present results by either narrowing down or extending the range [2 − 8 η : 2 0 . 5 η : 2 8 η ] . Obviously, more kernels (e.g., [2 − 12 η : 2 0 . 5 η : 2 12 η ] ), capable of encrypting better transfer learning skills in the reﬂection function, achieve larger performance improvement ratios.",
    "Conclusion": "In this paper, we propose a novel L2T framework for transfer learning which automatically determines what and how to transfer is the best between a source and a target domain by leveraging previous transfer learning experiences. In particular, L2T learns a reﬂection function mapping a pair of domains and the knowledge transferred between them to the performance improvement ratio. When a new pair of domains arrives, L2T optimizes what and how to transfer by maximizing the value of the learned reﬂection function. We believe that L2T opens a new door to improve transfer learning by leveraging transfer learning experiences. Many research issues, e.g., incorporating hierarchical latent feature factors as what to transfer and designing online L2T, can be further investigated.",
    "References": "M. Baktashmotlagh, M. T. Harandi, B. C. Lovell, and M. Salzmann. Unsupervised domain adaptation by domain invariant projection. In ICCV , pages 769–776, 2013.  M. Baktashmotlagh, M. T. Harandi, B. C. Lovell, and M. Salzmann. Domain adaptation on the",
    "statistical manifold. In CVPR , pages 2481–2488, 2014.": "J. M. Belmont, E. C. Butterﬁeld, R. P. Ferretti, et al. To secure transfer of training instruct self-management skills. In D. K. Detterman and R. J. P. Sternberg, editors, How and How Much Can Intelligence be Increased , pages 147–154. Ablex Norwood, NJ, 1982.  J. Blitzer, R. McDonald, and F. Pereira. Domain adaptation with structural correspondence",
    "learning. In EMNLP , pages 120–128, 2006.": "Q. Cao, Y. Ying, and P. Li. Similarity metric learning for face recognition. In ICCV , pages",
    "2408–2415, 2013.": "W. Dai, Q. Yang, G.-R. Xue, and Y. Yu. Boosting for transfer learning. In ICML , pages 193–200,",
    "2007.": "J. Yosinski, J. Clune, Y. Bengio, and H. Lipson. How transferable are features in deep neural",
    "SIGGRAPH) , 31(4):44:1–44:10, 2012.": "B. Gong, Y. Shi, F. Sha, and K. Grauman. Geodesic ﬂow kernel for unsupervised domain",
    "adaptation. In CVPR , pages 2066–2073, 2012.": "R. Gopalan, R. Li, and R. Chellappa. Domain adaptation for object recognition: An unsupervised",
    "approach. In ICCV , pages 999–1006, 2011.": "A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Schölkopf, and A. Smola. A kernel two-sample",
    "test. JMLR , 13(Mar):723–773, 2012.": "A. Gretton, D. Sejdinovic, H. Strathmann, S. Balakrishnan, M. Pontil, K. Fukumizu, and B. K. Sriperumbudur. Optimal kernel choice for large-scale two-sample tests. In NIPS , pages",
    "1205–1213, 2012.": "G. Grifﬁn, A. Holub, and P. Perona. Caltech-256 object category dataset. 2007.  P. J. Huber et al. Robust estimation of a location parameter. The Annals of Mathematical",
    "Statistics , 35(1):73–101, 1964.": "M. Long, J. Wang, G. Ding, D. Shen, and Q. Yang.",
    "regularization. TKDE , 26(7):1805–1818, 2014.": "M. Long, Y. Cao, J. Wang, and M. Jordan. Learning transferable features with deep adaptation",
    "networks. In ICML , pages 97–105, 2015.": "A. R. Luria. Cognitive Development: Its Cultural and Social Foundations . Harvard University",
    "Press, 1976.": "A. Maurer. Algorithmic stability and meta-learning. JMLR , 6(Jun):967–994, 2005.  K. Mo, S. Li, Y. Zhang, J. Li, and Q. Yang. Personalizing a dialogue system with transfer",
    "learning. arXiv preprint arXiv:1610.02891 , 2016.": "S. J. Pan and Q. Yang. A survey on transfer learning. TKDE , 22(10):1345–1359, 2010.  S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang. Domain adaptation via transfer component",
    "analysis. TNN , 22(2):199–210, 2011.": "R. Raina, A. Battle, H. Lee, B. Packer, and A. Y. Ng. Self-taught learning: transfer learning from unlabeled data. In ICML , pages 759–766, 2007.  P. Ruvolo and E. Eaton. ELLA: An efﬁcient lifelong learning algorithm. In ICML , pages",
    "507–515, 2013.": "Y. Shi and F. Sha. Information-theoretical learning of discriminative clusters for unsupervised",
    "domain adaptation. In ICML , pages 1079–1086, 2012.": "S. Thrun and L. Pratt. Learning to learn . Springer Science & Business Media, 1998.  T. Tommasi, F. Orabona, and B. Caputo. Learning categories from few examples with multi",
    "9": "E. Tzeng, J. Hoffman, T. Darrell, and K. Saenko. Simultaneous deep transfer across domains",
    "and tasks. In ICCV , pages 4068–4076, 2015.": "Y. Wei, Y. Zheng, and Q. Yang. Transfer knowledge between cities. In KDD , pages 1905–1914,",
    "2016.": "J. Yang, R. Yan, and A. G. Hauptmann. Adapting SVM classiﬁers to data with shifted distribu-",
    "tions. In ICDM , pages 69–76, 2007.": "J. Yang, D. Zhang, J.-y. Yang, and B. Niu. Globally maximizing, locally minimizing: unsu- pervised discriminant projection with applications to face and palm biometrics. TPAMI , 29(4),",
    "networks? In NIPS , pages 3320–3328, 2014.": "L. Zhang, W. Zuo, and D. Zhang. LSDT: Latent sparse domain transfer learning for visual",
    "1": "n 2 − 1 N k",
    "X": "i,i ′ =1",
    "− 1": "n 2 n",
    "where n = min( n s": "e , n t e ) .",
    "∂ L": "∂ W = ∂ ( β ∗ ) T ˆd W",
    "∂ W": "− µ ∗",
    "among which": "∂ ( β ∗ ) T ˆ d W",
    "=": "N k",
    "ˆ K ss": "k ( i,i ′ ) = − 2 δ k",
    "ˆ K tt": "k ( i,i ′ ) = − 2 δ k",
    "ˆ K st": "k ( i,i ′ ) = − 2 δ k",
    "(6)": "∂ ( β ∗ ) T ˆ Q W β ∗",
    "−": "n",
    "k W )] S N": "k − 2[ tr ( W T S N",
    "k W )] S L": "k",
    "where ˆ K ss": "k ( i,i ′ ) , ˆ K tt k ( j,j ′ ) , and ˆ K st k ( i,j ) depending on the kernel function are calculated as follows,",
    "ˆ B k ( i,i ′ ) =": "N k",
    "3": "Exemplar of A Pair of Source and Target Domains",
    "Target domain": "Figure 7: One example pair of source and target domains.",
    "Coefﬁcients of RBF Kernels": "We plot the values of the coefﬁcients for N k RBF kernels, i.e., β k for k = { 1 , · · · , N k } in Figure 8. Note that we use 33 RBF kernels as stated in the paper.",
    "Values of k": "Figure 8: Values of the coefﬁcients for all N k RBF kernels.",
    "Discussion on l e in Equation (2)": "l e , the performance improvement ratio, heavily depends on the number of labeled examples in the target domain T e , i.e., n t le . A smaller number of target labeled examples tends to produce a larger performance improvement ratio, and vice versa. Since the n t le varies from experience to experience, we adopt a transformed ˆ l e instead of l e to train the reﬂection function in Equation (2). The ˆ l e is expected to be the expectation of the performance improvement ratio in the range of [ p, q ] for the e -th experience, where p and q are the minimum and maximum number of target labeled examples. To",
    "12": "compute the expectation, we ﬁrst assume that the performance improvement ratio with regard to the number of target labeled examples follows the following monotonically decreasing function,",
    "(13)": "where a e and b are two parameters deciding the function. a e is conditioned on a speciﬁc experience but b is shared across all experiences. Note that f ( n t le ) = l e . As a consequence, we can obtain the",
    "expected performance improvement ratio as:": "ˆ l e =",
    "q − p": "Z q p",
    "a e + bx dx = 1": "a e",
    "b": "a e ( q − p ) log q + b",
    "(14)": "Combining with the fact that f ( n t le ) = n t le a e + bn t le = l e , we can ﬁnally obtain the corrected ˆ l e as, ˆ l e = l e n t le + b n t le",
    ",": "where the parameter b can be learned simultaneously during optimizing the objective (2)."
  },
  "tables": [
    {
      "page": 6,
      "table_index": 0,
      "content": [
        [
          "TCA LSDT DIP\noitar\nITL GFK SIE\n1.15 CMF STL L2T\ntnemevorpmi\n1.1\n1.05\n1 ecnamrofreP\n0.95\n3 15 30 45 60 75 90 105 120\nThe number of labeled examples in a target domain",
          "",
          "",
          "TCA\nITL",
          "",
          "LSDT\nGFK",
          "",
          "DIP\nSIE",
          "",
          ""
        ],
        [
          null,
          "",
          "",
          "CMF",
          "",
          "STL",
          "",
          "L2T",
          "",
          ""
        ],
        [
          null,
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        [
          null,
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        [
          null,
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ]
      ]
    },
    {
      "page": 7,
      "table_index": 0,
      "content": [
        [
          "0.9\n0.85\nycarucca\n0.8\n0.75\n0.7 noitacifissalC Original GFK\nTCA STL\n0.65 ITL DIP\nCMF SIE\n0.6 LSDT L2T\n0.55\n0 15 30 45 60 75 90 105 120\nThe number of labeled examples\nin a target domain",
          "ycarucca\nnoitacifissalC",
          "0.9\n0.85\n0.8\n0.75\nOriginal GFK\n0.7\nTCA STL\n0.65 ITL DIP\nCMF SIE\n0.6 LSDT L2T\n0.55\n0 15 30 45 60 75 90 105 120\nThe number of labeled examples\nin a target domain",
          "ycarucca\nnoitacifissalC",
          "1\n0.95\n0.9\nOriginal GFK\n0.85 TCA STL\nITL DIP\n0.8 CMF SIE\nLSDT L2T\n0.75\n0 15 30 45 60 75 90 105 120\nThe number of labeled examples\nin a target domain"
        ]
      ]
    },
    {
      "page": 7,
      "table_index": 1,
      "content": [
        [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        [
          "",
          "",
          "",
          "I",
          "Origi\nTCA\nTL",
          "nal",
          "",
          "GFK\nSTL\nDIP"
        ],
        [
          "",
          "",
          "",
          "",
          "CMF\nLSDT",
          "",
          "",
          "SIE\nL2T"
        ]
      ]
    },
    {
      "page": 7,
      "table_index": 2,
      "content": [
        [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        [
          "",
          "",
          "",
          "",
          "Origi\nTCA\nITL",
          "nal",
          "",
          "GFK\nSTL\nDIP"
        ],
        [
          "",
          "",
          "",
          "",
          "CMF\nLSDT",
          "",
          "",
          "SIE\nL2T"
        ]
      ]
    },
    {
      "page": 7,
      "table_index": 3,
      "content": [
        [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        [
          "",
          "",
          "",
          "",
          "Origi\nTCA\nITL",
          "nal",
          "",
          "GFK\nSTL\nDIP"
        ],
        [
          "",
          "",
          "",
          "",
          "CMF\nLSDT",
          "",
          "",
          "SIE\nL2T"
        ]
      ]
    },
    {
      "page": 7,
      "table_index": 4,
      "content": [
        [
          "0.95\n0.9\nycarucca\n0.85\n0.8\n0.75 noitacifissalC Original GFK\nTCA STL\n0.7 ITL DIP\nCMF SIE\n0.65\nLSDT L2T\n0.6\n0 15 30 45 60 75 90 105 120\nThe number of labeled examples\nin a target domain",
          "ycarucca\nnoitacifissalC",
          "bush/person/walkie-talkie\n0.9\n0.85\n0.8\n0.75 Original GFK\nTCA STL\n0.7\nITL DIP\n0.65 CMF SIE\nLSDT L2T\n0.6\n0 15 30 45 60 75 90 105 120\nThe number of labeled examples\nin a target domain",
          "ycarucca\nnoitacifissalC",
          "0.95\n0.9\n0.85\n0.8\n0.75 Original GFK\nTCA STL\n0.7 ITL DIP\nCMF SIE\n0.65 LSDT L2T\n0.6\n0 15 30 45 60 75 90 105 120\nThe number of labeled examples\nin a target domain"
        ]
      ]
    },
    {
      "page": 7,
      "table_index": 5,
      "content": [
        [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        [
          "",
          "",
          "",
          "",
          "Origi\nTCA",
          "nal",
          "",
          "GFK\nSTL"
        ],
        [
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          null
        ],
        [
          "",
          "",
          "",
          "",
          "ITL\nCMF\nLSDT",
          "",
          "",
          "DIP\nSIE\nL2T"
        ]
      ]
    },
    {
      "page": 7,
      "table_index": 6,
      "content": [
        [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        [
          "",
          "",
          "",
          "",
          "Origi\nTCA",
          "nal",
          "",
          "GFK\nSTL"
        ],
        [
          "",
          "",
          "",
          "I",
          "TL\nCMF\nLSDT",
          "",
          "",
          "DIP\nSIE\nL2T"
        ],
        [
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          null
        ]
      ]
    },
    {
      "page": 7,
      "table_index": 7,
      "content": [
        [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        [
          "",
          "",
          "",
          "",
          "Origi\nTCA",
          "nal",
          "",
          "GFK\nSTL"
        ],
        [
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          null
        ],
        [
          "",
          "",
          "",
          "I",
          "TL\nCMF\nLSDT",
          "",
          "",
          "DIP\nSIE\nL2T"
        ]
      ]
    },
    {
      "page": 12,
      "table_index": 0,
      "content": [
        [
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        [
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        [
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        [
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ]
      ]
    }
  ],
  "images": [
    "processed/images/1708.05629v1_page3_img0.png",
    "processed/images/1708.05629v1_page12_img0.png",
    "processed/images/1708.05629v1_page12_img1.png",
    "processed/images/1708.05629v1_page12_img2.png",
    "processed/images/1708.05629v1_page12_img3.png",
    "processed/images/1708.05629v1_page12_img4.png",
    "processed/images/1708.05629v1_page12_img5.png",
    "processed/images/1708.05629v1_page12_img6.png",
    "processed/images/1708.05629v1_page12_img7.png",
    "processed/images/1708.05629v1_page12_img8.png",
    "processed/images/1708.05629v1_page12_img9.png",
    "processed/images/1708.05629v1_page12_img10.png",
    "processed/images/1708.05629v1_page12_img11.png",
    "processed/images/1708.05629v1_page12_img12.png",
    "processed/images/1708.05629v1_page12_img13.png"
  ],
  "status": "completed"
}