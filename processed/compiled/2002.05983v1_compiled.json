{
  "metadata": {
    "title": "High-Performance High-Order Stencil Computation on FPGAs Using OpenCL",
    "authors": [
      "Hamid Reza Zohouri",
      "Artur Podobas",
      "Satoshi Matsuoka"
    ],
    "abstract": "In this paper we evaluate the performance of FPGAs for high-order stencil computation using High-Level Synthesis. We show that despite the higher computation intensity and on-chip memory requirement of such stencils compared to first-order ones, our design technique with combined spatial and temporal blocking remains effective. This allows us to reach similar, or even higher, compute performance compared to first-order stencils. We use an OpenCL-based design that, apart from parameterizing performance knobs, also parameterizes the stencil radius. Furthermore, we show that our performance model exhibits the same accuracy as first-order stencils in predicting the performance of high-order ones. On an Intel Arria 10 GX 1150 device, for 2D and 3D star-shaped stencils, we achieve over 700 and 270 GFLOP/s of compute performance, respectively, up to a stencil radius of four. These results outperform the state-of-the-art YASK framework on a modern Xeon for 2D and 3D stencils, and outperform a modern Xeon Phi for 2D stencils, while achieving competitive performance in 3D. Furthermore, our FPGA design achieves better power efficiency in almost all cases.",
    "published": "",
    "arxiv_id": "2002.05983v1",
    "categories": [
      "cs.DC"
    ],
    "pdf_url": "http://arxiv.org/pdf/2002.05983v1",
    "pdf_file": "data/pdfs/2002.05983v1.pdf",
    "pdf_filename": "2002.05983v1.pdf"
  },
  "processing_info": {
    "processed_at": "2025-10-28T10:41:13.192891",
    "is_large_pdf": false,
    "sections_found": 17,
    "tables_found": 8,
    "images_found": 10
  },
  "sections_text": {
    "High-Performance High-Order Stencil Computation": "on FPGAs Using OpenCL",
    "Hamid Reza Zohouri, Artur Podobas, Satoshi Matsuoka": "Tokyo Institute of Technology, Tokyo, Japan {zohouri.h.aa@m, podobas.a.aa@m, matsu@is}.titech.ac.jp Abstract â€”In this paper we evaluate the performance of FPGAs for high-order stencil computation using High-Level Synthesis. We show that despite the higher computation intensity and onchip memory requirement of such stencils compared to first-order ones, our design technique with combined spatial and temporal blocking remains effective. This allows us to reach similar, or even higher, compute performance compared to first-order stencils. We use an OpenCL-based design that, apart from parameterizing performance knobs, also parameterizes the stencil radius. Furthermore, we show that our performance model exhibits the same accuracy as first-order stencils in predicting the performance of high-order ones. On an Intel Arria GX device, for 2D and 3D star-shaped stencils, we achieve over and GFLOP/s of compute performance, respectively, up to a stencil radius of four. These results outperform the state-of-theart YASK framework on a modern Xeon for 2D and 3D stencils, and outperform a modern Xeon Phi for 2D stencils, while achieving competitive performance in 3D. Furthermore, our FPGA design achieves better power efficiency in almost all cases. Keywordsâ€”FPGA, OpenCL, High-Order Stencil I. I NTRODUCTION The stencil computation pattern is widely used in HighPerformance Computing (HPC) for weather prediction, seismic and wave propagation simulation, fluid simulations, image processing and convolutional neural networks. This computation pattern involves traversing a multi-dimensional grid, cell by cell, and calculating a weighted sum based on the value of the cell and its neighbors up to a certain distance that is called the radius of the stencil. First-order stencils are regularly used in image processing and convolutional neural networks. However, many scientific applications require high-order stencils in their computation. Three out of the nine nominees for the ACM Gordon Bell award in the past two years accelerated applications that involved high-order stencil computation [1, 2, 3], with both of the winners being among them. Compared to first-order (Fig. 1), the difficulty for implementing high-order stencils is two-fold: these stencils are more compute-intensive due to more computation per cell update, and they require more on-chip memory since neighbors are further apart in space. In the past few years, leveraging High-Level Synthesis (HLS) on FPGAs has gained significant traction since it allows programmers with no knowledge of Hardware Description Languages (HDL) to be able to take advantage of the programmability and better power efficiency of FPGAs [4, 5]. This initiative was further accelerated by the adoption of the OpenCL programming language by both Altera (now part of Intel) and Xilinx . In our previous work , we studied the optimization of first-order star-shaped 2D and 3D stencils on FPGAs using Intel FPGA SDK for OpenCL. By combining spatial and temporal blocking, unlike many previous works on FPGAs, we achieved higher performance than the limit imposed by the external memory bandwidth, without restricting input size. Furthermore, using multiple HLS-specific optimizations allowed us to overcome the issues arisen from the added design complexity due to multiple levels of blocking. In this paper, we build upon our previous work to accelerate high-order stencils on FPGAs. We modify our OpenCL kernel so that apart from performance knobs (block size, vector size, and degree of temporal parallelism), stencil radius is also parameterized. This allows us to synthesize high-order stencils on our FPGA platform just by changing one compilation parameter. Our contributions are as follows: â€¢ We optimize second to fourth-order 2D and 3D stencils using one OpenCL kernel for each, and, to the best of our knowledge, report the highest performance for high-order stencil computation on a single FPGA. â€¢ We show that our combined spatial and temporal blocking",
    "Methodology": "remains effective for high-order stencils, allowing us to quickly choose the best performance parameters in every case. Regardless of stencil order, for 2D and 3D star-shaped stencils, we achieved over and GFLOP/s of compute performance, respectively, on an Intel Arria GX device. This level of performance is enough to compete with other hardware for high-order 2D stencil computation. However, even though temporal blocking is also effective for high-order 3D stencil computation on FPGAs, it is not enough to compete with high-bandwidth devices like Xeon Phi or modern GPUs. We conclude that for high-order 3D stencil computation, having high-bandwidth memory coupled with an efficient memory",
    "1 We consider stencil radius and order to be equal": "scientific publications, stencil order is equal to double the radius and hence, what we call â€œfirst-orderâ€ is called â€œsecond-order.â€ Fig. 1. First-order and third-order star-shaped 3D stencils II. R ELATED WORK Stencil computation, due to its importance, has been widely studied on different platforms. One of the most prominent works was done by Intel in , where they describe the 3.5D blocking compared to what can be obtained with temporal blocking but limited external memory bandwidth. This issue will become even more pronounced for the next-generation Stratix GX Read PE nWrite PE nPE nCompute",
    "Stencil Accelerator": "Fig. 2. Design overview, taken from â€¢ Shift register size and addresses for access to different neighboring cells in the shift register were parameterized with respect to stencil radius. â€¢ Comparisons with block and dimension variables were modified to take stencil radius into account. The exit condition for the main loop, which is compared with the global index, was also updated. â€¢ Boundary conditions were modified so that all out-ofbound neighboring cells correctly fall back on the cell that is on the border. Since this could not be efficiently realized using unrolled loops and branches, we created a code generator that generates and inserts the boundary conditions into the base kernel. â€¢ Support for non-square block sizes was added to allow more room for parameter tuning for high-order stencils Since stencil radius had already been considered in our performance model in , no further changes were required in",
    "A. Benchmarks": "We modified the baseline 3D stencil implementation from , available at , to support high-order stencils. To achieve this, we changed the computation in the main loop to reflect the following equation: ğ‘“ ğ‘ ğ‘¡+ = ğ‘ ğ‘ ğ‘“ ğ‘ ğ‘¡ + âˆ‘ (ğ‘ ğ‘¤ ğ‘“ ğ‘¤,ğ‘– ğ‘¡ + ğ‘ ğ‘’ ğ‘“ ğ‘’,ğ‘– ğ‘¡ + ğ‘ ğ‘  ğ‘“ ğ‘ ,ğ‘– ğ‘¡ + ğ‘ ğ‘› ğ‘“ ğ‘›,ğ‘– ğ‘¡ + ğ‘Ÿğ‘ğ‘‘ ğ‘–= ğ‘ ğ‘ ğ‘“ ğ‘,ğ‘– ğ‘¡ + ğ‘ ğ‘ ğ‘“ ğ‘,ğ‘– ğ‘¡ ) (ï€±) In (1), ğ‘“ ğ‘¥ ğ‘¡ refers to value in position x at time t , ğ‘ ğ‘¥ refers to the coefficient for the value in position x, rad is the stencil radius/order, ğ‘¥âˆˆ {Center, West, East, South, North, Below, Above}, and the set { x,i } refers to the i th neighbor cell in the direction of x . In this particular implementation, the coefficient for all the neighbors in a given direction is fixed; however, since we disallow reordering of floating-point operations, the coefficient is not shared and hence, the number of floating-point operations per cell update is equal to Ã— ğ‘Ÿğ‘ğ‘‘+ , with Ã— ğ‘Ÿğ‘ğ‘‘+ floating-point multiplications (FMUL) and Ã— ğ‘Ÿğ‘ğ‘‘ floating-point addition operations (FADD). Optimizing this implementation is equal to optimizing the worst-case scenario where all the coefficients for all of the neighboring cells are different. The 2D version of this kernel uses the same equation, but without the Above and Below neighbors. Table I shows the computational characteristics of our benchmarks. The number of bytes per cell update is calculated with the assumption of full spatial reuse (no redundant memory accesses). It is evident from the table that the stencil FLOP to byte ratio increases with its radius, which makes high-order stencils less memory-bound than lower order ones. B. Hardware and Software Setup Our FPGA platform is a Nallatech 385A board with an Arria",
    "10 GX 1150 device and two banks of DDR4 memory operating": "at MHz ( MHz double data-rate). We used Quartus and Intel OpenCL SDK for OpenCL v16.1. for kernel compilations. We avoided newer versions of Quartus (v17. and v17.1) since they reliably resulted in lower performance (2030% lower) and higher area utilization (5-10% more Block RAMs) for the same kernel. For power measurement, we periodically ( ms interval) read the power sensor that is available on the board using the API provided by the board manufacturer, and average the values during kernel execution. For comparison purposes, we used a 12-core Intel Xeon E5v4 CPU, and a 64-core Intel Xeon Phi 7210F processor. The Xeon processor is accompanied by quad-channel DDR4 memory operating at MHz. The Xeon Phi processor was set to operate in flat mode; however, we used numactl to set the faster MCDRAM memory as the preferred memory, and made sure the stencil input fits in this memory. All hyperthreads were used on both processors. We implemented our stencils, both in 2D and 3D, using the state-of-the-art YASK framework .",
    "Cell Update": "FLOP Byte 1. 2. 3. 4. 1. 3. 4. 6. for single-precision floating-point computation. The FLOP to Byte column refers to the ratio of compute performance to external memory bandwidth of each device. Without temporal blocking, computation of a specific stencil will be memory-bound on a given device, if the FLOP to Byte ratio of the stencil is lower than that of the device. Comparing the FLOP to Byte ratios between Table I and Table II, we can conclude that for every stencil order, computation will be memory-bound on all of our hardware. Since the FPGA platform has the highest FLOP to Byte ratio, it is the most bandwidthstarved platform and hence, is expected to have the worst computational efficiency. However, due to effectiveness of temporal blocking on FPGAs, we expect to be able to break away from the memory-bound nature of stencil computation on this platform.",
    "C. Benchmark Settings": "For FPGA benchmarks, to minimize redundant computation in the last spatial block and fully show the potential of the device, we set the size of input dimensions to a value that is a multiple of the size of the respective compute block dimension. If we denote the size of the compute block in each dimension by ğ‘ğ‘ ğ‘–ğ‘§ğ‘’ {ğ‘¥|ğ‘¦} , we have (from ): ğ‘ğ‘ ğ‘–ğ‘§ğ‘’ {ğ‘¥|ğ‘¦} = ğ‘ğ‘ ğ‘–ğ‘§ğ‘’ {ğ‘¥|ğ‘¦} âˆ’ Ã— (ğ‘ğ‘ğ‘Ÿ ğ‘¡ğ‘–ğ‘šğ‘’ Ã— ğ‘Ÿğ‘ğ‘‘) (ï€²) In (2), ğ‘ğ‘ ğ‘–ğ‘§ğ‘’ {ğ‘¥|ğ‘¦} is the size of the spatial block in each dimension, and ğ‘ğ‘ğ‘Ÿ ğ‘¡ğ‘–ğ‘šğ‘’ denotes the degree of temporal parallelism. For 2D stencils, the selected value was between and , and for 3D stencils, it was between and . Exact numbers are reported in Section VI.A. Furthermore, we set the number of iterations to 1000, which resulted in a minimum run time of seconds for 2D, and seconds for 3D stencils. The amount of variation that was observed during FPGA execution was less than ms. For benchmarks on the Xeon and Xeon Phi processors, we tried multiple different inputs sizes and selected values that gave the best performance. On the Xeon processor, these values were and , for 2D and 3D stencils, respectively, and for the Xeon Phi processor, they were and . All benchmarks used iterations, for a minimum run time of seconds on the Xeon, and seconds on the Xeon Phi processor. All of our kernels use single-precision floating-point values. For the FPGA platform, we only measure kernel execution time and ignore data transfer time between host and device. For Xeon and Xeon Phi, we use the timing and performance values reported by YASK, which only include the stencil computation and ignore initialization steps. Our power measurement on YASK starts and ends with the built-in profiler. All experiments are repeated five times, and all values are averaged. We calculate performance in terms of number of cells updated per seconds (GCell/s) as follows: ğ‘Ÿğ‘¢ğ‘›_ğ‘¡ğ‘–ğ‘šğ‘’ ğ‘›ğ‘¢ğ‘š_ğ‘–ğ‘›ğ‘ğ‘¢ğ‘¡_ğ‘”ğ‘Ÿğ‘–ğ‘‘_ğ‘ğ‘’ğ‘™ğ‘™ğ‘  Ã— ğ‘–ğ‘¡ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘›_ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ (ï€³) Computation performance (GFLOP/s) and throughput (GB/s) values are calculated by multiplying the GCell/s value by the FLOP and byte per cell update values of the stencil, respectively. Redundant computation and memory accesses are not taken into account for the reported performance values. V. P ERFORMANCE T UNING",
    "A. Fpga": "To tune performance on our FPGA platform, we first need to calculate the number of DSPs that are needed to implement each cell update. On the Arria FPGA, each DSP is capable of performing one Fused Multiply and Add (FMA) operation. For each cell update in 2D stencils, Ã— ğ‘Ÿğ‘ğ‘‘+ multiplications and Ã— ğ‘Ÿğ‘ğ‘‘ additions are required. For 3D stencils, Ã— ğ‘Ÿğ‘ğ‘‘+ multiplications and Ã— ğ‘Ÿğ‘ğ‘‘ additions are required. In all cases, each multiplication can be fused with the addition that follows it, except the last one. Hence, Ã— ğ‘Ÿğ‘ğ‘‘+ and Ã— ğ‘Ÿğ‘ğ‘‘+ DSPs are required to implement one cell update, for 2D and 3D stencils, respectively. It is worth noting that with shared coefficients, only the number of FMUL operations will be reduced and the number of FADD operations will stay the same. Because of this, DSP utilization will only be reduced by one per cell update, since still one DSP will be required whether the operation is FMA or FADD. Since the Arria GX FPGA has DSPs, we can calculate the total degree of parallelism as: ğ‘ğ‘ğ‘Ÿ ğ‘¡ğ‘œğ‘¡ğ‘ğ‘™ = { 4Ã—ğ‘Ÿğ‘ğ‘‘+ âŒ‹ 2ğ· 6Ã—ğ‘Ÿğ‘ğ‘‘+ âŒ‹ 3ğ· (ï€´) Then we have: ğ‘ğ‘ğ‘Ÿ ğ‘¡ğ‘–ğ‘šğ‘’ Ã— ğ‘ğ‘ğ‘Ÿ ğ‘£ğ‘’ğ‘ â‰¤ğ‘ğ‘ğ‘Ÿ ğ‘¡ğ‘œğ‘¡ğ‘ğ‘™ (ï€µ) Here, ğ‘ğ‘ğ‘Ÿ ğ‘¡ğ‘–ğ‘šğ‘’ and ğ‘ğ‘ğ‘Ÿ ğ‘£ğ‘’ğ‘ refer to degree of temporal parallelism (equal to numbers of replicated PEs) and vector size, respectively. We restrict ğ‘ğ‘ğ‘Ÿ ğ‘£ğ‘’ğ‘ to values that are a multiple of two, since the size of ports to memory are limited to such values. We also restrict ğ‘ğ‘ğ‘Ÿ ğ‘¡ğ‘–ğ‘šğ‘’ to values that follow (6) to allow best alignment for accesses to external memory (from ): TABLE II. H ARDWARE C HARACTERISTICS Device Performance (GFLOP/s) Bandwidth (GB/s) TDP (Watt) Node (nm) FLOP Arria GX 34. 42. Xeon E5v4 76. 9. Xeon Phi 7210F 13. GTX 192. 8. GTX",
    "980 Ti": "393. 30. 1. 0. 627. 25. 3. 0. 708. 19. 3. 0. 793. 16. 3. 0. Tesla P100 842. 64. 4. 0. 1344. 53. 7. 0. 1517. 41. 8. 0. 1699. 34. 9. 0. TABLE IV. 2D S TENCIL P ERFORMANCE R ESULTS rad Performance (GFLOP/s) Performance (GCell/s) Estimated Performance (GB/s) (GB/s|GFLOP/s|GCell/s) f max (MHz) Logic Memory (Bits|Blocks) DSP Power (Watt)",
    "Power Efficiency": "(GFLOP/s/Watt) Roofline Ratio Arria GX 758. 84. 10. 19. 764. 44. 10. 10. 703. 28. 10. 6. 719. 21. 10. 5. Xeon E5v4 45. 5. 0. 0. 85. 5. 0. 0. 124. 4. 1. 0. 165. 5. 1. 0. Xeon Phi 7210F 222. 24. 1. 0. 398. 23. 1. 0. 592. 23. 2. 0. 759. 23. 3. 0. blocking proved to be ineffective on these devices. On the other hand, the FPGA can achieve multiple times higher computation throughput than its memory bandwidth, due to the effectiveness of temporal blocking on this platform. For the fourth-order stencil, even with temporal blocking, the achieved computation throughput on the FPGA is lower than the utilized memory bandwidth on the Xeon Phi device and hence, the Xeon Phi achieves better performance. We expect the Xeon Phi to be faster than the Arria FPGA also for stencil orders above four. For 3D stencils, we also include results from and",
    "22.24 GB/s of streaming bandwidth, while the system they use": "only provides 6. GB/s. This assumption is not reasonable since streaming bandwidth, whether it is from FPGA external memory or the link between host and the FPGA, will remain the limiting factor in performance of stencil computation for the foreseeable future, and that is why temporal blocking is used. In their case, since temporal blocking is not employed, the roofline of the performance they can achieve in practice is only 0. GCell/s. Compared to , since they also share coefficients, we will use the GCell/s metric for performance comparison. They report",
    "1.54 GCell/s for a third-order 3D star-shaped stencil, while we": "achieve 7. GCell/s, which is over times higher. They also estimate that a future FPGA device that is four times larger than a VirtexSX475T FPGA (roughly the size of the modern Virtex Ultrascale+ VU11P device) can achieve close to GCell/s, while we already achieve higher performance. VII. C ONCLUSION In this work, we studied the performance and power efficiency of high-order stencil computation on FPGAs using combined spatial and temporal blocking. We showed that even though temporal blocking exhibits limited or no scalability on CPU, GPU and Xeon Phi platforms, good scalability could be Fig. 4. Performance of 3D stencil computation in GCell/s E5v4 GTX 980Ti",
    "Tesla P100": "Performance (GFLOP/s) First-order Second-order Third-order Forth-order achieved on FPGAs even for high-order stencils. This advantage allowed us to scale the compute performance of high-order stencils to close to what could be achieved with first-order",
    "2800 FPGA since the FLOP to byte ratio goes beyond 100 (with": "banks of DDR4memory), but the Stratix MX series with HBM memory will likely not suffer from this problem. A CKNOWLEDGMENT This work was supported by MEXT, JST-CREST under Grant Number JPMJCR1303, JSPS KAKENHI under Grant Number JP16F16764, the JSPS Postdoctoral fellowship under grant P16764, and performed under the auspices of the Realworld Big-Data Computation Open Innovation Laboratory, Japan. We would like to thank Intel for donating licenses for their FPGA toolchain through their university program. R EFERENCES H. Fu et al., â€œ18.9-Pflops nonlinear earthquake simulation on Sunway TaihuLight,â€ in Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SCâ€™17) , Denver, CO, USA, 2017, pp. 2:1-2:12. C. Yang et al., â€œ10M-Core Scalable Fully-Implicit Solver for Nonhydrostatic Atmospheric Dynamics,â€ International Conference for High Performance Computing, Networking, Storage and Analysis (SCâ€™16) , Salt Lake City, UT, USA, 2016, pp. 57-68. T. Muranushi et al ., â€œSimulations of Below-Ground Dynamics of Fungi:",
    "1.184 Pflops Attained by Automated Generation and Autotuning of": "Temporal Blocking Codes,â€ International Conference for High Performance Computing, Networking, Storage and Analysis (SCâ€™16) , Salt Lake City, UT, USA, 2016, pp. 23-33. H. R. Zohouri, N. Maruyama, A. Smith, M. Matsuda and S. Matsuoka, â€œEvaluating and Optimizing OpenCL Kernels for High Performance Computing with FPGAs,â€ International Conference for High Performance Computing, Networking, Storage and Analysis (SCâ€™16) , Salt Lake City, UT, USA, 2016, pp. 409-420. U. Aydonat, S. Oâ€™Connell, D. Capalija, A. C. Ling, and G. R. Chiu, â€œAn OpenCLâ„¢ Deep Learning Accelerator on Arria 10,â€ in Proceedings of the ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGAâ€™17) , Monterey, CA, USA, 2017, pp. 55-64. T. S. Czajkowski et al ., â€œFrom OpenCL to High-Performance Hardware on FPGAs,â€ 22nd International Conference on Field Programmable Logic and Applications (FPLâ€™12) , Oslo, Norway, 2012, pp. 531-534. Xilinx, Inc., (2017). UG1023: SDAccel Environment User Guide (v2017.4) . [online] Available : https://www.xilinx.com/support/document ation/sw_manuals/xilinx2017_4/ug1023-sdaccel-user-guide.pdf. H. R. Zohouri, A. Podobas, S. Matsuoka, â€œCombined Spatial and Temporal Blocking for High-Performance Stencil Computation on FPGAs Using OpenCL,â€ in Proceedings of the ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGAâ€™18) , Monterey, CA, USA, 2018, pp. 153-162. C. Yount, J. Tobin, A. Breuer and A. Duran, â€œYASKâ€”Yet Another Stencil Kernel: A Framework for HPC Stencil Code-Generation and Tuning,â€ Sixth International Workshop on Domain-Specific Languages and High-Level Frameworks for High Performance Computing (WOLFHPC) , Salt Lake City, UT, 2016, pp. 30-39. W. T. Tang et al ., â€œOptimizing and Auto-Tuning Iterative Stencil Loops for GPUs with the In-Plane Method,â€ IEEE 27th International Symposium on Parallel and Distributed Processing (IPDSPâ€™13) , Boston, MA, USA, 2013, pp. 452-462. A. Nguyen, N. Satish, J. Chhugani, C. Kim and P. Dubey, â€œ3.5-D Blocking Optimization for Stencil Computations on Modern CPUs and GPUs,â€ International Conference for High Performance Computing, Networking, Storage and Analysis (SCâ€™10) , New Orleans, LA, USA, 2010, pp. 1-13. N. Maruyama and T. Aoki, â€œOptimizing Stencil Computations for NVIDIA Kepler GPUs,â€ in Proceedings of the 1st International Workshop on High-Performance Stencil Computations (HiStencilsâ€™14) , Vienna, Austria, 2014, pp. 89-95. C. Yount, â€œVector Folding: Improving Stencil Performance via Multidimensional SIMD-vector Representation,â€ IEEE 17th International Conference on High Performance Computing and Communications, IEEE 7th International Symposium on Cyberspace Safety and Security, and IEEE 12th International Conference on Embedded Software and Systems , New York, NY, USA, 2015, pp. 865-870. T. Kenter, J. FÃ¶rstner and C. Plessl, â€œFlexible FPGA design for FDTD using OpenCL,â€ 27th International Conference on Field Programmable Logic and Applications (FPLâ€™17) , Ghent, Belgium, 2017, pp. 1-7. K. Sano and S. Yamamoto, â€œFPGA-Based Scalable and Power-Efficient Fluid Simulation using Floating-Point DSP Blocks,â€ in IEEE Transactions on Parallel and Distributed Systems , vol. 28, no. 10, pp. 2823-2837, Oct. 2017. R. Cattaneo, G. Natale, C. Sicignano, D. Sciuto, and M. D. Santambrogio, â€œOn How to Accelerate Iterative Stencil Loops: A Scalable StreamingBased Approach,â€ in ACM Transactions on Architecture and Code Optimization , vol. 12, no. 4, pp. 1-26, Dec. 2015. H. M. Waidyasooriya, Y. Takei, S. Tatsumi and M. Hariyama, â€œOpenCLBased FPGA-Platform for Stencil Computation and Its Optimization Methodology,â€ in IEEE Transactions on Parallel and Distributed Systems , vol. 28, no. 5, pp. 1390-1402, May 2017. M. Shafiq, M. PericÃ s, R. de la Cruz, M. Araya-Polo, N. Navarro and E. AyguadÃ©, â€œExploiting memory customization in FPGA for 3D stencil computations,â€ International Conference on Field-Programmable Technology (FPTâ€™09) , Sydney, NSW, Australia, 2009, pp. 38-45. H. Fu and R. G. Clapp, â€œEliminating the Memory Bottleneck: An FPGAbased Solution for 3D Reverse Time Migrationâ€ in Proceedings of the 19th ACM/SIGDA international symposium on Field programmable gate arrays (FPGAâ€™11) , Monterey, CA, USA, 2011, pp. 65-74. https://github.com/naoyam/benchmarks (2009, March) Linux Programmerâ€™s Manual: MSR. [Online]. Available: http://man7.org/linux/man-pages/man4/msr.4.html C. Yount and A. Duran, â€œEffective Use of Large High-Bandwidth Memory Caches in HPC Stencil Computation via Temporal Wave-Front Tiling,â€ 7th International Workshop on Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMBSâ€™16) , Salt Lake, UT, 2016, pp. 65-75. S. Williams, A. Waterman, and D. Patterson, â€œRoofline: An insightful visual performance model for multicore architectures,â€ Communications of the ACM , vol. 52, no. 4, pp. 65-75, Apr. 2009. Intel Corporation, â€œIntel Arria Device Datasheet,â€ Jan. 2018. [Online]. Available: https://www.altera.com/en_US/pdfs/literature/hb/arria-10/a10 _datasheet.pdf"
  },
  "sections_summary": {
    "High-Performance High-Order Stencil Computation": "on FPGAs Using OpenCL",
    "Hamid Reza Zohouri, Artur Podobas, Satoshi Matsuoka": "Here is a concise overall summary:\n\nThis study demonstrates the effectiveness of using FPGAs with High-Level Synthesis (HLS) for high-order stencil computation. A combined spatial and temporal blocking technique achieves impressive performance results, surpassing state-of-the-art frameworks on Intel Arria GX devices, with over 1 GFLOP/s of compute performance. Additionally, the design exhibits better power efficiency in most cases. The study also introduces a novel parameterization approach to easily synthesize high-order stencils on FPGAs by changing one compilation parameter, achieving the highest known performance for high-order stencil computation in 2D and 3D applications.",
    "Methodology": "High-order stencils are effective on Intel Arria GX devices for both 2D and 3D star-shaped stencils, achieving over 100 GFLOP/s of compute performance. However, temporal blocking is not enough to compete with high-bandwidth devices like Xeon Phi or modern GPUs for high-order 3D stencil computation.",
    "1 We consider stencil radius and order to be equal": "The order of stencil calculations is equal to double the radius, making \"first-order\" stencils actually \"second-order\". Stencil computation has been widely studied on different platforms, including Intel's work on 3.5D blocking compared to temporal blocking and its limitations with external memory bandwidth.",
    "Stencil Accelerator": "Shift register size, addresses, and comparisons with block variables were parameterized based on stencil radius. The main loop's exit condition was updated to account for global index. Boundary conditions were modified to handle out-of-bounds cells correctly, using a code generator that inserts the boundary conditions into the base kernel. Support for non-square block sizes was also added.",
    "A. Benchmarks": "A modified 3D stencil implementation was created to support high-order stencils by changing the computation equation in the main loop. The new equation involves summing coefficients for neighboring cells, resulting in more floating-point operations per cell update. The 2D version of the kernel is used without Above and Below neighbors. Optimizing this implementation requires optimizing for the worst-case scenario with different coefficients for all neighboring cells.",
    "10 GX 1150 device and two banks of DDR4 memory operating": "The text describes a study comparing the performance of two high-performance computing processors: an Intel Xeon E5v4 CPU with 12 cores and a quad-channel DDR4 memory, and an Intel Xeon Phi 7210F processor with 64 cores and faster MCDRAM memory. The researchers used OpenCL for kernel compilation on both processors, using older Quartus versions to ensure optimal performance. They measured power consumption during kernel execution and compared the results.",
    "Cell Update": "Computing a specific stencil will be memory-bound on a given device if its FLOP to Byte ratio is lower than that of the device. All hardware platforms, including the FPGA with the highest FLOP to Byte ratio, are expected to be memory-bound for stencil computations. However, temporal blocking may help break away from this limitation on FPGAs.",
    "C. Benchmark Settings": "The size of input dimensions is set to a multiple of the compute block dimension to minimize redundant computation in FPGA benchmarks. The optimal sizes were determined by trial and error, with results varying between and for 2D stencils and and for 3D stencils. The minimum run times were seconds for 2D and seconds for 3D stencils.",
    "A. Fpga": "For tuning performance on an FPGA platform, the number of DSPs needed to implement each cell update in 2D and 3D stencils is calculated by considering multiplications and additions required for each update. The total degree of parallelism (papar_total) can be calculated using formulas: papar_total = {4Ã—ğ‘Ÿğ‘ğ‘‘+ âŒ‹ 2ğ·, 6Ã—ğ‘Ÿğ‘ğ‘‘+ âŒ‹ 3ğ·} and papar_total Ã— papar_temple â‰¤ papar_total. Papar_temple is the degree of temporal parallelism (equal to numbers of replicated PEs) and papar_vector_size is the vector size, restricted to values that are a multiple of two.",
    "980 Ti": "The text lists various performance results for a 2D stencil computation, including:\n\n* GFLOP/s, GCell/s, and estimated GB/s performance\n* Fmax frequency\n* Logic memory (bits and blocks)\n* DSP power in watts",
    "Power Efficiency": "The table compares computation throughputs of different devices: \n\n- Arria GX: lower throughput compared to memory bandwidth\n- Xeon E5v4, Xeon Phi, and FPGA: FPGA achieves higher throughput with temporal blocking, while Xeon Phi outperforms other two for stencil orders above 4 and for 3D stencils.",
    "22.24 GB/s of streaming bandwidth, while the system they use": "Streaming bandwidth, whether from FPGA external memory or host-FPGA link, limits stencil computation performance, leading to a reliance on temporal blocking. Without temporal blocking, achieved performance is 0 GCell/s, while with it, performance can reach up to 6 GB/s.",
    "1.54 GCell/s for a third-order 3D star-shaped stencil, while we": "The text discusses achieving high performance (GCell/s) on FPGAs for high-order stencil computations using combined spatial and temporal blocking. A larger FPGA device is estimated to achieve similar performance, while the current performance already surpasses this estimate.",
    "Tesla P100": "FPGAs achieved high-performance in all orders (first, second, third, and fourth) compared to other architectures, scaling compute performance for high-order stencils.",
    "2800 FPGA since the FLOP to byte ratio goes beyond 100 (with": "The Stratix MX series with HBM memory is unlikely to suffer from overheating issues due to DDR4 memory banks. This work was supported by several grants and performed under the auspices of a research laboratory. References include past research projects on high-performance computing, nonlinear earthquake simulation, and atmospheric dynamics simulations.",
    "1.184 Pflops Attained by Automated Generation and Autotuning of": "Here is a concise and coherent overall summary:\n\nTemporal blocking codes are used to optimize stencil computations on Field-Programmable Gate Arrays (FPGAs) for high-performance computing applications using OpenCL. Researchers have proposed various techniques to improve performance, efficiency, and scalability of these computations, including exploiting memory customization, eliminating the memory bottleneck, utilizing large high-bandwidth memory caches, and leveraging performance models such as Roofline. Additionally, approaches like combined spatial and temporal blocking, stencil code-generation frameworks, and auto-tuning techniques have been developed to achieve better results in HPC applications on FPGAs."
  },
  "tables": [
    {
      "page": 3,
      "table_index": 0,
      "content": [
        [
          "",
          "Radius",
          "FLOP per\nCell Update",
          "Byte per\nCell Update",
          "FLOP\nByte"
        ],
        [
          "2D",
          "1",
          "9",
          "8",
          "1.125"
        ],
        [
          null,
          "2",
          "17",
          "8",
          "2.125"
        ],
        [
          null,
          "3",
          "25",
          "8",
          "3.125"
        ],
        [
          null,
          "4",
          "33",
          "8",
          "4.125"
        ],
        [
          "3D",
          "1",
          "13",
          "8",
          "1.625"
        ],
        [
          null,
          "2",
          "25",
          "8",
          "3.125"
        ],
        [
          null,
          "3",
          "37",
          "8",
          "4.625"
        ],
        [
          null,
          "4",
          "49",
          "8",
          "6.125"
        ]
      ]
    },
    {
      "page": 4,
      "table_index": 0,
      "content": [
        [
          "TABLE II. HARDWARE CHARACTERISTICS",
          null,
          null,
          null,
          null,
          null,
          null
        ],
        [
          "Device",
          "Peak Compute\nPerformance\n(GFLOP/s)",
          "Peak Memory\nBandwidth\n(GB/s)",
          "TDP\n(Watt)",
          "Node\n(nm)",
          "FLOP\nByte",
          "Year"
        ],
        [
          "Arria 10\nGX 1150",
          "1450",
          "34.1",
          "70",
          "20",
          "42.522",
          "2014"
        ],
        [
          "Xeon\nE5-2650 v4",
          "700",
          "76.8",
          "105",
          "14",
          "9.115",
          "2016"
        ],
        [
          "Xeon Phi\n7210F",
          "5325",
          "400",
          "235",
          "14",
          "13.313",
          "2016"
        ],
        [
          "GTX\n580",
          "1580",
          "192.4",
          "244",
          "40",
          "8.212",
          "2010"
        ],
        [
          "GTX\n980 Ti",
          "6900",
          "336.6",
          "275",
          "28",
          "20.499",
          "2015"
        ],
        [
          "Tesla\nP100",
          "9300",
          "720.9",
          "250",
          "16",
          "12.901",
          "2016"
        ],
        [
          "",
          null,
          null,
          null,
          null,
          null,
          null
        ]
      ]
    },
    {
      "page": 5,
      "table_index": 0,
      "content": [
        [
          "TABLE III. FPGA RESULTS",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null
        ],
        [
          "",
          "rad",
          "bsize",
          "par\nvec",
          "par\ntime",
          "Input Size",
          "Estimated\nPerformance (GB/s)",
          "Measured Performance\n(GB/s|GFLOP/s|GCell/s)",
          "fmax\n(MHz)",
          "Logic",
          "Memory\n(Bits|Blocks)",
          "DSP",
          "Power\n(Watt)",
          "Model\nAccuracy"
        ],
        [
          "2D",
          "1",
          "4096",
          "8",
          "36",
          "16096Ã—16096",
          "780.500",
          "673.959|758.204|84.245",
          "343.76",
          "55%",
          "38%|083%",
          "95%",
          "72.530",
          "86.3%"
        ],
        [
          null,
          "2",
          "4096",
          "4",
          "42",
          "15712Ã—15712",
          "423.173",
          "359.752|764.473|44.969",
          "322.47",
          "64%",
          "75%|100%",
          "100%",
          "69.611",
          "85.0%"
        ],
        [
          null,
          "3",
          "4096",
          "4",
          "28",
          "15712Ã—15712",
          "264.863",
          "225.215|703.797|28.152",
          "302.75",
          "57%",
          "75%|100%",
          "96%",
          "66.139",
          "85.0%"
        ],
        [
          null,
          "4",
          "4096",
          "4",
          "22",
          "15680Ã—15680",
          "206.061",
          "174.381|719.322|21.798",
          "301.20",
          "60%",
          "78%|100%",
          "99%",
          "68.925",
          "84.6%"
        ],
        [
          "3D",
          "1",
          "256Ã—256",
          "16",
          "12",
          "696Ã—696Ã—696",
          "378.345",
          "230.568|374.673|28.821",
          "286.61",
          "60%",
          "94%|100%",
          "89%",
          "71.628",
          "60.9%"
        ],
        [
          null,
          "2",
          "256Ã—128",
          "16",
          "6",
          "696Ã—728Ã—696",
          "176.713",
          "097.035|303.234|12.129",
          "262.88",
          "44%",
          "73%|087%",
          "83%",
          "59.664",
          "54.9%"
        ],
        [
          null,
          "3",
          "256Ã—128",
          "16",
          "4",
          "696Ã—728Ã—696",
          "114.667",
          "063.737|294.784|07.967",
          "255.36",
          "44%",
          "81%|099%",
          "81%",
          "63.183",
          "55.6%"
        ],
        [
          null,
          "4",
          "256Ã—128",
          "16",
          "3",
          "696Ã—728Ã—696",
          "81.597",
          "044.701|273.794|05.588",
          "242.77",
          "47%",
          "85%|100%",
          "80%",
          "58.572",
          "54.8%"
        ]
      ]
    },
    {
      "page": 6,
      "table_index": 0,
      "content": [
        [
          "",
          "rad",
          "Performance\n(GFLOP/s)",
          "Performance\n(GCell/s)",
          "Power Efficiency\n(GFLOP/s/Watt)",
          "Roofline\nRatio"
        ],
        [
          "0 1 0 5 1\na irrA 1\nX\nG",
          "1",
          "758.204",
          "84.245",
          "10.454",
          "19.76"
        ],
        [
          null,
          "2",
          "764.473",
          "44.969",
          "10.982",
          "10.55"
        ],
        [
          null,
          "3",
          "703.797",
          "28.152",
          "10.641",
          "6.60"
        ],
        [
          null,
          "4",
          "719.322",
          "21.798",
          "10.436",
          "5.11"
        ],
        [
          "4\nv\nn 0\no5\ne6\nX2\n5-\nE",
          "1",
          "45.306",
          "5.034",
          "0.521",
          "0.52"
        ],
        [
          null,
          "2",
          "85.255",
          "5.015",
          "0.942",
          "0.52"
        ],
        [
          null,
          "3",
          "124.500",
          "4.980",
          "1.331",
          "0.52"
        ],
        [
          null,
          "4",
          "165.231",
          "5.007",
          "1.737",
          "0.52"
        ],
        [
          "ih\nP F 0\nn 1\no2\ne7\nX",
          "1",
          "222.804",
          "24.756",
          "1.000",
          "0.50"
        ],
        [
          null,
          "2",
          "398.735",
          "23.455",
          "1.774",
          "0.47"
        ],
        [
          null,
          "3",
          "592.250",
          "23.690",
          "2.629",
          "0.47"
        ],
        [
          null,
          "4",
          "759.198",
          "23.006",
          "3.369",
          "0.46"
        ]
      ]
    },
    {
      "page": 6,
      "table_index": 1,
      "content": [
        [
          "",
          null,
          "rad",
          "Performance\n(GFLOP/s)",
          "Performance\n(GCell/s)",
          "Power Efficiency\n(GFLOP/s/Watt)",
          "Roofline\nRatio"
        ],
        [
          "0 1 0 5 1\na irrA 1\nX\nG",
          null,
          "1",
          "374.673",
          "28.821",
          "5.231",
          "6.76"
        ],
        [
          null,
          null,
          "2",
          "303.234",
          "12.129",
          "5.082",
          "2.85"
        ],
        [
          null,
          null,
          "3",
          "294.784",
          "7.967",
          "4.666",
          "1.87"
        ],
        [
          null,
          null,
          "4",
          "273.794",
          "5.588",
          "4.674",
          "1.31"
        ],
        [
          "4\nv\nn 0\no5\ne6\nX2\n5-\nE",
          null,
          "1",
          "61.282",
          "4.714",
          "0.686",
          "0.49"
        ],
        [
          null,
          null,
          "2",
          "115.225",
          "4.609",
          "1.235",
          "0.48"
        ],
        [
          null,
          null,
          "3",
          "151.996",
          "4.108",
          "1.617",
          "0.43"
        ],
        [
          null,
          null,
          "4",
          "205.751",
          "4.199",
          "2.069",
          "0.44"
        ],
        [
          "ih\nP F 0\nn 1\no2\ne7\nX",
          null,
          "1",
          "288.990",
          "22.230",
          "1.279",
          "0.44"
        ],
        [
          null,
          null,
          "2",
          "549.300",
          "21.972",
          "2.428",
          "0.44"
        ],
        [
          null,
          null,
          "3",
          "788.544",
          "21.312",
          "3.480",
          "0.43"
        ],
        [
          null,
          null,
          "4",
          "1069.278",
          "21.822",
          "4.714",
          "0.44"
        ],
        [
          "X 0\nT8\nG5",
          null,
          "1",
          "224.822",
          "17.294",
          "1.229",
          "0.72"
        ],
        [
          null,
          null,
          "2",
          "358.725",
          "14.349",
          "1.960",
          "0.60"
        ],
        [
          null,
          null,
          "3",
          "404.928",
          "10.944",
          "2.213",
          "0.46"
        ],
        [
          null,
          null,
          "4",
          "453.446",
          "9.254",
          "2.478",
          "0.38"
        ],
        [
          "X\nT\nG",
          "iT\n0\n8\n9",
          "1",
          "393.322",
          "30.256",
          "1.907",
          "0.72"
        ],
        [
          null,
          null,
          "2",
          "627.582",
          "25.103",
          "3.043",
          "0.60"
        ],
        [
          null,
          null,
          "3",
          "708.414",
          "19.146",
          "3.435",
          "0.46"
        ],
        [
          null,
          null,
          "4",
          "793.295",
          "16.190",
          "3.846",
          "0.38"
        ],
        [
          "a\nls\ne\nT",
          "0\n0\n1\nP",
          "1",
          "842.381",
          "64.799",
          "4.493",
          "0.72"
        ],
        [
          null,
          null,
          "2",
          "1344.100",
          "53.764",
          "7.169",
          "0.60"
        ],
        [
          null,
          null,
          "3",
          "1517.217",
          "41.006",
          "8.092",
          "0.46"
        ],
        [
          null,
          null,
          "4",
          "1699.008",
          "34.674",
          "9.061",
          "0.38"
        ]
      ]
    },
    {
      "page": 7,
      "table_index": 0,
      "content": [
        [
          "First-order Second-order Third-order Forth-order\n1800\n1600\n)s/P 1400\nO1200\nL\nF G1000\n( e 800\nc\nn\na 600\nm\nr o 400\nfr\ne 200\nP\n0\nA10 GX1150 E5-2650 v4 Phi 7210F GTX 580 GTX 980Ti Tesla P100"
        ],
        [
          "Fig. 3. Performance of 3D stencil computation in GFLOP/s"
        ],
        [
          "First-order Second-order Third-order Forth-order\n70\n60\n)s/lle\n50\nC\nG\n( 40\ne\nc\nn a 30\nm\nr o 20\nfr\ne\nP 10\n0\nA10 GX1150 E5-2650 v4 Phi 7210F GTX 580 GTX 980Ti Tesla P100"
        ],
        [
          "Fig. 4. Performance of 3D stencil computation in GCell/s"
        ]
      ]
    },
    {
      "page": 7,
      "table_index": 1,
      "content": [
        [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          ""
        ],
        [
          "",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          ""
        ],
        [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          null
        ],
        [
          "",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          "",
          ""
        ],
        [
          "",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          "",
          ""
        ],
        [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null
        ],
        [
          "",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          "",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          "",
          ""
        ],
        [
          "",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          "",
          "",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          null,
          null,
          null,
          null,
          null,
          null
        ],
        [
          "",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          "",
          "",
          "",
          null,
          null,
          null,
          null,
          null,
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        [
          "",
          "",
          "",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ],
        [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ]
      ]
    },
    {
      "page": 7,
      "table_index": 2,
      "content": [
        [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          null,
          null,
          null
        ],
        [
          "",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          null,
          null,
          null
        ],
        [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          null,
          null
        ],
        [
          "",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          "",
          null,
          null
        ],
        [
          "",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          "",
          "",
          null
        ],
        [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          ""
        ],
        [
          "",
          "",
          "",
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          "",
          null,
          null,
          null,
          "",
          "",
          "",
          ""
        ],
        [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          "",
          null,
          null,
          null,
          null,
          null,
          null,
          null
        ],
        [
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          "",
          ""
        ]
      ]
    }
  ],
  "images": [
    "processed/images/2002.05983v1_page6_img0.png",
    "processed/images/2002.05983v1_page6_img1.png",
    "processed/images/2002.05983v1_page7_img0.png",
    "processed/images/2002.05983v1_page7_img1.png",
    "processed/images/2002.05983v1_page7_img2.png",
    "processed/images/2002.05983v1_page7_img3.png",
    "processed/images/2002.05983v1_page7_img4.png",
    "processed/images/2002.05983v1_page7_img5.png",
    "processed/images/2002.05983v1_page7_img6.png",
    "processed/images/2002.05983v1_page7_img7.png"
  ],
  "status": "completed"
}