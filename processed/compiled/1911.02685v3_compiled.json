{
  "metadata": {
    "title": "A Comprehensive Survey on Transfer Learning",
    "authors": [
      "Fuzhen Zhuang",
      "Zhiyuan Qi",
      "Keyu Duan",
      "Dongbo Xi",
      "Yongchun Zhu",
      "Hengshu Zhu",
      "Hui Xiong",
      "Qing He"
    ],
    "abstract": "Transfer learning aims at improving the performance of target learners on target domains by transferring the knowledge contained in different but related source domains. In this way, the dependence on a large number of target domain data can be reduced for constructing target learners. Due to the wide application prospects, transfer learning has become a popular and promising area in machine learning. Although there are already some valuable and impressive surveys on transfer learning, these surveys introduce approaches in a relatively isolated way and lack the recent advances in transfer learning. Due to the rapid expansion of the transfer learning area, it is both necessary and challenging to comprehensively review the relevant studies. This survey attempts to connect and systematize the existing transfer learning researches, as well as to summarize and interpret the mechanisms and the strategies of transfer learning in a comprehensive way, which may help readers have a better understanding of the current research status and ideas. Unlike previous surveys, this survey paper reviews more than forty representative transfer learning approaches, especially homogeneous transfer learning approaches, from the perspectives of data and model. The applications of transfer learning are also briefly introduced. In order to show the performance of different transfer learning models, over twenty representative transfer learning models are used for experiments. The models are performed on three different datasets, i.e., Amazon Reviews, Reuters-21578, and Office-31. And the experimental results demonstrate the importance of selecting appropriate transfer learning models for different applications in practice.",
    "published": "",
    "arxiv_id": "1911.02685v3",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "pdf_url": "http://arxiv.org/pdf/1911.02685v3",
    "pdf_file": "data/pdfs/1911.02685v3.pdf",
    "pdf_filename": "1911.02685v3.pdf"
  },
  "processing_info": {
    "processed_at": "2025-10-28T10:16:23.494898",
    "sections_found": 49,
    "tables_found": 1,
    "images_found": 0
  },
  "sections_text": {
    "arXiv:1911.02685v3  [cs.LG]  23 Jun 2020": "1",
    "A Comprehensive Survey on Transfer Learning": "Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Senior Member, IEEE,",
    "Hui Xiong, Fellow, IEEE, and Qing He": "Abstract —Transfer learning aims at improving the performance of target learners on target domains by transferring the knowledge contained in different but related source domains. In this way, the dependence on a large number of target domain data can be reduced for constructing target learners. Due to the wide application prospects, transfer learning has become a popular and promising area in machine learning. Although there are already some valuable and impressive surveys on transfer learning, these surveys introduce approaches in a relatively isolated way and lack the recent advances in transfer learning. Due to the rapid expansion of the transfer learning area, it is both necessary and challenging to comprehensively review the relevant studies. This survey attempts to connect and systematize the existing transfer learning researches, as well as to summarize and interpret the mechanisms and the strategies of transfer learning in a comprehensive way, which may help readers have a better understanding of the current research status and ideas. Unlike previous surveys, this survey paper reviews more than forty representative transfer learning approaches, especially homogeneous transfer learning approaches, from the perspectives of data and model. The applications of transfer learning are also brieﬂy introduced. In order to show the performance of different transfer learning models, over twenty representative transfer learning models are used for experiments. The models are performed on three different datasets, i.e., Amazon Reviews, Reuters-21578, and Ofﬁce-31. And the experimental results demonstrate the importance of selecting appropriate transfer learning models for different applications in practice. Index Terms —Transfer learning, machine learning, domain adaptation, interpretation.",
    "A": "LTHOUGH traditional machine learning technology has achieved great success and has been successfully ap- plied in many practical applications, it still has some limita- tions for certain real-world scenarios. The ideal scenario of machine learning is that there are abundant labeled training instances, which have the same distribution as the test data. However, collecting sufﬁcient training data is often expen- sive, time-consuming, or even unrealistic in many scenarios. Semi-supervised learning can partly solve this problem by relaxing the need of mass labeled data. Typically, a semi- supervised approach only requires a limited number of labeled data, and it utilizes a large amount of unlabeled data to improve the learning accuracy. But in many cases, unlabeled instances are also difﬁcult to collect, which usu- ally makes the resultant traditional models unsatisfactory. Transfer learning, which focuses on transferring the knowledge across domains, is a promising machine learning methodology for solving the above problem. The concept about transfer learning may initially come from educational psychology. According to the generalization theory of trans- fer, as proposed by psychologist C.H. Judd, learning to transfer is the result of the generalization of experience. It is possible to realize the transfer from one situation to another, • Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, and Qing He are with the Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, China and the University of Chinese Academy of Sciences, Beijing 100049, China. • Hengshu Zhu is with Baidu Inc., No. 10 Shangdi 10th Street, Haidian District, Beijing, China. • Hui Xiong is with Rutgers, the State University of New Jersey, 1 Washington Park, Newark, New Jersey, USA. • Zhiyuan Qi is with the equal contribution to the ﬁrst author. • Fuzhen Zhuang and Zhiyuan Qi are corresponding authors, zhuang- fuzhen@ict.ac.cn and qizhyuan@gmail.com. Fig. 1. Intuitive examples about transfer learning. as long as a person generalizes his experience. According to this theory, the prerequisite of transfer is that there needs to be a connection between two learning activities. In practice, a person who has learned the violin can learn the piano faster than others, since both the violin and the piano are musical instruments and may share some common knowledge. Fig. 1 shows some intuitive examples about transfer learning. Inspired by human beings’ capabilities to transfer knowledge across domains, transfer learning aims to leverage knowledge from a related domain (called source domain) to improve the learning performance or minimize the number of labeled examples required in a target domain. It is worth mentioning that the transferred knowledge does not always bring a positive impact on new tasks. If there is little in common between domains, knowledge transfer could be unsuccessful. For example, learning to ride a bicy- cle cannot help us learn to play the piano faster. Besides, the similarities between domains do not always facilitate learn- ing, because sometimes the similarities may be misleading. For example, although Spanish and French have a close re- lationship with each other and both belong to the Romance 2 group of languages, people who learn Spanish may experi- ence difﬁculties in learning French, such as using the wrong vocabulary or conjugation. This occurs because previous successful experience in Spanish can interfere with learning the word formation, usage, pronunciation, conjugation, etc., in French. In the ﬁeld of psychology, the phenomenon that previous experience has a negative effect on learning new tasks is called negative transfer . Similarly, in the transfer learning area, if the target learner is negatively affected by the transferred knowledge, the phenomenon is also termed as negative transfer , . Whether negative transfer will occur may depend on several factors, such as the relevance between the source and the target domains and the learners capacity of ﬁnding the transferable and beneﬁcial part of the knowledge across domains. In , a formal deﬁnition and some analyses of negative transfer are given. Roughly speaking, according to the discrepancy between domains, transfer learning can be further divided into two categories, i.e., homogeneous and heterogeneous transfer learning . Homogeneous transfer learning approaches are developed and proposed for handling the situations where the domains are of the same feature space. In homogeneous transfer learning, some studies assume that domains differ only in marginal distributions. Therefore, they adapt the do- mains by correcting the sample selection bias  or covariate shift . However, this assumption does not hold in many cases. For example, in sentiment classiﬁcation problem, a word may have different meaning tendencies in different domains. This phenomenon is also called context feature bias . To solve this problem, some studies further adapt the conditional distributions. Heterogeneous transfer learn- ing refers to the knowledge transfer process in the situations where the domains have different feature spaces. In addition to distribution adaptation, heterogeneous transfer learning requires feature space adaptation , which makes it more complicated than homogeneous transfer learning. The survey aims to give readers a comprehensive un- derstanding about transfer learning from the perspectives of data and model. The mechanisms and the strategies of transfer learning approaches are introduced to allow readers grasp how the approaches work. And a number of the existing transfer learning researches are connected and systematized. Speciﬁcally, over forty representative transfer learning approaches are introduced. Besides, we conduct experiments to demonstrate on which dataset a transfer learning model performs well. In this survey, we focus more on homogeneous transfer learning. Some interesting transfer learning topics are not covered in this survey, such as reinforcement transfer learn- ing , lifelong transfer learning , and online transfer learning . The rest of this survey are organized into seven sections. Section 2 clariﬁes the difference between transfer learning and other related machine learning tech- niques. Section 3 introduces the notations used in this sur- vey and the deﬁnitions about transfer learning. Sections 4 and 5 interpret transfer learning approaches from the data and the model perspectives, respectively. Section 6 intro- duces some applications of transfer learning. Experiments are conducted and the results are provided in Section 7. The last section concludes this survey. The main contributions of this survey are summarized below. • Over forty representative transfer learning approaches are introduced and summarized, which can give read- ers a comprehensive overview about transfer learning. • Experiments are conducted to compare different trans- fer learning approaches. The performance of over twenty different approaches is displayed intuitively and then analyzed, which may be instructive for the readers to select the appropriate ones in practice.",
    "R ELATED W ORK": "Some areas related to transfer learning are introduced. The connections and difference between them and transfer learn- ing are clariﬁed.",
    "Semi-Supervised Learning [11]: Semi-supervised learning": "is a machine learning task and method that lies between supervised learning (with completely labeled instances) and unsupervised learning (without any labeled instances). Typically, a semi-supervised method utilizes abundant un- labeled instances combined with a limited number of la- beled instances to train a learner. Semi-supervised learn- ing relaxes the dependence on labeled instances, and thus reduces the expensive labeling costs. Note that, in semi- supervised learning, both the labeled and unlabeled in- stances are drawn from the same distribution. In contrast, in transfer learning, the data distributions of the source and the target domains are usually different. Many transfer learn- ing approaches absorb the technology of semi-supervised learning. The key assumptions in semi-supervised learning, i.e., smoothness, cluster, and manifold assumptions, are also made use of in transfer learning. It is worth mentioning that semi-supervised transfer learning is a controversial term. The reason is that the concept of whether the label information is available in transfer learning is ambiguous because both the source and the target domains can be involved.",
    "Multi-View Learning [12]: Multi-view learning focuses on": "the machine learning problems with multi-view data. A view represents a distinct feature set. An intuitive example about multiple views is that a video object can be described from two different viewpoints, i.e., the image signal and the audio signal. Brieﬂy, multi-view learning describes an object from multiple views, which results in abundant in- formation. By properly considering the information from all views, the learner’s performance can be improved. There are several strategies adopted in multi-view learning such as subspace learning, multi-kernel learning, and co-training , . Multi-view techniques are also adopted in some transfer learning approaches. For example, Zhang et al. pro- posed a multi-view transfer learning framework, which im- poses the consistency among multiple views . Yang and Gao incorporated multi-view information across different domains for knowledge transfer . The work by Feuz and Cook introduces a multi-view transfer learning approach for activity learning, which transfers activity knowledge between heterogeneous sensor platforms .",
    "Multi-Task Learning [18]: The thought of multi-task learn-": "ing is to jointly learn a group of related tasks. To be more speciﬁc, multi-task learning reinforces each task by taking advantage of the interconnections between task, i.e., considering both the inter-task relevance and the inter-task 3 difference. In this way, the generalization of each task is en- hanced. The main difference between transfer learning and multi-task learning is that the former transfer the knowl- edge contained in the related domains, while the latter transfer the knowledge via simultaneously learning some related tasks. In other words, multi-task learning pays equal attention to each task, while transfer learning pays more attention to the target task than to the source task. There are some commons and associations between transfer learning and multi-task learning. Both of them aim to improve the performance of learners via knowledge transfer. Besides, they adopt some similar strategies for constructing models, such as feature transformation and parameter sharing. Note that some existing studies utilize both the transfer learn- ing and the multi-task learning technologies. For example, the work by Zhang et al. employs multi-task and transfer learning techniques for biological image analysis . The work by Liu et al. proposes a framework for human action recognition based on multi-task learning and multi-source transfer learning .",
    "O VERVIEW": "In this section, the notations used in this survey are listed for convenience. Besides, some deﬁnitions and categorizations about transfer learning are introduced, and some related surveys are also provided.",
    "Notation": "For convenience, a list of symbols and their deﬁnitions are shown in Table 1. Besides, we use ||·|| to represent the norm and superscript T to denote the transpose of a vector/matrix.",
    "Deﬁnition": "In this subsection, some deﬁnitions about transfer learning are given. Before giving the deﬁnition of transfer learning, let us review the deﬁnitions of a domain and a task. Deﬁnition 1. (Domain) A domain D is composed of two parts, i.e., a feature space X and a marginal distribution P ( X ) . In other words, D = {X , P ( X ) } . And the symbol X denotes an instance set, which is deﬁned as X = { x | x i ∈X , i = 1 , · · · , n } . Deﬁnition 2. (Task) A task T consists of a label space Y and a decision function f , i.e., T = {Y , f } . The decision function f is an implicit one, which is expected to be learned from the sample data. Some machine learning models actually output the pre- dicted conditional distributions of instances. In this case, f ( x j ) = { P ( y k | x j ) | y k ∈Y , k = 1 , · · · , |Y|} . In practice, a domain is often observed by a number of instances with/without the label information. For ex- ample, a source domain D S corresponding to a source task T S is usually observed via the instance-label pairs, i.e., D S = { ( x , y ) | x i ∈X S , y i ∈Y S , i = 1 , · · · , n S } ; an observation of the target domain usually consists of a number of unlabeled instances and/or limited number of labeled instances.",
    "Deﬁnition 3. (Transfer Learning) Given some/an observation(s)": "corresponding to m S ∈ N + source domain(s) and task(s) TABLE 1 Notations. Symbol Deﬁnition n Number of instances m Number of domains D Domain T Task X Feature space Y Label space x Feature vector y Label X Instance set Y Label set corresponding to X S Source domain T Target domain L Labeled instances U Unlabeled instances H Reproducing kernel Hilbert space θ Mapping/Coefﬁcient vector α Weighting coefﬁcient β Weighting coefﬁcient λ Tradeoff parameter δ Parameter/Error b Bias B Boundary parameter N Iteration/Kernel number f Decision function L Loss function η Scale parameter G Graph Φ Nonlinear mapping σ Monotonically increasing function Ω Structural risk κ Kernel function K Kernel matrix H Centering matrix C Covariance matrix d Document w Word z Class variable ˜ z Noise D Discriminator G Generator S Function M Orthonormal bases Θ Model parameters P Probability E Expectation Q Matrix variable R Matrix variable W Mapping matrix (i.e., { ( D S i , T S i ) | i = 1 , · · · , m S } ), and some/an observa- tion(s) about m T ∈ N + target domain(s) and task(s) (i.e., { ( D T j , T T j ) | j = 1 , · · · , m T } ), transfer learning utilizes the knowledge implied in the source domain(s) to improve the performance of the learned decision functions f T j ( j = 1 , · · · , m T ) on the target domain(s). The above deﬁnition, which covers the situation of multi- source transfer learning, is an extension of the one presented in the survey . If m S equals 1 , the scenario is called single- source transfer learning. Otherwise, it is called multi-source transfer learning. Besides, m T represents the number of the transfer learning tasks. A few studies focus on the setting that m T ≥ 2 . The existing transfer learning studies pay more attention to the scenarios where m T = 1 (especially where m S = m T = 1 ). It is worth mentioning that the observation of a domain or a task is a concept with broad 4 Transfer Learning",
    "Relational-Based Approach": "Symmetric Transformation Asymmetric Transformation Label-Setting-Based Categorization Space-Setting-Based Categorization Fig. 2. Categorizations of transfer learning. sense, which is often cemented into a labeled/unlabeled instance set or a pre-learned model. A common scenario is that we have abundant labeled instances or have a well- trained model on the source domain, and we only have limited labeled target-domain instances. In this case, the resources such as the instances and the model are actually the observations, and the goal of transfer learning is to learn a more accurate decision function on the target domain. Another term commonly used in the transfer learning area is domain adaptation. Domain adaptation refers to the process that adapting one or more source domains to trans- fer knowledge and improve the performance of the target learner . Transfer learning often relies on the domain adaptation process, which attempts to reduce the difference between domains.",
    "Categorization of Transfer Learning": "There are several categorization criteria of transfer learning. For example, transfer learning problems can be divided into three categories, i.e., transductive, inductive, and un- supervised transfer learning . The complete deﬁnitions of these three categories are presented in . These three categories can be interpreted from a label-setting aspect. Roughly speaking, transductive transfer learning refers to the situations where the label information only comes from the source domain. If the label information of the target- domain instances is available, the scenario can be catego- rized into inductive transfer learning. If the label informa- tion is unknown for both the source and the target domains, the situation is known as unsupervised transfer learning. Another categorization is based on the consistency between the source and the target feature spaces and label spaces. If X S = X T and Y S = Y T , the scenario is termed as homogeneous transfer learning. Otherwise, if X S ̸ = X T or/and Y S ̸ = Y T , the scenario is referred to as heteroge- neous transfer learning. According to the survey , the transfer learning ap- proaches can be categorized into four groups: instance- based, feature-based, parameter-based, and relational-based approaches. Instance-based transfer learning approaches are mainly based on the instance weighting strategy. Feature- based approaches transform the original features to create a new feature representation; they can be further divided into two subcategories, i.e., asymmetric and symmetric feature- based transfer learning. Asymmetric approaches transform the source features to match the target ones. In contrast, symmetric approaches attempt to ﬁnd a common latent feature space and then transform both the source and the target features into a new feature representation. The parameter-based transfer learning approaches transfer the knowledge at the model/parameter level. Relational-based transfer learning approaches mainly focus on the problems in relational domains. Such approaches transfer the logical relationship or rules learned in the source domain to the target domain. For better understanding, Fig. 2 shows the above-mentioned categorizations of transfer learning. Some surveys are provided for the readers who want to have a more complete understanding of this ﬁeld. The survey by Pan and Yang , which is a pioneering work, cat- egorizes transfer learning and reviews the research progress before 2010 . The survey by Weiss et al. introduces and summarizes a number of homogeneous and heterogeneous transfer learning approaches . Heterogeneous transfer learning is specially reviewed in the survey by Day and Khoshgoftaar . Some surveys review the literatures re- lated to speciﬁc themes such as reinforcement learning , computational intelligence , and deep learning , . Besides, a number of surveys focus on speciﬁc application scenarios including activity recognition , visual catego- rization , collaborative recommendation , computer vision , and sentiment analysis . Note that the organization of this survey does not strictly follow the above-mentioned categorizations. In the next two sections, transfer learning approaches are interpreted from the data and the model perspectives. Roughly speak- ing, data-based interpretation covers the above-mentioned instance-based and feature-based transfer learning ap- proaches, but from a broader perspective. Model-based interpretation covers the above-mentioned parameter-based approaches. Since there are relatively few studies concern- ing relational-based transfer learning and the representative approaches are well introduced in , , this survey does not focus on relational-based approaches. 5 Covariance ...",
    "Geometric Structure": "Cluster Structure ... Data-Based Interpretation",
    "Type": "Distribution Adaptation Data Property Preservation/Adjustment Marginal Distribution Adaptation Conditional Distribution Adaptation Kullback-Leibler Divergence Maximum Mean Discrepancy Jensen-Shannon Divergence ...",
    "Strategy": "Model Ensemble",
    "Feature Reduction": "Joint Distribution Adaptation Feature Replication ... Feature Encoding Bregman Divergence Feature Stacking Mean Manifold Structure ... Feature Mapping",
    "Heuristic Method": "Space Adaptation",
    "Label Space Adaptation": "Spectral Feature Alignment Subspace Feature Alignment ... ... Statistic Feature Alignment Feature Selection Fig. 3. Strategies and the objectives of the transfer learning approaches from the data perspective.",
    "D ATA -B ASED I NTERPRETATION": "Many transfer learning approaches, especially the data- based approaches, focus on transferring the knowledge via the adjustment and the transformation of data. Fig. 3 shows the strategies and the objectives of the approaches from the data perspective. As shown in Fig. 3, space adaptation is one of the objectives. This objective is required to be sat- isﬁed mostly in heterogeneous transfer learning scenarios. In this survey, we focus more on homogeneous transfer learning, and the main objective in this scenario is to reduce the distribution difference between the source-domain and the target-domain instances. Furthermore, some advanced approaches may attempt to preserve the data properties in the adaptation process. There are generally two strategies for realizing the objectives from the data perspective, i.e., in- stance weighting and feature transformation. In this section, some related transfer learning approaches are introduced in proper order according to the strategies shown in Fig. 3.",
    "Instance Weighting Strategy": "Let us ﬁrst consider a simple scenario in which a large number of labeled source-domain and a limited number of target-domain instances are available and domains differ only in marginal distributions (i.e., P S ( X ) ̸ = P T ( X ) and P S ( Y | X ) = P T ( Y | X ) ). For example, suppose we need to build a model to diagnose cancer in a speciﬁc region where the elderly are the majority. Limited target-domain instances are given, and relevant data are available from another region where young people are the majority. Di- rectly transferring all the data from another region may be unsuccessful, since the marginal distribution difference exists, and the elderly have a higher risk of cancer than younger people. In this scenario, it is natural to consider adapting the marginal distributions. A simple idea is to assign weights to the source-domain instances in the loss function. The weighting strategy is based on the following equation : E ( x ,y ) ∼ P T [ L ( x , y ; f )] = E ( x ,y ) ∼ P S \u0014 P T ( x , y ) P S ( x , y ) L ( x , y ; f ) \u0015 = E ( x ,y ) ∼ P S \u0014 P T ( x ) P S ( x ) L ( x , y ; f ) \u0015 . Therefore, the general objective function of a learning task can be written as : min f 1 n S n S X i =1 β i L \u0010 f ( x S i ) , y S i \u0011 + Ω( f ) , where β i ( i = 1 , 2 , · · · , n S ) is the weighting parameter. The theoretical value of β i is equal to P T ( x i ) /P S ( x i ) . However, this ratio is generally unknown and is difﬁcult to be obtained by using the traditional methods. Kernel Mean Matching (KMM) , which is proposed by Huang et al. , resolves the estimation problem of the above unknown ratios by matching the means between the source- domain and the target-domain instances in a Reproducing Kernel Hilbert Space (RKHS), i.e., arg min β i ∈ [0 ,B ] 1 n S n S X i =1 β i Φ( x S i ) − 1 n T n T X j =1 Φ( x T j ) 2 H s.t. | 1 n S n S X i =1 β i − 1 | ≤ δ, where δ is a small parameter, and B is a parameter for con- straint. The above optimization problem can be converted 6 into a quadratic programming problem by expanding and using the kernel trick. This approach to estimating the ratios of distributions can be easily incorporated into many exist- ing algorithms. Once the weight β i is obtained, a learner can be trained on the weighted source-domain instances. There are some other studies attempting to estimate the weights. For example, Sugiyama et al. proposed an approach termed Kullback-Leibler Importance Estimation Procedure (KLIEP) . KLIEP depends on the minimization of the Kullback-Leibler (KL) divergence and incorporates a built-in model selection procedure. Based on the studies of weight estimation, some instance-based transfer learning frameworks or algorithms are proposed. For example, Sun et al. proposed a multi-source framework termed 2-Stage Weighting Framework for Multi-Source Domain Adaptation (2SW-MDA) with the following two stages . 1. Instance Weighting : The source-domain instances are as- signed with weights to reduce the marginal distribution difference, which is similar to KMM. 2. Domain Weighting : Weights are assigned to each source domain for reducing the conditional distribution differ- ence based on the smoothness assumption . Then, the source-domain instances are reweighted based on the instance weights and the domain weights. These reweighted instances and the labeled target-domain in- stances are used to train the target classiﬁer. In addition to directly estimating the weighting param- eters, adjusting weights iteratively is also effective. The key is to design a mechanism to decrease the weights of the instances that have negative effects on the target learner. A representative work is TrAdaBoost , which is a framework proposed by Dai et al . This framework is an extension of AdaBoost . AdaBoost is an effective boosting algorithm designed for traditional machine learn- ing tasks. In each iteration of AdaBoost, a learner is trained on the instances with updated weights, which results in a weak classiﬁer. The weighting mechanism of instances ensures that the instances with incorrect classiﬁcation are given more attention. Finally, the resultant weak classiﬁers are combined to form a strong classiﬁer. TrAdaBoost ex- tends the AdaBoost to the transfer learning scenario; a new weighting mechanism is designed to reduce the impact of the distribution difference. Speciﬁcally, in TrAdaBoost, the labeled source-domain and labeled target-domain instances are combined as a whole, i.e., a training set, to train the weak classiﬁer. The weighting operations are different for the source-domain and the target-domain instances. In each iteration, a temporary variable ¯ δ , which measures the classi- ﬁcation error rate on the labeled target-domain instances, is calculated. Then, the weights of the target-domain instances are updated based on ¯ δ and the individual classiﬁcation results, while the weights of the source-domain instances are updated based on a designed constant and the individual classiﬁcation results. For better understanding, the formulas used in the k -th iteration ( k = 1 , · · · , N ) for updating the weights are presented repeatedly as follows : β S k,i = β S k − 1 ,i (1 + q 2 ln n S /N ) − | f k ( x S i ) − y S i | ( i = 1 , · · · , n S ) , β T k,j = β T k − 1 ,j (¯ δ k / (1 − ¯ δ k )) − | f k ( x T j ) − y T j | ( j = 1 , · · · , n T ) . Note that each iteration forms a new weak classiﬁer. The ﬁnal classiﬁer is constructed by combining and ensembling half the number of the newly resultant weak classiﬁers through voting scheme. Some studies further extend TrAdaBoost. The work by Yao and Doretto  proposes a Multi-Source TrAdaBoost (MsTrAdaBoost) algorithm, which mainly has the following two steps in each iteration. 1. Candidate Classiﬁer Construction : A group of candi- date weak classiﬁers are respectively trained on the weighted instances in the pairs of each source domain and the target domain, i.e., D S i ∪D T ( i = 1 , · · · , m S ). 2. Instance Weighting : A classiﬁer (denoted by j and trained on D S j ∪D T ) which has the minimal classi- ﬁcation error rate ¯ δ on the target domain instances is selected, and then is used for updating the weights of the instances in D S j and D T . Finally, the selected classiﬁers from each iteration are com- bined to form the ﬁnal classiﬁer. Another parameter-based algorithm, i.e., TaskTrAdaBoost, is also proposed in the work , which is introduced in Section 5.3. Some approaches realize instance weighting strategy in a heuristic way. For example, Jiang and Zhai proposed a general weighting framework . There are three terms in the framework’s objective function, which are designed to minimize the cross-entropy loss of three types of instances. The following types of instances are used to construct the target classiﬁer. • Labeled Target-domain Instance : The classiﬁer should mini- mize the cross-entropy loss on them, which is actually a standard supervised learning task. • Unlabeled Target-domain Instance : These instances’ true con- ditional distributions P ( y | x T,U i ) are unknown and should be estimated. A possible solution is to train an auxiliary classiﬁer on the labeled source-domain and target-domain instances to help estimate the conditional distributions or assign pseudo labels to these instances. • Labeled Source-domain Instance : The authors deﬁne the weight of x S,L i as the product of two parts, i.e., α i and β i . The weight β i is ideally equal to P T ( x i ) /P S ( x i ) , which can be estimated by non-parametric methods such as KMM or can be set uniformly in the worst case. The weight α i is used to ﬁlter out the source-domain instances that differ greatly from the target domain. A heuristic method can be used to produce the value of α i , which contains the following three steps. 1. Auxiliary Classiﬁer Construction : An auxiliary classiﬁer trained on the labeled target-domain instances are used to classify the unlabeled source-domain instances. 2. Instance Ranking : The source-domain instances are ranked based on the probabilistic prediction results. 3. Heuristic Weighting ( β i ) : The weights of the top- k source-domain instances with wrong predictions are set to zero, and the weights of others are set to one.",
    "Feature Transformation Strategy": "Feature transformation strategy is often adopted in feature- based approaches. For example, consider a cross-domain text classiﬁcation problem. The task is to construct a target 7 TABLE 2 Metrics Adopted in Transfer Learning. Measurement Related Algorithms Maximum Mean Discrepancy      · · · Kullback-Leibler Divergence      · · · Jensen-Shannon Divergence      · · · Bregman Divergence      · · · Hilbert-Schmidt Independence Criterion      · · · classiﬁer by using the labeled text data from a related domain. In this scenario, a feasible solution is to ﬁnd the common latent features (e.g., latent topics) through fea- ture transformation and use them as a bridge to transfer knowledge. Feature-based approaches transform each orig- inal feature into a new feature representation for knowl- edge transfer. The objectives of constructing a new feature representation include minimizing the marginal and the conditional distribution difference, preserving the proper- ties or the potential structures of the data, and ﬁnding the correspondence between features. The operations of feature transformation can be divided into three types, i.e., feature augmentation, feature reduction, and feature alignment. Be- sides, feature reduction can be further divided into several types such as feature mapping, feature clustering, feature selection, and feature encoding. A complete feature trans- formation process designed in an algorithm may consist of several operations. 4.2.1 Distribution Difference Metric One primary objective of feature transformation is to reduce the distribution difference of the source and the target do- main instances. Therefore, how to measure the distribution difference or the similarity between domains effectively is an important issue. The measurement termed Maximum Mean Discrepancy (MMD) is widely used in the ﬁeld of transfer learning, which is formulated as follows : MMD ( X S , X T ) = 1 n S n S X i =1 Φ( x S i ) − 1 n T n T X j =1 Φ( x T j ) 2 H . MMD can be easily computed by using kernel trick. Brieﬂy, MMD quantiﬁes the distribution difference by calculating the distance of the mean values of the instances in a RKHS. Note that the above-mentioned KMM actually produces the weights of instances by minimizing the MMD distance between domains. Table. 2 lists some commonly used metrics and the related algorithms. In addition to Table. 2, there are some other measurement criteria adopted in transfer learning, including Wasserstein distance , , central moment discrepancy , etc. Some studies focus on optimizing and improving the existing measurements. Take MMD as an example. Gretton et al. proposed a multi-kernel version of MMD, i.e., MK-MMD , which takes advantage of multiple kernels. Besides, Yan et al. proposed a weighted version of MMD , which attempts to address the issue of class weight bias. 4.2.2 Feature Augmentation Feature augmentation operations are widely used in fea- ture transformation, especially in symmetric feature-based approaches. To be more speciﬁc, there are several ways to realize feature augmentation such as feature replication and feature stacking. For better understanding, we start with a simple transfer learning approach which is established based on feature replication. The work by Daum´e proposes a simple domain adap- tation method, i.e., Feature Augmentation Method (FAM) . This method transforms the original features by sim- ple feature replication. Speciﬁcally, in single-source transfer learning scenario, the feature space is augmented to three times its original size. The new feature representation con- sists of general features, source-speciﬁc features, and target- speciﬁc features. Note that, for the transformed source- domain instances, their target-speciﬁc features are set to zero. Similarly, for the transformed target-domain instances, their source-speciﬁc features are set to zero. The new feature representation of FAM is presented as follows: Φ S ( x S i ) = ⟨ x S i , x S i , 0 ⟩ , Φ T ( x T j ) = ⟨ x T j , 0 , x T j ⟩ , where Φ S and Φ T denote the mappings to the new feature space from the source and the target domain, respectively. The ﬁnal classiﬁer is trained on the transformed labeled instances. It is worth mentioning that this augmentation method is actually redundant. In other words, augmenting the feature space in other ways (with fewer dimensions) may be able to produce competent performance. The supe- riority of FAM is that its feature expansion has an elegant form, which results in some good properties such as the generalization to multi-source scenarios. An extension of FAM is proposed in  by Daum´e et al. , which utilizes the unlabeled instances to further facilitate the knowledge transfer process. However, FAM may not work well in handling het- erogeneous transfer learning tasks. The reason is that di- rectly replicating features and padding zero vectors are less effective when the source and the target domains have different feature representations. To solve this problem, Li et al. proposed an approach termed Heterogeneous Feature Augmentation (HFA) , . The feature representation of HFA is presented below: Φ S ( x S i ) = ⟨ W S x S i , x S i , 0 T ⟩ , Φ T ( x T j ) = ⟨ W T x T j , 0 S , x T j ⟩ , where W S x S i and W T x T j have the same dimension; 0 S and 0 T denote the zero vectors with the dimensions of x S and x T , respectively. HFA maps the original features into a common feature space, and then performs a feature stacking operation. The mapped features, original features, and zero elements are stacked in a particular order to produce a new feature representation. 4.2.3 Feature Mapping In the ﬁeld of traditional machine learning, there are many feasible mapping-based methods of extracting fea- tures such as Principal Component Analysis (PCA)  and Kernelized-PCA (KPCA) . However, these methods mainly focus on the data variance rather than the distribu- tion difference. In order to solve the distribution difference, 8 some feature extraction methods are proposed for transfer learning. Let us ﬁrst consider a simple scenario where there is little difference in the conditional distributions of the do- mains. In this case, the following simple objective function can be used to ﬁnd a mapping for feature extraction: min Φ \u0000 DIST ( X S , X T ; Φ) + λ Ω(Φ) \u0001 / \u0000 VAR ( X S ∪ X T ; Φ) \u0001 , where Φ is a low-dimensional mapping function, DIST ( · ) represents a distribution difference metric, Ω(Φ) is a regular- izer controlling the complexity of Φ , and VAR ( · ) represents the variance of instances. This objective function aims to ﬁnd a mapping function Φ that minimizes the marginal distribution difference between domains and meanwhile makes the variance of the instances as large as possible. The objective corresponding to the denominator can be opti- mized in several ways. One possible way is to optimize the objective of the numerator with a variance constraint. For example, the scatter matrix of the mapped instances can be enforced as an identity matrix. Another way is to optimize the objective of the numerator in a high-dimensional feature space at ﬁrst. Then, a dimension reduction algorithm such as PCA or KPCA can be performed to realize the objective of the denominator. Further, ﬁnding the explicit formulation of Φ( · ) is non- trivial. To solve this problem, some approaches adopt linear mapping technique or turn to the kernel trick. In general, there are three main ideas to deal with the above optimiza- tion problems. • (Mapping Learning + Feature Extraction) A possible way is to ﬁnd a high-dimensional space at ﬁrst where the objec- tives are met by solving a kernel matrix learning problem or a transformation matrix ﬁnding problem. Then, the high-dimensional features are compacted to form a low- dimensional feature representation. For example, once the kernel matrix is learned, the principal components of the implicit high-dimensional features can be extracted to construct a new feature representation based on PCA. • (Mapping Construction + Mapping Learning) Another way is to map the original features to a constructed high- dimensional feature space, and then a low-dimensional mapping is learned to satisfy the objective function. For example, a kernel matrix can be constructed based on a selected kernel function at ﬁrst. Then, the transfor- mation matrix can be learned, which projects the high- dimensional features into a common latent subspace. • (Direct Low-dimensional Mapping Learning) It is usu- ally difﬁcult to ﬁnd a desired low-dimensional mapping directly. However, if the mapping is assumed to satisfy certain conditions, it may be solvable. For example, if the low-dimensional mapping is restricted to be a linear one, the optimization problem can be easily solved. Some approaches also attempt to match the conditional distributions and preserve the structures of the data. To achieve this, the above simple objective function needs to incorporate new terms or/and constraints. For example, the following general objective function is a possible choice: min Φ µ DIST ( X S , X T ; Φ) + λ 1 Ω GEO (Φ) + λ 2 Ω(Φ) + (1 − µ ) DIST ( Y S | X S , Y T | X T ; Φ) , s.t. Φ( X ) T H Φ( X ) = I, with H = I − ( 1 /n ) ∈ R n × n , where µ is a parameter balancing the marginal and the conditional distribution difference , Ω GEO (Φ) is a reg- ularizer controlling the geometric structure, Φ( X ) is the matrix whose rows are the instances from both the source and the target domains with the extracted new feature representation, H is the centering matrix for constructing the scatter matrix, and the constraint is used to maximize the variance. The last term in the objective function denotes the measurement of the conditional distribution difference. Before the further discussion about the above objective function, it is worth mentioning that the label information of the target-domain instances is often limited or even unknown. The lack of the label information makes it difﬁcult to estimate the distribution difference. In order to solve this problem, some approaches resort to the pseudo-label strategy, i.e., assigning pseudo labels to the unlabeled target- domain instances. A simple method of realizing this is to train a base classiﬁer to assign pseudo labels. By the way, there are some other methods of providing pseudo labels such as co-training ,  and tri-training , . Once the pseudo-label information is complemented, the conditional distribution difference can be measured. For example, MMD can be modiﬁed and extended to measure the conditional distribution difference. Speciﬁcally, for each label, the source-domain and the target-domain instances that belong to the same class are collected, and the estima- tion expression of the conditional distribution difference is given by : |Y| X k =1 1 n S k n S k X i =1 Φ( x S i ) − 1 n T k n T k X j =1 Φ( x T j ) 2 H , where n S k and n T k denote the numbers of the instances in the source and the target domains with the same label Y k , respectively. This estimation actually measures the class- conditional distribution (i.e., P ( x | y ) ) difference to approx- imate the conditional distribution (i.e., P ( y | x ) ) difference. Some studies improve the above estimation. For example, the work by Wang et al. uses a weighted method to ad- ditionally solve the class imbalance problem . For better understanding, the transfer learning approaches that are the special cases of the general objective function presented in the previous paragraph are detailed as follows. • ( µ = 1 and λ 1 ̸ = 0 ) The objective function of Maximum Mean Discrepancy Embedding (MMDE) is given by : min K MMD ( X S , X T ; Φ) − λ 1 n S + n T X i ̸ = j || Φ( x i ) − Φ( x j ) || 2 s.t. ∀ ( x i ∈ k -NN ( x j )) ∧ ( x j ∈ k -NN ( x i )) , || Φ( x i ) − Φ( x j ) || 2 = || x i − x j || 2 , ( x i , x j ∈ X S ∪ X T ) , where k -NN ( x ) represents the k nearest neighbors of the instance x . The authors design the above objective func- tion motivated by Maximum Variance Unfolding (MVU) . Instead of employing a scatter matrix constraint, the constraints and the second term of this objective function aim to maximize the distance between instances as well as preserve local geometry. The desired kernel matrix K can be learned by solving a Semi-Deﬁnite Programming (SDP)  problem. After obtaining the kernel matrix, 9 PCA is applied to it, and then the leading eigenvectors are selected to help construct a low-dimensional feature representation. • ( µ = 1 and λ 1 = 0 ) The work by Pan et al. proposes an approach termed Transfer Component Analysis (TCA) , . TCA adopts MMD to measure the marginal dis- tribution difference and enforces the scatter matrix as the constraint. Different from MMDE that learns the kernel matrix and then further adopts PCA, TCA is a uniﬁed method that just needs to learn a linear mapping from an empirical kernel feature space to a low-dimensional fea- ture space. In this way, it avoids solving the SDP problem, which results in relatively low computational burden. The ﬁnal optimization problem can be easily solved via eigen- decomposition. TCA can also be extended to utilize the label information. In the extended version, the scatter matrix constraint is replaced by a new one that balances the label dependence (measured by HSIC) and the data variance. Besides, a graph Laplacian regularizer  is also added to preserve the geometry of the manifold. Sim- ilarly, the ﬁnal optimization problem can also be solved by eigen-decomposition. • ( µ = 0 . 5 and λ 1 = 0 ) Long et al. proposed an ap- proach termed Joint Distribution Adaptation (JDA) . JDA attempts to ﬁnd a transformation matrix that maps the instances to a low-dimensional space where both the marginal and the conditional distribution difference are minimized. To realize it, the MMD metric and the pseudo- label strategy are adopted. The desired transformation matrix can be obtained by solving a trace optimization problem via eigen-decomposition. Further, it is obvious that the accuracy of the estimated pseudo labels affects the performance of JDA. In order to improve the labeling quality, the authors adopt the iterative reﬁnement oper- ations. Speciﬁcally, in each iteration, JDA is performed, and then a classiﬁer is trained on the instances with the extracted features. Next, the pseudo labels are updated based on the trained classiﬁer. After that, JDA is per- formed repeatedly with the updated pseudo labels. The iteration ends when convergence occurs. Note that JDA can be extended by utilizing the label and structure infor- mation , clustering information , various statistical and geometrical information , etc. • ( µ ∈ (0 , 1) and λ 1 = 0 ) The paper by Wang et al. proposes an approach termed Balanced Distribution Adaptation (BDA) , which is an extension of JDA. Different from JDA which assumes that the marginal and the conditional distributions have the same importance in adaptation, BDA attempts to balance the marginal and the condi- tional distribution adaptation. The operations of BDA are similar to JDA. In addition, the authors also proposed the Weighted BDA (WBDA). In WBDA, the conditional distribution difference is measured by a weighted version of MMD to solve the class imbalance problem. It is worth mentioning that some approaches transform the features into a new feature space (usually of a high dimension) and train an adaptive classiﬁer simultaneously. To realize this, the mapping function of the features and the decision function of the classiﬁer need to be associated. One possible way is to deﬁne the following decision function: f ( x ) = θ · Φ( x )+ b , where θ denotes the classiﬁer parameter; b denotes the bias. In light of the representer theorem , the parameter θ can be deﬁned as θ = P n i =1 α i Φ( x i ) , and thus we have f ( x ) = n X i =1 α i Φ( x i ) · Φ( x ) + b = n X i =1 α i κ ( x i , x ) + b, where κ denotes the kernel function. By using the kernel matrix as the bridge, the regularizers designed for the map- ping function can be incorporated into the classiﬁer’s objec- tive function. In this way, the ﬁnal optimization problem is usually about the parameter (e.g., α i ) or the kernel function. For example, the paper by Long et al. proposes a general framework termed Adaptation Regularization Based Trans- fer Learning (ARTL) . The goals of ARTL are to learn the adaptive classiﬁer, to minimize the structural risk, to jointly reduce the marginal and the conditional distribution difference, and to maximize the manifold consistency be- tween the data structure and the predictive structure. The authors also proposed two speciﬁc algorithms under this framework based on different loss functions. In these two algorithms, the coefﬁcient matrix for computing MMD and the graph Laplacian matrix for manifold regularization are constructed at ﬁrst. Then, a kernel function is selected to construct the kernel matrix. After that, the classiﬁer learning problem is converted into a parameter (i.e., α i ) solving problem, and the solution formula is also given in . In ARTL, the choice of the kernel function affects the performance of the ﬁnal classiﬁer. In order to construct a robust classiﬁer, some studies turn to kernel learning. For example, the paper by Duan et al. proposes a uni- ﬁed framework termed Domain Transfer Multiple Kernel Learning (DTMKL) . In DTMKL, the kernel function is assumed to be a linear combination of a group of base kernels, i.e., κ ( x i , x j ) = P N k =1 β k κ k ( x i , x j ) . DTMKL aims to minimize the distribution difference, the classiﬁcation error, etc., simultaneously. The general objective function of DTMKL can be written as follows: min β k ,f σ \u0000 MMD ( X S , X T ; κ ) \u0001 + λ Ω L ( β k , f ) , where σ is any monotonically increasing function, f is the decision function with the same deﬁnition as the one in ARTL, and Ω L ( β k , f ) is a general term representing a group of regularizers deﬁned on the labeled instances such as the ones for minimizing the classiﬁcation error and controlling the complexity of the resultant model. The authors devel- oped an algorithm to learn the kernel and the decision function simultaneously by using the reduced gradient de- scent method . In each iteration, the weight coefﬁcients of base kernels are ﬁxed to update the decision function at ﬁrst. Then, the decision function is ﬁxed to update the weight coefﬁcients. Note that DTMKL can incorporate many existing kernel methods. The authors proposed two speciﬁc algorithms under this framework. The ﬁrst one implements the framework by using hinge loss and Support Vector Machine (SVM). The second one is an extension of the ﬁrst one with an additional regularizer utilizing pseudo- label information, and the pseudo labels of the unlabeled instances are generated by using base classiﬁers. 10 4.2.4 Feature Clustering Feature clustering aims to ﬁnd a more abstract feature representation of the original features. Although it can be regarded as a way of feature extraction, it is different from the above-mentioned mapping-based extraction. For example, some transfer learning approaches implic- itly reduce the features by using the co-clustering tech- nique, i.e., simultaneously clustering both the columns and rows of (or say, co-cluster) a contingency table based on the information theory . The paper by Dai et al.  proposes an algorithm termed Co-Clustering Based Clas- siﬁcation (CoCC), which is used for document classiﬁca- tion. In a document classiﬁcation problem, the transfer learning task is to classify the target-domain documents (represented by a document-to-word matrix) with the help of the labeled source document-to-word data. CoCC re- gards the co-clustering technique as a bridge to transfer the knowledge. In CoCC algorithm, both the source and the target document-to-word matrices are co-clustered. The source document-to-word matrix is co-clustered to generate the word clusters based on the known label information, and these word clusters are used as constraints during the co-clustering process of the target-domain data. The co- clustering criterion is to minimize the loss in mutual infor- mation, and the clustering results are obtained by iteration. Each iteration contains the following two steps. 1. Document Clustering : Each row of the target document- to-word matrix is re-ordered based on the objective function for updating the document clusters. 2. Word Clustering : The word clusters are adjusted to min- imize the joint mutual-information loss of the source and the target document-word matrices. After several times of iterations, the algorithm converges, and the classiﬁcation results are obtained. Note that, in CoCC, the word clustering process implicitly extracts the word features to form uniﬁed word clusters. Dai et al. also proposed an unsupervised clustering ap- proach, which is termed as Self-Taught Clustering (STC) . Similar to CoCC, this algorithm is also a co-clustering- based one. However, STC does not need the label infor- mation. STC aims to simultaneously co-cluster the source- domain and the target-domain instances with the assump- tion that these two domains share the same feature clusters in their common feature space. Therefore, two co-clustering tasks are separately performed at the same time to ﬁnd the shared feature clusters. Each iteration of STC has the following steps. 1. Instance Clustering : The clustering results of the source- domain and the target domain instances are updated to minimize their respective loss in mutual information. 2. Feature Clustering : The feature clusters are updated to minimize the joint loss in mutual information. When the algorithm converges, the clustering results of the target-domain instances are obtained. Different from the above-mentioned co-clustering-based ones, some approaches extract the original features into con- cepts (or topics). In the document classiﬁcation problem, the concepts represent the high-level abstractness of the words (e.g., word clusters). In order to introduce the concept-based transfer learning approaches easily, let us brieﬂy review the Latent Semantic Analysis (LSA) , the Probabilistic LSA (PLSA) , and the Dual-PLSA . • LSA : LSA is an approach to mapping the document-to- word matrix to a low-dimensional space (i.e., a latent se- mantic space) based on the SVD technique. In short, LSA attempts to ﬁnd the true meanings of the words. To realize this, SVD technique is used to reduce the dimensionality, which can remove the irrelevant information and ﬁlter out the noise information from the raw data. • PLSA : PLSA is developed based on a statistical view of LSA. PLSA assumes that there is a latent class variable z , which reﬂects the concept, associating the document d and the word w . Besides, d and w are independently con- ditioned on the concept z . The diagram of this graphical model is presented as follows: d P ( d i | z k ) ←−−−−− P ( z k ) ⇓ z P ( w j | z k ) −−−−−−→ w, where the subscripts i, j and k represent the indexes of the document, the word, and the concept, respectively. PLSA constructs a Bayesian network, and the parameters are estimated by using the Expectation-Maximization (EM) algorithm . • Dual-PLSA : The Dual-PLSA is an extension of PLSA. This approach assumes there are two latent variables z d and z w associating the documents and the words. Speciﬁcally, the variables z d and z w reﬂect the concepts behind the documents and the words, respectively. The diagram of the Dual-PLSA is provided below: d P ( d i | z d k 1 ) ←−−−−−− z d P ( z d k 1 ,z w k 2 ) ←−−−−−−→ z w P ( w j | z w k 2 ) −−−−−−→ w. The parameters of the Dual-PLSA can also be obtained based on the EM algorithm. Some concept-based transfer learning approaches are established based on PLSA. For example, the paper by Xue et al. proposes a cross-domain text classiﬁcation approach termed Topic-Bridged Probabilistic Latent Semantic Analy- sis (TPLSA) . TPLSA, which is an extension of PLSA, assumes that the source-domain and the target-domain instances share the same mixing concepts of the words. Instead of performing two PLSAs for the source domain and the target domain separately, the authors merge those two PLSAs as an integrated one by using the mixing concept z as a bridge, i.e., each concept has some probabilities to produce the source-domain and the target-domain documents. The diagram of TPLSA is provided below: d S d T տ ւ P ( d S i | z k ) ======= P ( d T i | z k ) z P ( z k | w j ) ←−−−−−− w. Note that PLSA does not require the label information. In order to exploit the label information, the authors add the concept constraints, which include must-link and cannot- link constraints, as the penalty terms in the objective function of TPLSA. Finally, the objective function is iter- atively optimized to obtain the classiﬁcation results (i.e., arg max z P ( z | d T i ) ) by using the EM algorithm. The work by Zhuang et al. proposes an approach termed Collaborative Dual-PLSA (CD-PLSA) for multi-domain text classiﬁcation ( m S source domains and m T target domains) 11 , . CD-PLSA is an extension of Dual-PLSA. Its dia- gram is shown below: P ( D k 0 ) ⇓ D → P ( d i | z d k 1 , D k 0 ) ⇓ d ← z d P ( z d k 1 ,z w k 2 ) ←−−−−−−→ z w → P ( w j | z w k 2 , D k 0 ) ⇓ w ց ր , where 1 ≤ k 0 ≤ m S + m T denotes the domain index. The domain D connects both the variables d and w , but is independent of the variables z d and z w . The label in- formation of the source-domain instances is utilized by initializing the value P ( d i | z d k 1 , D k 0 ) ( k 0 = 1 , · · · , m S ). Due to the lack of the target-domain label information, the value P ( d i | z d k 1 , D k 0 ) ( k 0 = m S + 1 , · · · , m S + m T ) can be initialized based on any supervised classiﬁer. Similarly, the authors adopt the EM algorithm to ﬁnd the param- eters. Through the iterations, all the parameters in the Bayesian network are obtained. Thus, the class label of the i -th document in a target domain (denoted by D k ) can be predicted by computing the posterior probabilities, i.e., arg max z d P ( z d | d i , D k ) . Zhuang et al. further proposed a general framework that is termed as Homogeneous-Identical-Distinct-Concept Model (HIDC) . This framework is also an extension of Dual-PLSA. HIDC is composed of three generative models, i.e., identical-concept, homogeneous-concept, and distinct- concept models. These three graphical models are presented below: Identical-Concept Model: D → d ← z d ց ր → z w IC → w, Homogeneous-Concept Model: ր ց D → d ← z d ց ր → z w HC → w, Distinct-Concept Model: ր ց ց D → d ← z d ց ր → z w DC → w . The original word concept z w is divided into three types, i.e., z w IC , z w HC , and z w DC . In the identical-concept model, the word distributions only rely on the word concepts, and the word concepts are independent of the domains. However, in the homogeneous-concept model, the word distributions also depend on the domains. The difference between the identical and the homogeneous concepts is that z w IC is di- rectly transferable, while z w HC is the domain-speciﬁc transfer- able one that may have different effects on the word distri- butions for different domains. In the distinct-concept model, z w DC is actually the nontransferable domain-speciﬁc one, which may only appear in a speciﬁc domain. The above- mentioned three models are combined as an integrated one, i.e., HIDC. Similar to other PLSA-related algorithms, HIDC also uses EM algorithm to get the parameters. 4.2.5 Feature Selection Feature selection is another kind of operation for feature reduction, which is used to extract the pivot features. The pivot features are the ones that behave in the same way in different domains. Due to the stability of these features, they can be used as the bridge to transfer the knowledge. For example, Blitzer et al. proposed an approach termed Structural Correspondence Learning (SCL) . Brieﬂy, SCL consists of the following steps to construct a new feature representation. 1. Feature Selection : SCL ﬁrst performs feature selection operations to obtain the pivot features. 2. Mapping Learning : The pivot features are utilized to ﬁnd a low-dimensional common latent feature space by using the structural learning technique . 3. Feature Stacking : A new feature representation is con- structed by feature augmentation, i.e., stacking the original features with the obtained low-dimensional features. Take the part-of-speech tagging problem as an example. The selected pivot features should occur frequently in source and target domains. Therefore, determiners can be included in pivot features. Once all the pivot features are deﬁned and selected, a number of binary linear classiﬁers whose function is to predict the occurrence of each pivot feature are constructed. Without losing generality, the decision function of the i -th classiﬁer, which is used to predict the i -th pivot feature, can be formulated as f i ( x ) = sign ( θ i · x ) , where x is assumed to be a binary feature input. And the i -th classiﬁer is trained on all the instances excluding the features derived from the i -th pivot feature. The following formula can be used to estimate the i -th classiﬁer’s parameters, i.e., θ i = arg min θ 1 n n X j =1 L ( θ · x j , Row i ( x j )) + λ || θ || 2 , where Row i ( x j ) denotes the true value of the unlabeled instance x j in terms of the i -th pivot feature. By stacking the obtained parameter vectors as column elements, a matrix ˜ W is obtained. Next, based on singular value decomposition (SVD), the top- k left singular vectors, which are the prin- cipal components of the matrix ˜ W , are taken to construct the transformation matrix W . At last, the ﬁnal classiﬁer is trained on the labeled instances in an augmented feature space, i.e., ([ x L i ; W T x L i ] T , y L i ) . 4.2.6 Feature Encoding In addition to feature extraction and selection, feature en- coding is also an effective tool. For example, autoencoders, which are often adopted in deep learning area, can be used for feature encoding. An autoencoder consists of an encoder and a decoder. The encoder tries to produce a more abstract representation of the input, while the decoder aims to map back that representation and to minimize the reconstruction error. Autoencoders can be stacked to build a deep learning architecture. Once an autoencoder completes the training process, another autoencoder can be stacked at the top of it. The newly added autoencoder is then trained by using the encoded output of the upper-level autoencoder as its input. In this way, deep learning architectures can thus be constructed. Some transfer learning approaches are developed based on autoencoders. For example, the paper by Glorot et al. proposes an approach termed Stacked Denoising Autoen- coder (SDA) . The denoising autoencoder, which can enhance the robustness, is an extension of the basic one . This kind of autoencoder contains a randomly corrupting mechanism that adds noise to the input before mapping. For 12 example, an input can be corrupted or partially destroyed by adding a masking noise or Gaussian noise. The denoising autoencoder is then trained to minimize the denoising re- construction error between the original clean input and the output. The SDA algorithm proposed in the paper mainly encompasses the following steps. 1. Autoencoder Training : The source-domain and target- domain instances are used to train a stack of denoising autoencoders in a greedy layer-by-layer way. 2. Feature Encoding & Stacking : A new feature representa- tion is constructed by stacking the encoding output of intermediate layers, and the features of the instances are transformed into the obtained new representation. 3. Learner Training : The target classiﬁer is trained on the transformed labeled instances. Although the SDA algorithm has excellent performance for feature extraction, it still has some drawbacks such as high computational and parameter-estimation cost. In order to shorten the training time and to speed up traditional SDA algorithms, Chen et al. proposed a modiﬁed version of SDA, i.e., Marginalized Stacked Linear Denoising Au- toencoder (mSLDA) , . This algorithm adopts linear autoencoders and marginalizes the randomly corrupting step in a closed form. It may seem that linear autoencoders are too simple to learn complex features. However, the authors observe that linear autoencoders are often sufﬁcient to achieve competent performance when encountering high dimensional data. The basic architecture of mSLDA is a single-layer linear autoencoder. The corresponding single- layer mapping matrix W (augmented with a bias column for convenience) should minimize the expected squared reconstruction loss function, i.e., W = arg min W 1 2 n n X i =1 E P (˜ x i | x ) \u0002 || x i − W ˜ x i || 2 \u0003 , where ˜ x i denotes the corrupted version of the input x i . The solution of W is given by , : W = n X i =1 x i E [˜ x i ] T ! n X i =1 E h ˜ x i ˜ x T i i ! − 1 . When the corruption strategy is determined, the above for- mulas can be further expanded and simpliﬁed into a speciﬁc form. Note that, in order to insert nonlinearity, a nonlinear function is used to squash the output of each autoencoder after we obtain the matrix W in a closed form. Then, the next linear autoencoder is stacked to the current one in a similar way to SDA. In order to deal with high dimensional data, the authors also put forward an extension approach to further reduce the computational complexity. 4.2.7 Feature Alignment Note that feature augmentation and feature reduction mainly focus on the explicit features in a feature space. In contrast, in addition to the explicit features, feature alignment also focuses on some implicit features such as the statistic features and the spectral features. Therefore, feature alignment can play various roles in the feature transformation process. For example, the explicit features can be aligned to generate a new feature representation, or the implicit features can be aligned to construct a satisﬁed feature transformation. There are several kinds of features that can be aligned, which includes subspace features, spectral features, and statistic features. Take the subspace feature alignment as an example. A typical approach mainly has the following steps. 1. Subspace Generation : In this step, the instances are used to generate the respective subspaces for the source and the target domains. The orthonormal bases of the source and the target domain subspaces are then obtained, which are denoted by M S and M T , respectively. These bases are used to learn the shift between the subspaces. 2. Subspace Alignment : In the second step, a mapping, which aligns the bases M S and M T of the subspaces, is learned. And the features of the instances are pro- jected to the aligned subspaces to generate new feature representation. 3. Learner Training : Finally, the target learner is trained on the transformed instances. For example, the work by Fernando et al. proposes an approach termed Subspace Alignment (SA) . In SA, the subspaces are generated by performing PCA; the bases M S and M T are obtained by selecting the leading eigenvectors. Then, a transformation matrix W is learned to align the subspaces, which is given by : W = arg min W || M S W − M T || 2 F = M T S M T , where || · || F denotes the Frobenius norm. Note that the matrix W aligns M S with M T , or say, transforms the source subspace coordinate system into the target subspace coor- dinate system. The transformed low-dimensional source- domain and target-domain instances are given by X S M S W and X T M T , respectively. Finally, a learner can be trained on the resultant transformed instances. In light of SA, a number of transfer learning approaches are established. For example, the paper by Sun and Saenko proposes an approach that aligns both the subspace bases and the distributions , which is termed as Subspace Distribution Alignment between Two Subspaces (SDA-TS). In SDA-TS, the transformation matrix W is formulated as W = M T S M T Q , where Q is a matrix used to align the distribution difference. The transformation matrix W in SA is a special case of the one in SDA-TS by setting Q to an identity matrix. Note that SA is a symmetrical feature-based approach, while SDA-TS is an asymmetrical one. In SDA- TS, the labeled source-domain instances are projected to the source subspace, then mapped to the target subspace, and ﬁnally mapped back to the target domain. The transformed source-domain instances are formulated as X S M S WM T T . Another representative subspace feature alignment ap- proach is Geodesic Flow Kernel (GFK) , which is pro- posed by Gong et al . GFK is closely related to a previous ap- proach termed Geodesic Flow Subspaces (GFS) . Before introducing GFK, let us review the steps of GFS at ﬁrst. GFS is inspired by incremental learning. Intuitively, utilizing the information conveyed by the potential path between two domains may be beneﬁcial to the domain adaptation. GFS generally takes the following steps to align features. 13 1. Subspace Generation : GFS ﬁrst generates two subspaces of the source and the target domains by performing PCA, respectively. 2. Subspace Interpolation : The two obtained subspaces can be viewed as two points on the Grassmann manifold . A ﬁnite number of the interpolated subspaces are generated between these two subspaces based on the geometric properties of the manifold. 3. Feature Projection & Stacking : The original features are transformed by stacking the corresponding projections from all the obtained subspaces. Despite the usefulness and superiority of GFS, there is a problem about how to determine the number of the interpo- lated subspaces. GFK resolves this problem by integrating inﬁnite number of the subspaces located on the geodesic curve from the source subspace to the target one. The key of GFK is to construct an inﬁnite-dimensional feature space that incorporating the information of all the subspaces lying on the geodesic ﬂow. In order to compute the inner product in the resultant inﬁnite-dimensional space, the geodesic- ﬂow kernel is deﬁned and derived. In addition, a subspace- disagreement measure is proposed to select the optimal dimensionality of the subspaces; a rank-of-domain metric is also proposed to select the optimal source domain when multi-source domains are available. Statistic feature alignment is another kind of feature alignment. For example, Sun et al. proposed an approach termed Co-Relation Alignment (CORAL) . CORAL constructs the transformation matrix of the source features by aligning the second-order statistic features, i.e., the co- variance matrices. The transformation matrix W is given by : W = arg min W || W T C S W − C T || 2 F , where C denotes the covariance matrix. Note that, com- pared to the above subspace-based approaches, CORAL avoids subspace generation as well as projection and is very easy to implement. Some transfer learning approaches are established based on spectral feature alignment. In traditional machine learn- ing area, spectral clustering is a clustering technique based on graph theory. The key of this technique is to utilize the spectrum, i.e., eigenvalues, of the similarity matrix to reduce the dimension of the features before clustering. The similarity matrix is constructed to quantitatively assess the relative similarity of each pair of data/vertices. On the basis of spectral clustering and feature alignment, Spectral Feature Alignment (SFA)  is proposed by Pan et al . SFA is an algorithm for sentiment classiﬁcation. This algorithm tries to identify the domain-speciﬁc words and domain- independent words in different domains, and then aligns these domain-speciﬁc word features to construct a low- dimensional feature representation. SFA generally contains the following ﬁve steps. 1. Feature Selection : In this step, feature selection operations are performed to select the domain- independent/pivot features. The paper presents three strategies to select domain-independent features. These strategies are based on the occurrence frequency of words, the mutual information between features and labels , and the mutual information between fea- tures and domains, respectively. 2. Similarity Matrix Construction : Once the domain-speciﬁc and the domain-independent features are identiﬁed, a bipartite graph is constructed. Each edge of this bipar- tite graph is assigned with a weight that measures the co-occurrence relationship between a domain-speciﬁc word and a domain-independent word. Based on the bipartite graph, a similarity matrix is then constructed. 3. Spectral Feature Alignment : In this step, a spectral clus- tering algorithm is adapted and performed to align domain-speciﬁc features , . Speciﬁcally, based on the eigenvectors of the graph Laplacian, a feature alignment mapping is constructed, and the domain- speciﬁc features are mapped into a low-dimensional feature space. 4. Feature Stacking : The original features and the low- dimensional features are stacked to produce the ﬁnal feature representation. 5. Learner Training : The target learner is trained on the labeled instances with the ﬁnal feature representation. There are some other spectral transfer learning ap- proaches. For example, the work by Ling et al. proposes an approach termed Cross-Domain Spectral Classiﬁer (CDSC) . The general ideas and steps of this approach are presented as follows. 1. Similarity Matrix Construction : In the ﬁrst step, two similarity matrices are constructed corresponding to the whole instances and the target-domain instances, respectively. 2. Spectral Feature Alignment : An objective function is de- signed with respect to a graph-partition indicator vec- tor; a constraint matrix is constructed, which contains pair-wise must-link information. Instead of seeking the discrete solution of the indicator vector, the solution is relaxed to be continuous, and the eigen-system problem corresponding to the objective function is solved to construct the aligned spectral features . 3. Learner Training : A traditional classiﬁer is trained on the transformed instances. To be more speciﬁc, the objective function has a form of the generalized Rayleigh quotient, which aims to ﬁnd the optimal graph partition that respects the label information with small cut-size , to maximize the separation of the target-domain instances, and to ﬁt the constraints of the pair-wise property. After eigen-decomposition, the last eigenvectors are selected and combined as a matrix, and then the matrix is normalized. Each row of the normalized matrix represents a transformed instance.",
    "M ODEL -B ASED I NTERPRETATION": "Transfer learning approaches can also be interpreted from the model perspective. Fig. 4 shows the corresponding strategies and the objectives. The main objective of a transfer learning model is to make accurate prediction results on the target domain, e.g., classiﬁcation or clustering results. Note that a transfer learning model may consist of a few sub- modules such as classiﬁers, extractors, or encoders. These sub-modules may play different roles, e.g., feature adapta- tion or pseudo label generation. In this section, some related 14 Model-Based Interpretation",
    "Objective": "Domain Adaptation ...",
    "Parameter Sharing": "Prediction Making Parameter Control Deep Learning Technique",
    "...": "Pseudo Label Generation Fig. 4. Strategies and objectives of the transfer learning approaches from the model perspective. transfer learning approaches are introduced in proper order according to the strategies shown in Fig. 4.",
    "Adversarial Deep Learning": "... Model Control",
    "Model Control Strategy": "From the perspective of model, a natural thought is to directly add the model-level regularizers to the learner’s objective function. In this way, the knowledge contained in the pre-obtained source models can be transferred into the target model during the training process. For example, the paper by Duan et al. proposes a general framework termed Domain Adaptation Machine (DAM) , , which is designed for multi-source transfer learning. The goal of DAM is to construct a robust classiﬁer for the target domain with the help of some pre-obtained base classiﬁers that are respectively trained on multiple source domains. The objective function is given by: min f T L T,L ( f T ) + λ 1 Ω D ( f T ) + λ 2 Ω( f T ) , where the ﬁrst term represents the loss function used to min- imize the classiﬁcation error of the labeled target-domain in- stances, the second term denotes different regularizers, and the third term is used to control the complexity of the ﬁnal decision function f T . Different types of the loss functions can be adopted in L T,L ( f T ) such as the square error or the cross-entropy loss. Some transfer learning approaches can be regarded as the special cases of this framework to some extent. • (Consensus Regularizer) The work by Luo et al. proposes a framework termed Consensus Regularization Frame- work (CRF) , . CRF is designed for multi-source transfer learning with no labeled target-domain instances. The framework constructs m S classiﬁers corresponding to each source domain, and these classiﬁers are required to reach mutual consensuses on the target domain. The objective function of each source classiﬁer, denoted by f S k (with k = 1 , · · · , m S ), is similar to that of DAM, which is presented below: min f S k − n Sk X i =1 log P ( y S k i | x S k i ; f S k ) + λ 2 Ω( f S k ) + λ 1 n T,U X i =1 X y j ∈Y S \u0010 1 m S m S X k 0 =1 P ( y j | x T,U i ; f S k 0 ) \u0011 , where f S k denotes the decision function corresponding to the k -th source domain, and S ( x ) = − x log x . The ﬁrst term is used to quantify the classiﬁcation error of the k -th classiﬁer on the k -th source domain, and the last term is the consensus regularizer in the form of cross- entropy. The consensus regularizer can not only enhance the agreement of all the classiﬁers, but also reduce the uncertainty of the predictions on the target domain. The authors implement this framework based on the logistic regression. A difference between DAM and CRF is that DAM explicitly constructs the target classiﬁer, while CRF makes the target predictions based on the reached consen- sus from the source classiﬁers. • (Domain-dependent Regularizer) Fast-DAM is a speciﬁc algorithm of DAM . In light of the manifold assump- tion  and the graph-based regularizer , , Fast-DAM designs a domain-dependent regularizer. The objective function is given by: min f T n T,L X j =1 \u0010 f T ( x T,L j ) − y T,L j \u0011 2 + λ 2 Ω( f T ) + λ 1 m S X k =1 β k n T,U X i =1 \u0010 f T ( x T,U i ) − f S k ( x T,U i ) \u0011 2 , where f S k ( k = 1 , 2 , · · · , m S ) denotes the pre-obtained source decision function for the k -th source domain and β k represents the weighting parameter that is determined by the relevance between the target domain and the k - th source domain and can be measured based on the MMD metric. The third term is the domain-dependent regularizer, which transfers the knowledge contained in 15 the source classiﬁer motivated by domain dependence. In , the authors also introduce and add a new term to the above objective function based on ε -insensitive loss function , which makes the resultant model have high computational efﬁciency. • (Domain-dependent Regularizer + Universum Regular- izer) Univer-DAM is an extension of the Fast-DAM . Its objective function contains an additional regularizer, i.e., Universum regularizer. This regularizer usually uti- lizes an additional dataset termed Universum where the instances do not belong to either the positive or the negative class . The authors treat the source-domain instances as the Universum for the target domain, and the objective function of Univer-DAM is presented as follows: min f T n T,L X j =1 \u0010 f T ( x T,L j ) − y T,L j \u0011 2 + λ 2 n S X j =1 \u0010 f T ( x S j ) \u0011 2 + λ 1 m S X k =1 β k n T,U X i =1 \u0010 f T ( x T,U i ) − f S k ( x T,U i ) \u0011 2 + λ 3 Ω( f T ) . Similar to Fast-DAM, the ε -insensitive loss function can also be utilized .",
    "Parameter Control Strategy": "The parameter control strategy focuses on the parameters of models. For example, in the application of object categoriza- tion, the knowledge from known source categories can be transferred into target categories via object attributes such as shape and color . The attribute priors, i.e., probabilistic distribution parameters of the image features corresponding to each attribute, can be learned from the source domain and then used to facilitate learning the target classiﬁer. The parameters of a model actually reﬂect the knowledge learned by the model. Therefore, it is possible to transfer the knowledge at the parametric level. 5.2.1 Parameter Sharing An intuitive way of controlling the parameters is to directly share the parameters of the source learner to the target learner. Parameter sharing is widely employed especially in the network-based approaches. For example, if we have a neural network for the source task, we can freeze (or say, share) most of its layers and only ﬁnetune the last few layers to produce a target network. The network-based approaches are introduced in Section 5.4. In addition to network-based parameter sharing, matrix- factorization-based parameter sharing is also workable. For example, Zhuang et al. proposed an approach for text clas- siﬁcation, which is referred to as Matrix Tri-Factorization Based Classiﬁcation Framework (MTrick) . The au- thors observe that, in different domains, different words or phrases sometimes express the same or similar connotative meaning. Thus, it is more effective to use the concepts be- hind the words rather than the words themselves as a bridge to transfer the knowledge in source domains. Different from PLSA-based transfer learning approaches that utilize the concepts by constructing Bayesian networks, MTrick attempts to ﬁnd the connections between the document classes and the concepts conveyed by the word clusters through matrix tri-factorization. These connections are con- sidered to be the stable knowledge that is supposed to be transferred. The main idea is to decompose a document-to- word matrix into three matrices, i.e., document-to-cluster, connection, and cluster-to-word matrices. Speciﬁcally, by performing the matrix tri-factorization operations on the source and the target document-to-word matrices respec- tively, a joint optimization problem is constructed, which is given by min Q,R,W || X S − Q S RW S || 2 + λ 1 || X T − Q T RW T || 2 + λ 2 || Q S − ˘ Q S || 2 s.t. Normalization Constraints , where X denotes the document-to-word matrix, Q denotes the document-to-cluster matrix, R represents the transfor- mation matrix from document clusters to word clusters, W denotes the cluster-to-word matrix, n d denotes the number of the documents, and ˘ Q S represents the label matrix. The matrix ˘ Q S is constructed based on the class information of the source-domain documents. If the i -th document belongs to the k -th class, ˘ Q S [ i,k ] = 1 . In the above objective function, the matrix R is actually the shared parameter. The ﬁrst term aims to tri-factorize the source document-to-word matrix, and the second term decomposes the target document-to- word matrix. The last term incorporates the source-domain label information. The optimization problem is solved based on the alternating iteration method. Once the solution of Q T is obtained, the class index of the k -th target-domain instance is the one with the maximum value in the k -th row of Q T . Further, Zhuang et al. extended MTrick and proposed an approach termed Triplex Transfer Learning (TriTL) . MTrick assumes that the domains share the similar con- cepts behind their word clusters. In contrast, TriTL as- sumes that the concepts of these domains can be further divided into three types, i.e., domain-independent, transfer- able domain-speciﬁc, and nontransferable domain-speciﬁc concepts, which is similar to HIDC. This idea is motivated by Dual Transfer Learning (DTL), where the concepts are assumed to be composed of the domain-independent ones and the transferable domain-speciﬁc ones . The objec- tive function of TriTL is provided as follows: min Q,R,W m S + m T X k =1 || X k − Q k \u0002 R DI R TD R ND k \u0003   W DI W TD k W ND k   || 2 s.t. Normalization Constraints , where the deﬁnitions of the symbols are similar to those of MTrick and the subscript k denotes the index of the domains with the assumption that the ﬁrst m S domains are the source domains and the last m T domains are the target do- mains. The authors proposed an iterative algorithm to solve the optimization problem. And in the initialization phase, W DI and W TD k are initialized based on the clustering results of the PLSA algorithm, while W UT k is randomly initialized; the PLSA algorithm is performed on the combination of the instances from all the domains. There are some other approaches developed based on matrix factorization. Wang et al. proposed a transfer learn- ing framework for image classiﬁcation . Wang et al. 16 proposed a softly associative approach that integrates two matrix tri-factorizations into a joint framework . Do et al. utilized matrix tri-factorization to discover both the implicit and the explicit similarities for cross-domain rec- ommendation . 5.2.2 Parameter Restriction Another parameter-control-type strategy is to restrict the parameters. Different from the parameter sharing strategy that enforces the models share some parameters, parame- ter restriction strategy only requires the parameters of the source and the target models to be similar. Take the approaches to category learning as examples. The category-learning problem is to learn a new decision function for predicting a new category (denoted by the ( k + 1) -th category) with only limited target-domain in- stances and k pre-obtained binary decision functions. The function of these pre-obtained decision functions is to pre- dict which of the k categories an instance belongs to. In order to solve the category-learning problem, Tommasi et al. proposed an approach termed Single-Model Knowledge Transfer (SMKL) . SMKL is based on Least-Squares SVM (LS-SVM). The advantage of LS-SVM is that LS-SVM transforms inequality constraints to equality constraints and has high computational efﬁciency; its optimization is equiv- alent to solving a linear equation system problem instead of a quadratic programming problem. SMKL selects one of the pre-obtained binary decision functions, and transfers the knowledge contained in its parameters. The objective function is given by min f 1 2 θ − β ˜ θ 2 + λ 2 n T,L X j =1 η j \u0010 f ( x T,L j ) − y T,L j \u0011 2 , where f ( x ) = θ · Φ( x ) + b , β is the weighting parameter controlling the transfer degree, ˜ θ is the parameter of a selected pre-obtained model, and η j is the coefﬁcient for resolving the label imbalance problem. The kernel param- eter and the tradeoff parameter are chosen based on cross- validation. In order to ﬁnd the optimal weighting parameter, the authors refer to an earlier work . In , Cawley proposed a model selection mechanism for LS-SVM, which is based on the leave-one-out cross-validation method. The superiority of this method is that the leave-one-out error for each instance can be obtained in a closed form without performing the real cross-validation experiment. Motivated by Cawley’s work, the generalization error can be easily estimated to guide the parameter setting in SMKL. Tommasi et al. further extended SMKL by utilizing all the pre-obtained decision functions. In , an approach that is referred to as Multi-Model Knowledge Transfer (MMKL) is proposed. Its objective function is presented as follows: min f 1 2 θ − k X i =1 β i θ i 2 + λ 2 n T,L X j =1 η j \u0010 f ( x T,L j ) − y T,L j \u0011 2 , where θ i and β i are the model parameter and the weighting parameter of the i -th pre-obtained decision function, respec- tively. The leave-one-out error can also be obtained in a closed form, and the optimal value of β i ( i = 1 , 2 , · · · , k ) is the one that maximizes the generalization performance.",
    "Model Ensemble Strategy": "In sentiment analysis applications related to product re- views, data or models from multiple product domains are available and can be used as the source domains . Com- bining data or models directly into a single domain may not be successful because the distributions of these domains are different from each other. Model ensemble is another commonly used strategy. This strategy aims to combine a number of weak classiﬁers to make the ﬁnal predictions. Some previously mentioned transfer learning approaches already adopted this strategy. For example, TrAdaBoost and MsTrAdaBoost ensemble the weak classiﬁers via voting and weighting, respectively. In this subsection, several typical ensemble-based transfer learning approaches are introduced to help readers better understand the function and the appliance of this strategy. As mentioned in Section 4.1, TaskTrAdaBoost, which is an extension of TrAdaBoost for handling multi-source scenarios, is proposed in the paper . TaskTrAdaBoost mainly has the following two stages. 1. Candidate Classiﬁer Construction : In the ﬁrst stage, a group of candidate classiﬁers are constructed by per- forming AdaBoost on each source domain. Note that, for each source domain, each iteration of AdaBoost re- sults in a new weak classiﬁer. In order to avoid the over- ﬁtting problem, the authors introduced a threshold to pick the suitable classiﬁers into the candidate group. 2. Classiﬁer Selection and Ensemble : In the second stage, a revised version of AdaBoost is performed on the target- domain instances to construct the ﬁnal classiﬁer. In each iteration, an optimal candidate classiﬁer which has the lowest classiﬁcation error on the labeled target-domain instances is picked out and assigned with a weight based on the classiﬁcation error. Then, the weight of each target-domain instance is updated based on the performance of the selected classiﬁer on the target do- main. After the iteration process, the selected classiﬁers are ensembled to produce the ﬁnal predictions. The difference between the original AdaBoost and the sec- ond stage of TaskTrAdaBoost is that, in each iteration, the former constructs a new candidate classiﬁer on the weighted target-domain instances, while the latter selects one pre- obtained candidate classiﬁer which has the minimal clas- siﬁcation error on the weighted target-domain instances. The paper by Gao et al. proposes another ensemble- based framework that is referred to as Locally Weighted En- semble (LWE) . LWE focuses on the ensemble process of various learners; these learners could be constructed on different source domains, or be built by performing different learning algorithms on a single source domain. Different from TaskTrAdaBoost that learns the global weight of each learner, the authors adopted the local-weight strategy, i.e., assigning adaptive weights to the learners based on the local manifold structure of the target-domain test set. In LWE, a learner is usually assigned with different weights when classifying different target-domain instances. Speciﬁcally, the authors adopt a graph-based approach to estimate the weights. The steps for weighting are outlined below. 1. Graph Construction : For the i -th source learner, a graph G T S i is constructed by using the learner to classify the 17 target-domain instances in the test set; if two instances are classiﬁed into the same class, they are connected in the graph. Another graph G T is constructed for the target-domain instances as well by performing a clustering algorithm. 2. Learner Weighting : The weight of the i -th learner for the j -th target-domain instance x T j is proportional to the similarity between the instance’s local structures in G T S i and G T . And the similarity can be measured by the percentage of the common neighbors of x T j in these two graphs. Note that this weighting scheme is based on the clustering- manifold assumption, i.e., if two instances are close to each other in a high-density region, they often have similar labels. In order to check the validity of this assumption for the task, the target task is tested on the source-domain training set(s). Speciﬁcally, the clustering quality of the training set(s) is quantiﬁed and checked by using a metric such as purity or entropy. If the clustering quality is not satisfactory, uniform weights are assigned to the learners instead. Besides, it is intuitive that if the measured structure similarity is particularly low for every learner, weighting and combining these learners seems unwise. Therefore, the authors introduce a threshold and compare it to the average similarity. If the similarity is lower than the threshold, the label of x T j is determined by the voting scheme among its reliable neighbors, where the reliable neighbors are the ones whose label predictions are made by the combined classiﬁer. The above-mentioned TaskTrAdaBoost and LWE ap- proaches mainly focus on the ensemble process. In con- trast, some studies focus more on the construction of weak learners. For example, Ensemble Framework of Anchor Adapters (ENCHOR)  is a weighting ensemble frame- work proposed by Zhuang et al . An anchor is a speciﬁc instance. Different from TrAdaBoost which adjusts weights of instances to train and produce a new learner iteratively, ENCHOR constructs a group of weak learners via using dif- ferent representations of the instances produced by anchors. The thought is that the higher similarity between a certain instance and an anchor, the more likely the feature of that in- stance remains unchanged relative to the anchor, where the similarity can be measured by using the cosine or Gaussian distance function. ENCHOR contains the following steps. 1. Anchor Selection : In this step, a group of anchors are selected. These anchors can be selected based on some rules or even randomly. In order to improve the ﬁ- nal performance of ENCHOR, the authors proposed a method of selecting high-quality anchors . 2. Anchor-based Representation Generation : For each anchor and each instance, the feature vector of an instance is directly multiplied by a coefﬁcient that measures the distance from the instance to the anchor. In this way, each anchor produces a new pair of anchor-adapted source and target instance sets. 3. Learner Training and Ensemble : The obtained pairs of instance sets can be respectively used to train learners. Then, the resultant learners are weighted and combined to make the ﬁnal predictions. The framework ENCHOR is easy to be realized in a parallel manner in that the operations performed on each anchor are independent.",
    "Deep Learning Technique": "Deep learning methods are particularly popular in the ﬁeld of machine learning. Many researchers utilize the deep learning techniques to construct transfer learning models. For example, the SDA and the mSLDA approaches men- tioned in Section 4.2.6 utilize the deep learning techniques. In this subsection, we speciﬁcally discuss the deep-learning- related transfer learning models. The deep learning ap- proaches introduced are divided into two types, i.e., non- adversarial (or say, traditional) ones and adversarial ones. 5.4.1 Traditional Deep Learning As said earlier, autoencoders are often used in deep learning area. In addition to SDA and mSLDA, there are some other reconstruction-based transfer learning approaches. For ex- ample, the paper by Zhuang et al. proposes an approach termed Transfer Learning with Deep Autoencoders (TLDA) , . TLDA adopts two autoencoders for the source and the target domains, respectively. These two autoen- coders share the same parameters. The encoder and the decoder both have two layers with activation functions. The diagram of the two autoencoders is presented as follows: X S ( W 1 ,b 1 ) −−−−−→ Q S ( W 2 ,b 2 ) −−−−−−−−−−→ Softmax Regression R S ( ˆ W 2 , ˆ b 2 ) −−−−−→ ˜ Q S ( ˆ W 1 , ˆ b 1 ) −−−−−→ ˜ X S , ⇑ KL Divergence ⇓ X T ( W 1 ,b 1 ) −−−−−→ Q T ( W 2 ,b 2 ) −−−−−−−−−−→ Softmax Regression R T ( ˆ W 2 , ˆ b 2 ) −−−−−→ ˜ Q T ( ˆ W 1 , ˆ b 1 ) −−−−−→ ˜ X T . There are several objectives of TLDA, which are listed as follows. 1. Reconstruction Error Minimization : The output of the de- coder should be extremely close to the input of encoder. In other words, the distance between X S and ˜ X S as well as the distance between X T and ˜ X T should be minimized. 2. Distribution Adaptation : The distribution difference be- tween Q S and Q T should be minimized. 3. Regression Error Minimization : The output of the encoder on the labeled source-domain instances, i.e., R S , should be consistent with the corresponding label information Y S . Therefore, the objective function of TLDA is given by min Θ L REC ( X, ˜ X ) + λ 1 KL ( Q S || Q T ) + λ 2 Ω( W, b, ˆ W, ˆ b ) + λ 3 L REG ( R S , Y S ) , where the ﬁrst term represents the reconstruction error, KL ( · ) represents the KL divergence, the third term controls the complexity, and the last term represents the regression error. TLDA is trained by using a gradient descent method. The ﬁnal predictions can be made in two different ways. The ﬁrst way is to directly use the output of the encoder to make predictions. And the second way is to treat the autoencoder as a feature extractor, and then train the target classiﬁer on the labeled instances with the feature representation produced by the encoder’s ﬁrst-layer output. 18 In addition to the reconstruction-based domain adapta- tion, discrepancy-based domain adaptation is also a popular direction. In earlier research, the shallow neural networks are tried to learn the domain-independent feature repre- sentation . It is found that the shallow architectures often make it difﬁcult for the resultant models to achieve excellent performance. Therefore, many studies turn to uti- lize deep neural networks. Tzeng et al.  added a single adaptation layer and a discrepancy loss to the deep neural network, which improves the performance. Further, Long et al. performed multi-layer adaptation and utilized multi- kernel technique, and they proposed an architecture termed Deep Adaptation Networks (DAN) . For better understanding, let us review DAN in detail. DAN is based on AlexNet  and its architecture is presented below . full −−→ 6th R S 6 full −−→ 7th R S 7 full −−→ 8th R S 8 \u0010 f ( X S ) \u0011 X S X T conv −−→ 1st Q S 1 Q T 1 conv −−→ ··· Q S 5 Q T 5 | {z } ր ց ⇑ MK-MMD ⇓ ⇑ MK-MMD ⇓ ⇑ MK-MMD ⇓ Five Convolutional Layers full −−→ 6th R T 6 full −−→ 7th R T 7 full −−→ 8th R T 8 \u0010 f ( X T ) \u0011 | {z } Three Fully Connected Layers In the above network, the features are ﬁrst extracted by ﬁve convolutional layers in a general-to-speciﬁc manner. Next, the extracted features are fed into one of the two fully connected networks switched by their original domains. These two networks both consist of three fully connected layers that are specialized for the source and the target domains. DAN has the following objectives. 1. Classiﬁcation Error Minimization : The classiﬁcation error of the labeled instances should be minimized. The cross-entropy loss function is adopted to measure the prediction error of the labeled instances. 2. Distribution Adaptation : Multiple layers, which include the representation layers and the output layer, can be jointly adapted in a layer-wise manner. Instead of using the single-kernel MMD to measure the distribution difference, the authors turn to MK-MMD. The authors adopt the linear-time unbiased estimation of MK-MMD to avoid numerous inner product operations . 3. Kernel Parameter Optimization : The weighting parame- ters of the multiple kernels in MK-MMD should be optimized to maximize the test power . The objective function of the DAN network is given by: min Θ max κ n L X i =1 L \u0010 f ( x L i ) , y L i \u0011 + λ 8 X l =6 MK-MMD ( R S l , R T l ; κ ) , where l denotes the index of the layer. The above opti- mization is actually a minimax optimization problem. The maximization of the objective function with respect to the kernel function κ aims to maximize the test power. After this step, the subtle difference between the source and the target domains are magniﬁed. This train of thought is similar to the Generative Adversarial Network (GAN) . In the training process, the DAN network is initialized by a pre- trained AlexNet . There are two categories of param- eters that should be learned, i.e., the network parameters and the weighting parameters of the multiple kernels. Given that the ﬁrst three convolutional layers output the general features and are transferable, the authors freeze them and ﬁne-turn the last two convolutional layers and the two fully connected layers . The last fully connected layer (or say, the classiﬁer layer) is trained from scratch. Long et al. further extended the above DAN approach and proposed the DAN framework . The new charac- teristics are summarized as follows. 1. Regularizer Adding : The framework introduces an ad- ditional regularizer to minimize the uncertainty of the predicted labels of the unlabeled target-domain in- stances, which is motivated by entropy minimization criterion . 2. Architecture Generalizing : The DAN framework can be applied to many other architectures such as GoogLeNet  and ResNet . 3. Measurement Generalizing : The distribution difference can be estimated by other metrics. For example, in addition to MK-MMD, the authors also present the Mean Embedding test for distribution adaptation . The objective function of the DAN framework is given by: min Θ max κ n L X i =1 L \u0010 f ( x L i ) , y L i \u0011 + λ 1 l end X l = l strt DIST ( R S l , R T l ) + λ 2 n T,U X i =1 X y j ∈Y S \u0010 P ( y j | f ( x T,U i )) \u0011 , where l strt and l end denote the boundary indexes of the fully connected layers for adapting the distributions. There are some other impressive works. For example, Long et al. constructed residual transfer networks for do- main adaptation, which is motivated by deep residual learn- ing . Besides, another work by Long et al. proposes the Joint Adaptation Network (JAN) , which adapts the joint distribution difference of multiple layers. Sun and Saenko extended CORAL for deep domain adaptation and proposed an approach termed Deep CORAL (DCORAL), in which the CORAL loss is added to minimize the feature covariance . Chen et al. realized that the instances with the same label should be close to each other in the feature space, and they not only add the CORAL loss but also add an instance-based class-level discrepancy loss . Pan et al. constructed three prototypical networks (corresponding to D S , D T and D S ∪D T ) and incorporated the thought of multi-model consensus. They also adopt pseudo-label strategy and adapt both the instance-level and class-level discrepancy . Kang et al. proposed the Contrastive Adaptation Network (CAN), which is based on the dis- crepancy metric termed contrastive domain discrepancy . Zhu et al. aimed to adapt the extracted multiple fea- ture representations and proposed the Multi-Representation Adaptation Network (MRAN) . Deep learning technique can also be used for multi- source transfer learning. For example, the work by Zhu et al. proposes a framework that is referred to as Multiple Feature Spaces Adaptation Network (MFSAN) . The architec- ture of MFSAN consists of a common-feature extractor, m S domain-speciﬁc feature extractors, and m S domain-speciﬁc 19 classiﬁers. The corresponding schematic diagram is shown below. X S 1 · · · X S k · · · X S m S X T Common −−−−−→ Extractor Q S 1 · · · Q S k · · · Q S m S Q T Domain-Speciﬁc −−−−−−−−−→ Extractors R S 1 · · · R S k · · · R S m S R T 1 · · · R T k · · · R T m S Domain-Speciﬁc −−−−−−−−−→ Classiﬁers ˆ Y S 1 · · · ˆ Y S k · · · ˆ Y S m S ˆ Y T 1 · · · ˆ Y T k · · · ˆ Y T m S In each iteration, MFSAN has the following steps. 1. Common Feature Extraction : For each source domain (denoted by D S k with k = 1 , · · · , m S ), the source- domain instances (denoted by X S k ) are separately input to the common-feature extractor to produce instances in a common latent feature space (denoted by Q S k ). Similar operations are also performed on the target-domain instances (denoted by X T ), which produces Q T . 2. Speciﬁc Feature Extraction : For each source domain, the extracted common features Q S k is fed to the k - th domain-speciﬁc feature extractor. Meanwhile, Q T is fed to all the domain-speciﬁc feature extractors, which results in R T k with k = 1 , · · · , m S . 3. Data Classiﬁcation : The output of the k -th domain- speciﬁc feature extractor is input to the k -th classiﬁer. In this way, m S pairs of the classiﬁcation results are predicted in the form of probability. 4. Parameter Updating : The parameters of the network are updated to optimize the objective function. There are three objectives in MFSAN, i.e., classiﬁcation error minimization, distribution adaptation, and consensus regularization. The objective function is given by: min Θ m S X i =1 L ( ˆ Y S i , Y S i ) + λ 1 m S X i =1 MMD ( R S i , R T i ) + λ 2 m S X i ̸ = j ˆ Y T i − ˆ Y T j , where the ﬁrst term represents the classiﬁcation error of the labeled source-domain instances, the second term measures the distribution difference, and the third term measures the discrepancy of the predictions on the target-domain instances. 5.4.2 Adversarial Deep Learning The thought of adversarial learning can be integrated into deep-learning-based transfer learning approaches. As men- tioned above, in the DAN framework, the network Θ and the kernel κ play a minimax game, which reﬂects the thought of adversarial learning. However, the DAN frame- work is a little different from the traditional GAN-based methods in terms of the adversarial matching. In the DAN framework, there is only a few parameters to be optimized in the max game, which makes the optimization easier to achieve equilibrium. Before introducing the adversarial transfer learning approaches, let us brieﬂy review the origi- nal GAN framework and the related work. The original GAN , which is inspired by the two- player game, is composed of two models, a generator G and a discriminator D . The generator produces the counterfeits of the true data for the purpose of confusing the discrimina- tor and making the discriminator produce wrong detection. The discriminator is fed with the mixture of the true data and the counterfeits, and it aims to detect whether a data is the true one or the fake one. These two models actually play a two-player minimax game, and the objective function is as follows: min G max D E x ∼ P true [log D ( x )] + E ˜ z ∼ P ˜ z [log (1 − D ( G (˜ z )))] , where ˜ z represents the noise instances (sampled from a certain noise distribution) used as the input of the generator for producing the counterfeits. The entire GAN can be trained by using the back-propagation algorithm. When the two-player game achieves equilibrium, the generator can produce almost true-looking instances. Motivated by GAN, many transfer learning approaches are established based on the assumption that a good feature representation contains almost no discriminative informa- tion about the instances’ original domains. For example, the work by Ganin et al. proposes a deep architecture termed Domain-Adversarial Neural Network (DANN) for domain adaptation , . DANN assumes that there is no labeled target-domain instance to work with. Its architec- ture consists of a feature extractor, a label predictor, and a domain classiﬁer. The corresponding diagram is as follows. Label −−−−−→ Predictor ˆ Y S,L ˆ Y T,U X S,L X T,U Feature −−−−−→ Extractor ↑ Q S,L Q T,U \u001b Domain −−−−−→ Classiﬁer ˆ S ˆ T ( Domain Label ) The feature extractor acts like the generator, which aims to produce the domain-independent feature representation for confusing the domain classiﬁer. The domain classiﬁer plays the role like the discriminator, which attempts to detect whether the extracted features come from the source domain or the target domain. Besides, the label predictor produces the label prediction of the instances, which is trained on the extracted features of the labeled source-domain instances, i.e., Q S,L . DANN can be trained by inserting a special gra- dient reversal layer (GRL). After the training of the whole system, the feature extractor learns the deep feature of the instances, and the output ˆ Y T,U is the predicted labels of the unlabeled target-domain instances. There are some other related impressive works. The work by Tzeng et al. proposes a uniﬁed adversarial domain adaptation framework . The work by Shen et al. adopts Wasserstein distance for domain adaptation . Hoffman et al. adopted cycle-consistency loss to ensure the structural and semantic consistency . Long et al. proposed the Conditional Domain Adversarial Network (CDAN), which utilizes a conditional domain discriminator to assist adver- sarial adaptation . Zhang et al. adopted a symmetric design for the source and the target classiﬁers . Zhao et al. utilized domain adversarial networks to solve the multi- source transfer learning problem . Yu et al. proposed a dynamic adversarial adaptation network . Some approaches are designed for some special scenar- ios. Take the partial transfer learning as an example. The partial transfer learning approaches are designed for the sce- nario that the target-domain classes are less than the source- domain classes, i.e., Y S ⊆Y T . In this case, the source- domain instances with different labels may have different 20 importance for domain adaptation. To be more speciﬁc, the source-domain and the target-domain instances with the same label are more likely to be potentially associated. How- ever, since the target-domain instances are unlabeled, how to identify and partially transfer the important information from the labeled source-domain instances is a critical issue. The paper by Zhang et al. proposes an approach for partial domain adaptation, which is called Impor- tance Weighted Adversarial Nets-Based Domain Adaptation (IWANDA) . The architecture of IWANDA is different from that of DANN. DANN adopts one common feature extractor based on the assumption that there exists a com- mon feature space where Q S,L and Q T,U have the similar distribution. However, IWANDA uses two domain-speciﬁc feature extractors for the source and the target domains, respectively. Speciﬁcally, IWANDA consists of two feature extractors, two domain classiﬁers, and one label predictor. The diagram of IWANDA is presented below. Label −−−−−→ Predictor ˆ Y S,L ˆ Y T,U X S,L Source Feature −−−−−−−−→ Extractor ↑ Q S,L X T,U Target Feature −−−−−−−→ Extractor Q T,U ↓ \u001b + β S −−−−→ + ˆ Y T,U 2nd Domain −−−−−−→ Classiﬁer ˆ S 2 ˆ T 2 1st Domain −−−−−−→ Classiﬁer ˆ S 1 ˆ T 1 Weight −−−−−→ Function β S Before training, the source feature extractor and the label predictor are pre-trained on the labeled source-domain in- stances. These two components are frozen in the training process, which means that only the target feature extractor and the domain classiﬁers should be optimized. In each iteration, the above network is optimized by taking the following steps. 1. Instance Weighting : In order to solve the partial transfer issue, the source-domain instances are assigned with weights based on the output of the ﬁrst domain clas- siﬁer. The ﬁrst domain classiﬁer is fed with Q S,L and Q T,U , and then outputs the probabilistic predictions of their domains. If a source domain instance is predicted with a high probability of belonging to the target do- main, this instance is highly likely to associate with the target domain. Thus, this instance is assigned with a larger weight and vice versa. 2. Prediction Making : The label predictor outputs the label predictions of the instances. The second classiﬁer pre- dicts which domain an instance belongs to. 3. Parameter Updating : The ﬁrst classiﬁer is optimized to minimize the domain classiﬁcation error. The second classiﬁer plays a minmax game with the target fea- ture extractor. This classiﬁer aims to detect whether a instance is the instance from the target domain or the weighted instance from the source domain, and to reduce the uncertainty of the label prediction ˆ Y T,U . The target feature extractor aims to confuse the second classiﬁer. These components can be optimized in a similar way to GAN or by inserting a GRL. In addition to IWANDA, the work by Cao et al. con- structs the selective adversarial network for partial transfer learning . There are some other studies related to transfer learning. For example, the work by Wang et al. proposes a minimax-based approach to select high-quality source-domain data . Chen et al. investigated the trans- ferability and the discriminability in the adversarial domain adaptation, and proposed a spectral penalization approach to boost the existing adversarial transfer learning methods .",
    "A PPLICATION": "In previous sections, a number of representative trans- fer learning approaches are introduced, which have been applied to solving a variety of text-related/image-related problems in their original papers. For example, MTrick  and TriTL  utilize the matrix factorization technique to solve cross-domain text classiﬁcation problems; the deep- learning-based approaches such as DAN , DCORAL , and DANN ,  are applied to solving image classiﬁcation problems. Instead of focusing on the general text-related or image-related applications, in this section, we mainly focus on the transfer learning applications in speciﬁc areas such as medicine, bioinformatics, transportation, and recommender systems.",
    "Medical Application": "Medical imaging plays an important role in the medical area, which is a powerful tool for diagnosis. With the de- velopment of computer technology such as machine learn- ing, computer-aided diagnosis has become a popular and promising direction. Note that medical images are gener- ated by special medical equipment, and their labeling often relies on experienced doctors. Therefore, in many cases, it is expensive and hard to collect sufﬁcient training data. Trans- fer learning technology can be utilized for medical imaging analysis. A commonly used transfer learning approach is to pre-train a neural network on the source domain (e.g., ImageNet, which is an image database containing more than fourteen million annotated images with more than twenty thousand categories ) and then ﬁnetune it based on the instances from the target domain. For example, Maqsood et al. ﬁnetuned the AlexNet  for the detection of Alzheimer’s disease . Their ap- proach has the following four steps. First, the MRI images from the target domain are pre-processed by performing contrast stretching operations. Second, the AlexNet architec- ture  is pre-trained over ImageNet  (i.e., the source domain) as a starting point to learn the new task. Third, the convolutional layers of AlexNet are ﬁxed, and the last three fully connected layers are replaced by the new ones including one softmax layer, one fully connected layer, and one output layer. Finally, the modiﬁed AlexNet is ﬁnetuned by training on the Alzheimer’s dataset  (i.e., the target domain). The experimental results show that the proposed approach achieves the highest accuracy for the multi-class classiﬁcation problem (i.e, Alzheimer’s stage detection). Similarly, Shin et al. ﬁnetuned the pre-trained deep neural network for solving the computer-aided detection problems . Byra et al. utilized the transfer learning tech- nology to help assess knee osteoarthritis . In addition to imaging analysis, transfer learning has some other applica- tions in the medical area. For example, the work by Tang et 21 al. combines the active learning and the domain adaptation technologies for the classiﬁcation of various medical data . Zeng et al. utilized transfer learning for automatically encoding ICD-9 codes that are used to describe a patient’s diagnosis .",
    "Bioinformatics Application": "Biological sequence analysis is an important task in the bioinformatics area. Since the understanding of some or- ganisms can be transferred to other organisms, transfer learning can be applied to facilitate the biological sequence analysis. The distribution difference problem exists signiﬁ- cantly in this application. For example, the function of some biological substances may remain unchanged but with the composition changed between two organisms, which may result in the marginal distribution difference. Besides, if two organisms have a common ancestor but with long evo- lutionary distance, the conditional distribution difference would be signiﬁcant. The work by Schweikert et al. uses the mRNA splice site prediction problem as the example to analyze the effectiveness of transfer learning approaches . In their experiments, the source domain contains the sequence instances from a well-studied model organism, i.e., C. elegans , and the target organisms include two additional nematodes (i.e., C. remanei and P. paciﬁcus ), D. melanogaster , and the plant A. thaliana . A number of transfer learning approaches, e.g., FAM  and the variant of KMM , are compared with each other. The experimental results show that transfer learning can help improve the classiﬁcation performance. Another widely encountered task in the bioinformatics area is gene expression analysis, e.g., predicting associations between genes and phenotypes. In this application, one of the main challenges is the data sparsity problem, since there is usually very little data of the known associations. Transfer learning can be used to leverage this problem by providing additional information and knowledge. For example, Petegrosso et al.  proposed a transfer learn- ing approach to analyze and predict the gene-phenotype associations based on the Label Propagation Algorithm (LPA) . LPA utilizes the Protein-Protein Interaction (PPI) network and the initial labeling to predict the target associations based on the assumption that the genes that are connected in the PPI network should have the similar labels. The authors extended LPA by incorporating multi-task and transfer-learning technologies. First, Human Phenotype On- tology (HPO), which provides a standardized vocabulary of phenotypic features of human diseases, is utilized to form the auxiliary task. In this way, the associations can be predicted by utilizing phenotype paths and both the linkage knowledge in HPO and in the PPI network; the interacted genes in PPI are more likely to be associated with the same phenotype and the connected phenotypes in HPO are more likely to be associated with the same gene. Second, Gene Ontology (GO), which contains the association information between gene functions and genes, is used as the source domain. Additional regularizers are designed, and the PPI network and the common genes are used as the bridge for knowledge transfer. The gene-GO term and gene-HPO phenotype associations are constructed simultaneously for all the genes in the PPI network. By transferring additional knowledge, the predicted gene-phenotype associations can be more reliable. Transfer learning can also be applied to solving the PPI prediction problems. Xu et al.  proposed an approach to transfer the linkage knowledge from the source PPI network to the target one. The proposed approach is based on the collective matrix factorization technique , where a factor matrix is shared across domains.",
    "Transportation Application": "One application of transfer learning in the transportation area is to understand the trafﬁc scene images. In this applica- tion, a challenge problem is that the images taken from a cer- tain location often suffer from variations because of different weather and light conditions. In order to solve this problem, Di et al. proposed an approach that attempts to transfer the information of the images that were taken from the same location in different conditions . In the ﬁrst step, a pre- trained network is ﬁnetuned to extract the feature represen- tations of images. In the second step, the feature transfor- mation strategy is adopted to construct a new feature rep- resentation. Speciﬁcally, the dimension reduction algorithm (i.e., partial least squares regression ) is performed on the extracted features to generate low-dimension features. Then, a transformation matrix is learned to minimize the domain discrepancy of the dimension-reduced data. Next, the subspace alignment operations are adopted to further reduce the domain discrepancy. Note that, although images under different conditions often have different appearances, they often have the similar layout structure. Therefore, in the ﬁnal step, the cross-domain dense correspondences are established between the test image and the retrieved best matching image at ﬁrst, and then the annotations of the best matching image are transferred to the test image via the Markov random ﬁeld model , . Transfer learning can also be applied to the task of driver behavior modeling. In this task, sufﬁcient personalized data of each individual driver are usually unavailable. In such situations, transferring the knowledge contained in the his- torical data for the newly-involved driver is a promising alternative. For example, Lu et al. proposed an approach to driver model adaptation in lane-changing scenarios . The source domain contains the sufﬁcient data describing the behavior of the source drivers, while the target domain has a few numbers of data about the target driver. In the ﬁrst step, the data from both domains are pre-processed by performing PCA to generate low-dimension features. The authors assume that the source and the target data are from two manifolds. Therefore, in the second step, a manifold alignment approach is adopted for domain adap- tation. Speciﬁcally, the dynamic time warping algorithm  is applied to measuring similarity and ﬁnding the corresponding source-domain data point of each target- domain data point. Then, local Procrustes analysis  is adopted to align the two manifolds based on the obtained correspondences between data points. In this way, the data from the source domain can be transferred to the target domain. And in the ﬁnal step, a stochastic modeling method (e.g., Gaussian mixture regression ) is used to model 22 the behavior of the target driver. The experimental results demonstrate that the transfer learning approach can help the target driver even when few target-domain data are available. Besides, the results also show that when the number of target instances are very small or very large, the superiority of their approach is not obvious. This may because the relationship across domains cannot be found exactly with few target-domain instances, and in the case of sufﬁcient target-domain instances, the necessity of transfer learning is reduced. Besides, there are some other applications of transfer learning in the transportation area. For example, Liu et al. applied transfer learning to driver poses recognition . Wang et al. adopted the regularization technique in transfer learning for vehicle type recognition . Transfer learning can also be utilized for anomalous activity detection , , trafﬁc sign recognition , etc.",
    "Recommender-System Application": "Due to the rapid increase of the amount of information, how to effectively recommend the personalized content for individual users is an important issue. In the ﬁeld of recommender systems, some traditional recommendation methods, e.g., factorization-based collaborative ﬁltering, of- ten rely on the factorization of the user-item interaction matrix to obtain the predictive function. These methods often require a large amount of training data to make accurate recommendations. However, the necessary training data, e.g., the historical interaction data, are often sparse in real-world scenarios. Besides, for new registered users or new items, traditional methods are often hard to make effective recommendations, which is also known as the cold- start problem. Recognizing the above-mentioned problems in recom- mender systems, kinds of transfer learning approaches, e.g., instance-based and feature-based approaches, have been proposed. These approaches attempt to make use of the data from other recommender systems (i.e., the source domains) to help construct the recommender system in the target domain. Instance-based approaches mainly focus on transferring different types of instances, e.g., ratings, feedbacks, and examinations, from the source domain to the target domain. The work by Pan et al.  leverages the uncertain ratings (represented as rating distributions) of the source domain for knowledge transfer. Speciﬁcally, the source-domain uncertain ratings are used as constraints to help complete the rating matrix factorization task on the target domain. Hu et al.  proposed an approach termed transfer meeting hybrid, which extracts the knowledge from unstructured text by using an attentive memory network and selectively transfer the useful information. Feature-based approaches often leverage and transfer the information from a latent feature space. For example, Pan et al. proposed an approach termed Coordinate System Transfer (CST)  to leverage both the user-side and the item-side latent features. The source-domain instances come from another recommender system, sharing common users and items with the target domain. CST is developed based on the assumption that the principle coordinates, which reﬂect the tastes of users or the factors of items, character- ize the domain-independent structure and are transferable across domains. CST ﬁrst constructs two principle coordi- nate systems, which are actually the latent features of users and items, by applying sparse matrix tri-factorization on the source-domain data, and then transfer the coordinate systems to the target domain by setting them as constraints. The experimental results show that CST signiﬁcantly out- performs the non-transfer baselines (i.e., average ﬁlling model and latent factorization model) in all data sparsity levels . There are some other studies about cross-domain rec- ommendation , , , . For example, He et al. proposed a transfer learning framework based on the Bayesian neural network . Zhu et al.  proposed a deep framework, which ﬁrst generates the user and item feature representations based on the matrix factorization technique, and then employs a deep neural network to learn the mapping of features across domains. Yuan et al.  proposed a deep domain adaptation approach based on autoencoders and a modiﬁed DANN ,  to extract and transfer the instances from rating matrices.",
    "Communication Application : In addition to WiFi localiza-": "tion tasks , , transfer learning has also been employed in wireless-network applications. For example, Bastug et al. proposed a caching mechanism ; the knowledge contained in contextual information, which is extracted from the interactions between devices, is transferred to the target domain. Besides, some studies focus on the energy saving problems. The work by Li et al. proposes an energy saving scheme for cellular radio access networks, which utilizes the transfer-learning expertise . The work by Zhao and Grace applies transfer learning to topology management for reducing energy consumption .",
    "Urban-Computing Application : With a large amount of": "data related to our cities, urban-computing is a promis- ing researching track in directions of trafﬁc monitoring, health care, social security, etc. Transfer learning has been applied to alleviate the data scarcity problem in many urban computing applications. For example, Guo et al.  proposed an approach for chain store site recommendation, which leverages the knowledge from semantically-relevant domains (e.g., other cities with the same store and other chain stores in the target city) to the target city. Wei et al.  proposed a ﬂexible multi-modal transfer learning approach that transfers knowledge from a city that have sufﬁcient multi-model data and labels to the target city to alleviate the data sparsity problem. Transfer learning has been applied to some recognition tasks such as hand gesture recognition , face recogni- tion , activity recognition , and speech emotion recognition . Besides, transfer-learning expertise has also been incorporated into some other areas such as sen- timent analysis , , , fraud detection , social network , and hyperspectral image analysis , .",
    "E XPERIMENT": "Transfer learning techniques have been successfully applied in many real-world applications. In this section, we perform 23 experiments to evaluate the performance of some represen- tative transfer learning models 1  of different categories on two mainstream research areas, i.e., object recognition and text classiﬁcation. The datasets are introduced at ﬁrst. Then, the experimental results and further analyses are provided.",
    "Dataset and Preprocessing": "Three datasets are studied in the experiments, i.e., Ofﬁce- 31, Reuters-21578, and Amazon Reviews. For simplicity, we focus on the classiﬁcation tasks. The statistical information of the preprocessed datasets is listed in Table 3. • Amazon Reviews 2  is a multi-domain sentiment dataset which contains product reviews taken from Ama- zon.com of four domains (Books, Kitchen, Electronics and DVDs). Each review in the four domains has a text and a rating from zero to ﬁve. In the experiments, the ratios that are less than three are deﬁned as the negative ones, while others are deﬁned as the positive ones. The frequency of each word in all reviews is calculated. Then, the ﬁve thousand words with the highest frequency are selected as the attributes of each review. In this way, we ﬁnally have 1000 positive instances, 1000 negative instances, and about 5000 unlabeled instances in each domain. In the experiments, every two of the four domains are selected to generate twelve tasks. • Reuters-21578 3 is a dataset for text categorization, which has a hierarchical structure. The dataset contains 5 top categories (Exchanges, Orgs, People, Places, Topics). In out experiment, we use the top three big category Orgs, People and Places to generate three classiﬁcation tasks (Orgs vs People, Orgs vs Places and People vs Places). In each task, the subcategories in the corresponding two categories are separately divided into two parts. Then, the resultant four parts are used as the components to form two domains. Each domain has about 1000 instances, and each instance has about 4500 features. Speciﬁcally, taking the task Orgs vs People as an example, one part from Orgs and one part from People and combined to form the source domain; similarly, the rest two parts form the target domain. Note that the instances in the three categories are all labeled. In order to generate the unlabeled instances, the labeled instances are selected from the dataset, and their labels are ignored. • Ofﬁce-31  is an object recognition dataset which contains thirty-one categories and three domains, i.e., Amazon, Webcam, and DSLR. These three domains have 2817, 498, and 795 instances, respectively. The images in Amazon are the online e-commerce pictures taken from Amazon.com. The images in Webcam are the low- resolution pictures taken by web cameras. And the im- ages in DSLR are the high-resolution pictures taken by DSLR cameras. In the experiments, every two of the three domains (with the order considered) are selected as the source and the target domains, which results in six tasks. 1. https://github.com/FuzhenZhuang/Transfer-Learning-Toolkit 2. http://www.cs.jhu.edu/ mdredze/datasets/sentiment/ 3. https://archive.ics.uci.edu/ml/datasets/Reuters- 21578+Text+Categorization+Collection",
    "(ĺ%": "HIDC TriTL CD-PLSA MTrick SFA mSLDA SDA GFK SCL TCA Baseline Fig. 5. Comparison results on Amazon Reviews.",
    "Experiment Setting": "Experiments are conducted to compare some representative transfer learning models. Speciﬁcally, eight algorithms are performed on the dataset Ofﬁce-31 for solving the object recognition problem. Besides, fourteen algorithms are per- formed and evaluated on the dataset Reuters-21578 for solving the text classiﬁcation problem. In the sentiment classiﬁcation problem, eleven algorithms are performed on Amazon Reviews. The classiﬁcation results are evaluated by accuracy, which is deﬁned as follows: accuracy = |{ x | x i ∈D test ∧ f ( x i ) = y i }| |D test | where D test denotes the test data and y denotes the truth classiﬁcation label; f ( x ) represents the predicted classiﬁca- tion result. Note that some algorithms need the base classi- ﬁer. In these cases, an SVM with a linear kernel is adopted as the base classiﬁer in the experiments. Besides, the source- domain instances are all labeled. And for the performed al- gorithms (except TrAdaBoost), the target-domain instances are unlabeled. Each algorithm was executed three times, and the average results are adopted as our experimental results. The evaluated transfer learning models include: HIDC , TriTL , CD-PLSA , , MTrick , SFA , mSLDA , , SDA , GFK , SCL , TCA , , CoCC , JDA , TrAdaBoost , DAN , DCORAL , MRAN , CDAN , DANN , , JAN , and CAN .",
    "Experiment Result": "In this subsection, we compare over twenty algorithms on three datasets in total. The parameters of all algorithms are set to the default values or the recommended values mentioned in the original papers. The experimental results are presented in Tables 4, 5, and 6 corresponding to Amazon Reviews, Reuters-21578, and Ofﬁce-31, respectively. In order to allow readers to understand the experimental results more intuitively, three radar maps, i.e., Figs. 5, 6, and 7, are provided, which visualize the experimental results. In the radar maps, each direction represents a task. The general performance of an algorithm is demonstrated by a polygon 24 TABLE 3 Statistical information of the preprocessed datasets. Area Dataset Domain Attribute Total Instances Tasks Sentiment Classiﬁcation Amazon Reviews 4 5000 27677 12 Text Classiﬁcation Reuters-21578 3 4772 6570 3 Object Recognition Ofﬁce-31 3 800 4110 6",
    "Orgs vs People": "SDA TriTL SCL TCA JDA TrAdaBoost Baseline Fig. 6. Comparison results on Reuters-21578. TABLE 4 Accuracy performance on the Amazon Reviews of four domains: Kitchen (K), Electronics (E), DVDs (D) and Books (B). Model K → D K → B K → E D → K D → B D → E B → K B → D B → E E → K E → D E → B Average HIDC 0.8800 0.8750 0.8800 0.7925 0.8100 0.8025 0.7925 0.8175 0.8075 0.8075 0.8700 0.8700 0.8338 TriTL 0.7150 0.7250 0.6775 0.5725 0.5250 0.5775 0.6150 0.6125 0.6000 0.6250 0.6100 0.6150 0.6225 CD-PLSA 0.7475 0.7225 0.7200 0.6075 0.6175 0.6075 0.5750 0.6100 0.6425 0.7225 0.7450 0.7000 0.6681 MTrick 0.8200 0.8350 0.8125 0.7725 0.7475 0.7275 0.7550 0.7450 0.7800 0.7900 0.7975 0.8100 0.7827 SFA 0.8525 0.8575 0.8675 0.7825 0.8050 0.7750 0.7925 0.7850 0.7775 0.8400 0.8525 0.8400 0.8190 mSLDA 0.7975 0.7825 0.7925 0.6350 0.6450 0.6325 0.6525 0.6675 0.6625 0.7225 0.7150 0.7125 0.7015 SDA 0.8425 0.7925 0.8025 0.7450 0.7600 0.7650 0.7625 0.7475 0.7425 0.8175 0.8050 0.8100 0.7827 GFK 0.6200 0.6275 0.6325 0.6200 0.6100 0.6225 0.5800 0.5650 0.5725 0.6575 0.6500 0.6325 0.6158 SCL 0.8575 0.8625 0.8725 0.7800 0.7850 0.7825 0.7925 0.7925 0.7825 0.8425 0.8525 0.8450 0.8206 TCA 0.7550 0.7550 0.7550 0.6475 0.6475 0.6500 0.5800 0.5825 0.5850 0.7175 0.7150 0.7125 0.6752 Baseline 0.7270 0.7090 0.8270 0.7400 0.7280 0.7300 0.7450 0.7720 0.7080 0.8400 0.7060 0.7070 0.7449 whose vertices representing the accuracy of the algorithm for dealing with different tasks. Table 4 shows the experimental results on Amazon Re- views. The baseline is a linear classiﬁer trained only on the source domain (here we directly use the results from the paper ). Fig. 5 visualizes the results. As shown in Fig. 5, most algorithms are relatively well-performed when the source domain is electronics or kitchen, which indicates that these two domains may contains more transferable information than the other two domains. In addition, it can be observed that HIDC, SCL, SFA, MTrick and SDA perform well and relatively stable in all the twelve tasks. Meanwhile, other algorithms, especially mSLDA, CD-PLSA, and TriTL, are relatively unstable; the performance of them ﬂuctuates in a range about twenty percent. TriTL has a relatively high accuracy on the tasks where the source domain is kitchen, but has a relatively low accuracy on other tasks. The algorithms TCA, mSLDA, and CD-PLSA have similar performance on all the tasks with an accuracy about seventy percent on average. Among the well-performed algorithms, HIDC and MTrick are based on feature reduction (feature clustering), while the others are based on feature encoding (SDA), feature alignment (SFA), and feature selection (SCL). Those strategies are currently the mainstreams of feature- based transfer learning. Table 5 presents the comparison results on Reuter-21578 (here we directly use the results of the baseline and CoCC from papers  and ). The baseline is a regularized least square regression model trained only on the labeled target domain instances . Fig. 6, which has the same structure of Fig. 5, visualizes the performance. For clarity, thirteen algorithms are divided into two parts that correspond to the two subﬁgures in Fig. 6. It can be observed that most algorithms are relatively well-performed for Orgs vs Places 25",
    ":ĺ$": "DAN DCORAL MRAN CDAN DANN JAN CAN Baseline Fig. 7. Comparison results on Ofﬁce-31. TABLE 5 Accuracy performance on the Reuters-21578 of three domains: Orgs, People, and Places. Model Orgs vs Places People vs Places Orgs vs People Average HIDC 0.7698 0.6945 0.8375 0.7673 TriTL 0.7338 0.5517 0.7505 0.6787 CD-PLSA 0.5624 0.5749 0.7826 0.6400 MTrick 0.7494 0.6457 0.7930 0.7294 CoCC 0.6704 0.8264 0.7644 0.7537 SFA 0.7468 0.6768 0.7906 0.7381 mSLDA 0.5645 0.6064 0.5289 0.5666 SDA 0.6603 0.5556 0.5992 0.6050 GFK 0.6220 0.5417 0.6446 0.6028 SCL 0.6794 0.5046 0.6694 0.6178 TCA 0.7368 0.6065 0.7562 0.6998 JDA 0.5694 0.6296 0.7424 0.6471 TrAdaBoost 0.7336 0.7052 0.7879 0.7422 Baseline 0.6683 0.5198 0.6696 0.6192 TABLE 6 Accuracy performance on Ofﬁce-31 of three domains: Amazon (A), Webcam (W), and DSLR (D). Model A → W D → W W → D A → D D → A W → A Average DAN 0.826 0.977 1.00 0.831 0.668 0.666 0.828 DCORAL 0.790 0.980 1.00 0.827 0.653 0.645 0.816 MRAN 0.914 0.969 0.998 0.864 0.683 0.709 0.856 CDAN 0.931 0.982 1.00 0.898 0.701 0.680 0.865 DANN 0.826 0.978 1.00 0.833 0.668 0.661 0.828 JAN 0.854 0.974 0.998 0.847 0.686 0.700 0.843 CAN 0.945 0.991 0.998 0.950 0.780 0.770 0.906 Baseline 0.616 0.954 0.990 0.638 0.511 0.498 0.701 and Orgs vs People, but poor for People vs Places. This phe- nomenon indicates that the discrepancy between People and Places may be relatively large. TrAdaBoost has a relatively good performance in this experiment because it uses the labels of the instances in the target domain to reduce the impact of the distribution difference. Besides, the algorithms HIDC, SFA, and MTrick have relatively consistent perfor- mance in the three tasks. These algorithms are also well- performed in the previous experiment on Amazon Reviews. In addition, the top two well-performed algorithms in terms of People vs Places are CoCC and TrAdaBoost. In the third experiment, seven deep-learning-based transfer learning models (i.e., DAN, DCORAL, MRAN, CDAN, DANN, JAN, and CAN) and the baseline (i.e., the Alexnet ,  pre-trained on ImageNet  and then directly trained on the target domain) are performed on the dataset Ofﬁce-31 (here we directly use the results of CDAN, JAN, CAN, and the baseline from the original papers , , , ). The ResNet-50  is used as the back- bone network for all these three models. The experimental results are provided in Table 6 and the average performance is visualized in Fig. 7. As shown in Fig. 7, all of these seven algorithms have excellent performance, especially on the tasks D → W and W → D, whose accuracy is very close to one hundred percent. This phenomenon reﬂects the superiority of the deep-learning based approaches, and is consistent with the fact that the difference between Webcam and DSLR is smaller than that between Webcam/DSLR and Amazon. Clearly, CAN outperforms the other six al- gorithms. In all the six tasks, the performance of DANN is similar to that of DAN, and is better than that of DCORAL, which indicates the effectiveness and the practicability of incorporating adversarial learning. It is worth mentioning that, in the above experiments, the performance of some algorithms is not ideal. One reason is that we use the default parameter settings provided in the algorithms’ original papers, which may not be suitable for the dataset we selected. For example, GFK was originally designed for object recognition, and we directly adopt it into text classiﬁcation in the ﬁrst experiment, which turns out to produce an unsatisfactory result (having about sixty- two percent accuracy on average). The above experimental results are just for reference. These results demonstrate that some algorithms may not be suitable for the datasets of certain domains. Therefore, it is important to choose the appropriate algorithms as the baselines in the process of re- search. Besides, in practical applications, it is also necessary to ﬁnd a suitable algorithm.",
    "C ONCLUSION AND F UTURE D IRECTION": "In this survey paper, we have summarized the mechanisms and the strategies of transfer learning from the perspectives of data and model. The survey gives the clear deﬁnitions about transfer learning and manages to use a uniﬁed sym- bol system to describe a large number of representative transfer learning approaches and related works. We have basically introduced the objectives and strategies in transfer learning based on data-based interpretation and model- based interpretation. Data-based interpretation introduces the objectives, the strategies, and some transfer learning 26 approaches from the data perspective. Similarly, model- based interpretation introduces the mechanisms and the strategies of transfer learning but from the model level. The applications of transfer learning have also been intro- duced. At last, experiments have been conducted to evaluate the performance of representative transfer learning models on two mainstream area, i.e., object recognition and text categorization. The comparisons of the models have also been given, which reﬂects that the selection of the transfer learning model is an important research topic as well as a complex issue in practical applications. Several directions are available for future research in the transfer learning area. First, transfer learning techniques can be further explored and applied to a wider range of applications. And new approaches are needed to solve the knowledge transfer problems in more complex scenarios. For example, in real-world scenarios, sometimes the user- relevant source-domain data comes from another company. In this case, how to transfer the knowledge contained in the source domain while protecting user privacy is an important issue. Second, how to measure the transferability across do- mains and avoid negative transfer is also an important issue. Although there have been some studies on negative transfer, negative transfer still needs further systematic analyses . Third, the interpretability of transfer learning also needs to be investigated further . Finally, theoretical studies can be further conducted to provide theoretical support for the effectiveness and applicability of transfer learning. As a popular and promising area in machine learning, transfer learning shows some advantages over traditional machine learning such as less data dependency and less label depen- dency. We hope our work can help readers have a better understanding of the research status and the research ideas.",
    "A CKNOWLEDGMENTS": "The research work is supported by the National Key Re- search and Development Program of China under Grant No. 2018YFB1004300, the National Natural Science Foundation of China under Grant No. U1836206, U1811461, 61773361, 61836013, and the Project of Youth Innovation Promotion Association CAS under Grant No. 2017146.",
    "R EFERENCES": "D.N. Perkins and G. Salomon, Transfer of Learning. Oxford, England: Pergamon, 1992.  S.J. Pan and Q. Yang, “A survey on transfer learning,” IEEE Trans. Knowl. Data Eng. , vol. 22, no. 10, pp. 1345–1359, Oct. 2010.  Z. Wang, Z. Dai, B. ´ Poczos, and J. Carbonell, “Characterizing and avoiding negative transfer,” in Proc. IEEE Conference on Computer Vision and Pattern Recognition , Long Beach, Jun. 2019, pp. 11293– 11302.  K. Weiss, T.M. Khoshgoftaar, and D. Wang, “A survey of transfer learning,” J. Big Data , vol. 3, no. 1, Dec. 2016.  J. Huang, A.J. Smola, A. Gretton, K.M. Borgwardt, and B. Sch¨olkopf, “Correcting sample selection bias by unlabeled data,” in Proc. 20th Annual Conference on Neural Information Processing Systems , Vancouver, Dec. 2006, pp. 601–608.  M. Sugiyama, T. Suzuki, S. Nakajima, H. Kashima, P. Bnau, and M. Kawanabe, “Direct importance estimation for covariate shift adaptation,” Ann. Inst. Stat. Math. , vol. 60, no. 4, pp. 699–746, Dec. 2008.  O. Day and T.M. Khoshgoftaar, “A survey on heterogeneous trans- fer learning,” J. Big Data , vol. 4, no. 1, Dec. 2017.  M.E. Taylor and P. Stone, “Transfer learning for reinforcement learning domains: A survey,” J. Mach. Learn. Res. , vol. 10, pp. 1633– 1685, Sep. 2009.  H.B. Ammar, E. Eaton, J.M. Luna, and P. Ruvolo, “Autonomous cross-domain knowledge transfer in lifelong policy gradient rein- forcement learning,” in Proc. 24th International Joint Conference on Artiﬁcial Intelligence , Buenos Aires, Jul. 2015, pp. 3345–3351.  P. Zhao and S.C.H. Hoi, “OTL: A framework of online transfer learning,” in Proc. 27th International Conference on Machine Learning , Haifa, Jun. 2010, pp. 1231–1238.  O. Chapelle, B. Schlkopf, and A. Zien, Semi-supervised Learning . Cambridge: MIT Press, 2010.  S. Sun, “A survey of multi-view machine learning,” Neural Com- put. Appl. , vol. 23, no. 7–8, pp. 2031–2038, Dec. 2013.  C. Xu, D. Tao, and C. Xu, “A survey on multi-view learning,” 2013, arXiv:1304.5634v1.  J. Zhao, X. Xie, X. Xu, and S. Sun, “Multi-view learning overview: Recent progress and new challenges,” Inf. Fusion , vol. 38, pp. 43–54, Nov. 2017.  D. Zhang, J. He, Y. Liu, L. Si, and R. Lawrence, “Multi-view transfer learning with a large margin approach,” in Proc. 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , San Diego, Aug. 2011, pp. 1208–1216.  P. Yang and W. Gao, “Multi-view discriminant transfer learning,” in Proc. 23rd International Joint Conference on Artiﬁcial Intelligence , Beijing, Aug. 2013, pp. 1848–1854.  K.D. Feuz and D.J. Cook, “Collegial activity learning between heterogeneous sensors,” Knowl. Inf. Syst. , vol. 53, pp. 337–364, Mar. 2017.  Y. Zhang and Q. Yang, “An overview of multi-task learning,” Natl. Sci. Rev. , vol. 5, no. 1, pp. 30–43, Jan. 2018.  W. Zhang, R. Li, T. Zeng, Q. Sun, S. Kumar, J. Ye, and S. Ji, “Deep model based transfer and multi-task learning for biological image analysis,” in Proc. 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , Sydney, Aug. 2015, pp. 1475– 1484.  A. Liu, N. Xu, W. Nie, Y. Su, and Y. Zhang, “Multi-domain and multi-task learning for human action recognition,” IEEE Trans. Image Process. , vol. 28, no. 2, pp. 853–867, Feb. 2019.  X. Peng, Z. Huang, X. Sun, and K. Saenko, “Domain agnostic learning with disentangled representations,” in Proc. 36th Interna- tional Conference on Machine Learning , Long Beach, Jun. 2019, pp. 5102–5112.  J. Lu, V. Behbood, P. Hao, H. Zuo, S. Xue, and G. Zhang, “Transfer learning using computational intelligence: A survey,” Knowledge- Based Syst. , vol. 80, pp. 14–23, May 2015.  C. Tan, F. Sun, T. Kong, W. Zhang, C. Yang, and C. Liu, “A Survey on deep transfer learning,” in Proc. 27th International Conference on Artiﬁcial Neural Networks , Rhodes, Oct. 2018, pp. 270–279.  M. Wang and W. Deng, “Deep visual domain adaptation: A survey,” Neurocomputing , vol. 312, pp. 135–153, Oct. 2018.  D. Cook, K.D. Feuz, and N.C. Krishnan, “Transfer learning for activity recognition: A survey,” Knowl. Inf. Syst. , vol. 36, no. 3, pp. 537–556, Sep. 2013.  L. Shao, F. Zhu, and X. Li, “Transfer learning for visual categoriza- tion: A survey,” IEEE Trans. Neural Netw. Learn. Syst. , vol. 26, no. 5, pp. 1019–1034, May 2015.  W. Pan, “A survey of transfer learning for collaborative recom- mendation with auxiliary data,” Neurocomputing , vol. 177, pp. 447– 453, Feb. 2016.  R. Liu, Y. Shi, C. Ji, and M. Jia, “A Survey of sentiment analysis based on transfer learning,” IEEE Access , vol. 7, pp. 85401–85412, Jun. 2019.  Q. Sun, R. Chattopadhyay, S. Panchanathan, and J. Ye, “A two- stage weighting framework for multi-source domain adaptation,” in Proc. 25th Annual Conference on Neural Information Processing Systems , Granada, Dec. 2011, pp. 505–513.  M. Belkin, P. Niyogi, and V. Sindhwani, “Manifold regularization: A geometric framework for learning from labeled and unlabeled examples,” J. Mach. Learn. Res. , vol. 7, pp. 2399–2434, Nov. 2006.  W. Dai, Q. Yang, G. Xue, and Y. Yu, “Boosting for transfer learning,” in Proc. 24th International Conference on Machine Learning , Corvalis, Jun. 2007, pp. 193–200.  Y. Freund and R.E. Schapire, “A decision-theoretic generalization of on-line learning and an application to boosting,” J. Comput. Syst. Sci. , vol. 55, no. 1, pp. 119–139, Aug. 1997. 27  Y. Yao and G. Doretto, “Boosting for transfer learning with multi- ple sources,” in Proc. IEEE Conference on Computer Vision and Pattern Recognition , San Francisco, Jun. 2010, pp. 1855–1862.  J. Jiang and C. Zhai, “Instance weighting for domain adaptation in NLP,” in Proc. 45th Annual Meeting of the Association of Computational Linguistics , Prague, Jun. 2007, pp. 264–271.  K.M. Borgwardt, A. Gretton, M.J. Rasch, H.-P. Kriegel, B. Scholkopf, and A.J. Smola, “Integrating structured biological data by kernel maximum mean discrepancy,” Bioinformatics , vol. 22, no. 14, pp. 49–57, Jul. 2006.  S.J. Pan, I.W. Tsang, J.T. Kwok, and Q. Yang, “Domain adaptation via transfer component analysis,” IEEE Trans. Neural Netw. , vol. 22, no. 2, pp. 199–210, Feb. 2011.  M. Ghifary, W.B. Kleijn, and M. Zhang, “Domain adaptive neural networks for object recognition,” in Proc. Paciﬁc Rim International Conference on Artiﬁcial Intelligence , Gold Coast, Dec. 2014, pp. 898– 904.  M. Long, J. Wang, G. Ding, J. Sun, and P.S. Yu, “Transfer feature learning with joint distribution adaptation,”in Proc. IEEE Interna- tional Conference on Computer Vision , Sydney, Dec. 2013, pp. 2200– 2207.  M. Long, J. Wang, G. Ding, S.J. Pan, and P.S. Yu, “Adaptation regularization: A general framework for transfer learning,” IEEE Trans. Knowl. Data Eng. , vol. 26, no. 5, pp. 1076-1089, May 2014.  S. Kullback and R.A. Leibler, “On information and sufﬁciency,” Ann. Math. Statist. , vol. 22, no. 1, pp. 79–86, 1951.  W. Dai, G.-R. Xue, Q. Yang, and Y. Yu, “Co-clustering based classiﬁcation for out-of-domain documents,” in Proc. 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , San Jose, Aug. 2007, pp. 210–219.  W. Dai, Q. Yang, G. Xue, and Y. Yu, “Self-taught clustering,” in Proc. 25th International Conference of Machine Learning , Helsinki, Jul. 2008, pp. 200–207.  J. Davis and P. Domingos, “Deep transfer via second-order Markov logic,” in Proc. 26th International Conference on Machine Learning , Montreal, Jun. 2009, pp. 217–224.  F. Zhuang, X. Cheng, P. Luo, S.J. Pan, and Q. He, “Supervised rep- resentation learning: Transfer learning with deep autoencoders,” in Proc. 24th International Joint Conference on Artiﬁcial Intelligence , Buenos Aires, Jul. 2015, pp. 4119–4125.  I. Dagan, L. Lee, and F. Pereira, “Similarity-based methods for word sense disambiguation,” in Proc. 35th Annual Meeting of the Association of Computational Linguistics and 8th Conference of the European Chapter of the Association for Computational Linguistics (ACL/EACL) , Madrid, Jul. 1997, pp. 56–63.  B. Chen, W. Lam, I. Tsang, and T. Wong, “Location and scatter matching for dataset shift in text mining,” in Proc. 10th IEEE International Conference on Data Mining , Sydney, Dec. 2010, pp. 773– 778.  S. Dey, S. Madikeri, and P. Motlicek, “Information theoretic clus- tering for unsupervised domain-adaptation,” in Proc. IEEE Interna- tional Conference on Acoustics, Speech and Signal Processing , Shanghai, Mar. 2016, pp. 5580–5584.  W.-H. Chen, P.-C. Cho, and Y.-L. Jiang, “Activity recognition using transfer learning,” Sens. Mater. , vol. 29, no. 7, pp. 897–904, Jul. 2017.  J. Giles, K.K. Ang, L.S. Mihaylova, and M. Arvaneh, “A subject- to-subject transfer learning framework based on Jensen-Shannon divergence for improving brain-computer interface,” in Proc. IEEE International Conference on Acoustics, Speech and Signal Processing , Brighton, May 2019, pp. 3087–3091.  L.M. Bregman, “The relaxation method of ﬁnding the common point of convex sets and its application to the solution of problems in convex programming,” USSR Comput. Math. Math. Phys. , vol. 7, no. 3, pp. 200–217, 1967.  S. Si, D. Tao, and B. Geng, “Bregman divergence-based regulariza- tion for transfer subspace learning,” IEEE Trans. Knowl. Data Eng. , vol. 22, no. 7, pp. 929–942, Jul. 2010.  H. Sun, S. Liu, S. Zhou, and H. Zou, “Unsupervised cross-view semantic transfer for remote sensing image classiﬁcation,” IEEE Geosci. Remote Sens. Lett. , vol. 13, no. 1, pp. 13–17, Jan. 2016.  H. Sun, S. Liu, and S. Zhou, “Discriminative subspace alignment for unsupervised visual domain adaptation,” Neural Process. Lett. , vol. 44, no. 3, pp. 779–793, Dec. 2016.  Q. Shi, Y. Zhang, X. Liu, and K. Zhao, “Regularised transfer learning for hyperspectral image classiﬁcation,” IET Comput. Vis. , vol. 13, no. 2, pp. 188–193, Feb. 2019.  A. Gretton, O. Bousquet, A.J. Smola, and B. Schlkopf, “Measuring statistical dependence with Hilbert-Schmidt norms,” in Proc. 18th International Conference on Algorithmic Learning Theory , Singapore, Oct. 2005, pp. 63–77.  H. Wang and Q. Yang, “Transfer learning by structural analogy,” in Proc. 25th AAAI Conference on Artiﬁcial Intelligence , San Francisco, Aug. 2011, pp. 513–518.  M. Xiao and Y. Guo, “Feature space independent semi-supervised domain adaptation via kernel matching,” IEEE Trans. Pattern Anal. Mach. Intell. , vol. 37, no. 1, pp. 54–66, Jan. 2015.  K. Yan, L. Kou, and D. Zhang, “Learning domain-invariant sub- space using domain features and independence maximization,” IEEE T. Cybern. , vol. 48, no. 1, pp. 288–299, Jan. 2018.  J. Shen, Y. Qu, W. Zhang, and Y. Yu, “Wasserstein distance guided representation learning for domain adaptation,” in Proc. 32nd AAAI Conference on Artiﬁcial Intelligence , New Orleans, Feb. 2018, pp. 4058–4065.  C.-Y. Lee, T. Batra, M.H. Baig, and D. Ulbricht, “Sliced Wasserstein discrepancy for unsupervised domain adaptation,” in Proc. IEEE Conference on Computer Vision and Pattern Recognition , Long Beach, Jun. 2019, pp. 10285–10295.  W. Zellinger, T. Grubinger, E. Lughofer, T. Natschlger, and S. Saminger-Platz, “Central moment discrepancy (CMD) for domain- invariant representation learning,” in Proc. 5th International Confer- ence on Learning Representations , Toulon, Apr. 2017, pp. 1–13.  A. Gretton, D. Sejdinovic, H. Strathmann, S. Balakrishnan, M. Pon- til, K. Fukumizu, and B.K. Sriperumbudur, “Optimal kernel choice for large-scale two-sample tests,” in Proc. 26th Annual Conference on Neural Information Processing Systems , Lake Tahoe, Dec. 2012, pp. 1205–1213.  H. Yan, Y. Ding, P. Li, Q. Wang, Y. Xu, and W. Zuo, “Mind the class weight bias: Weighted maximum mean discrepancy for unsu- pervised domain adaptation,” in Proc. IEEE Conference on Computer Vision and Pattern Recognition , Honolulu, Jul. 2017, pp. 2272–2281.  H. Daum´e III, “Frustratingly easy domain adaptation,” in Proc. 45th Annual Meeting of the Association for Computational Linguistics , Prague, Jun. 2007, pp. 256–263.  H. Daum´e III, A. Kumar, and A. Saha, “Co-regularization based semi-supervised domain adaptation,” in Proc. 24th Annual Confer- ence on Neural Information Processing Systems , Vancouver, Dec. 2010, pp. 478–486.  L. Duan, D. Xu, and I.W. Tsang, “Learning with augmented features for heterogeneous domain adaptation,” in Proc. 29th Inter- national Conference on Machine Learning , Edinburgh, Jun. 2012, pp. 1–8.  W. Li, L. Duan, D. Xu, and I.W. Tsang, “Learning with augmented features for supervised and semi-supervised heterogeneous do- main adaptation,” IEEE Trans. Pattern Anal. Mach. Intell. , vol. 36, no. 6, pp. 1134–1148, Jun. 2014.  K.I. Diamantaras and S.Y. Kung, Principal Component Neural Net- works . New York: Wiley, 1996.  B. Schlkopf, A. Smola, and K. Mller, “Nonlinear component anal- ysis as a kernel eigenvalue problem,” Neural Comput. , vol. 10, no. 5, pp. 1299–1319, Jul. 1998.  J. Wang, Y. Chen, S. Hao, W. Feng, and Z. Shen, “Balanced distribution adaptation for transfer learning,” in Proc. 17th IEEE International Conference on Data Mining , New Orleans, Nov. 2017, pp. 1129–1134.  A. Blum and T. Mitchell, “Combining labeled and unlabeled data with co-training,” in Proc. 11th Annual Conference on Computational Learning Theory , Madison, Jul. 1998, pp. 92–100.  M. Chen, K.Q. Weinberger, and J.C. Blitzer, “Co-training for domain adaptation,” in Proc. 25th Annual Conference on Neural Information Processing Systems , Granada, Dec. 2011, pp. 2456–2464.  Z.-H. Zhou and M. Li, “Tri-training: Exploiting unlabeled data using three classiﬁers,” IEEE Trans. Knowl. Data Eng. , vol. 17, no. 11, pp. 1529–1541, Nov. 2005.  K. Saito, Y. Ushiku, and T. Harada, “Asymmetric tri-training for unsupervised domain adaptation,” in Proc. 34th International Conference on Machine Learning , Sydney, Aug. 2017, pp. 2988–2997.  S.J. Pan, J.T. Kwok, and Q. Yang, “Transfer learning via dimen- sionality reduction,” in Proc. 23rd AAAI Conference on Artiﬁcial Intelligence , Chicago, Jul. 2008, pp. 677–682.  K.Q. Weinberger, F. Sha, and L.K. Saul, “Learning a kernel matrix for nonlinear dimensionality reduction,” in Proc. 21st International Conference on Machine Learning , Banff, Jul. 2004, pp. 106–113. 28  L. Vandenberghe and S. Boyd, “Semideﬁnite programming,” SIAM Rev. , vol. 38, no. 1, pp. 49–95, Mar. 1996.  S.J. Pan, I.W. Tsang, J.T. Kwok, and Q. Yang, “Domain adaptation via transfer component analysis,” in Proc. 21st International Joint Conference on Artiﬁcial Intelligence , Pasadena, Jul. 2009, pp. 1187– 1192.  C. Hou, Y.H. Tsai, Y. Yeh, and Y.F. Wang, “Unsupervised domain adaptation with label and structural consistency,” IEEE Trans. Image Process. , vol. 25, no. 12, pp. 5552–5562, Dec. 2016.  J. Tahmoresnezhad and S. Hashemi, “Visual domain adaptation via transfer feature learning,” Knowl. Inf. Syst. , vol. 50, no. 2, pp. 585–605, Feb. 2017.  J. Zhang, W. Li, and P. Ogunbona, “Joint geometrical and statistical alignment for visual domain adaptation,” in Proc. IEEE Conference on Computer Vision and Pattern Recognition , Honolulu, Jul. 2017, pp. 5150–5158.  B. Schlkopf, R. Herbrich, and A.J. Smola, “A generalized repre- senter theorem,” in Proc. International Conference on Computational Learning Theory , Amsterdam, Jul. 2001, pp. 416–426.  L. Duan, I.W. Tsang, and D. Xu, “Domain transfer multiple kernel learning,” IEEE Trans. Pattern Anal. Mach. Intell. , vol. 34, no. 3, pp. 465–479, Mar. 2012.  A. Rakotomamonjy, F.R. Bach, S. Canu, and Y. Grandvalet, “Sim- pleMKL,” J. Mach. Learn. Res. , vol. 9, pp. 2491-2521, Nov. 2008.  I.S. Dhillon, S. Mallela, and D.S. Modha, “Information-theoretic co-clustering,” in Proc. 9th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , Washington, Aug. 2003, pp. 89–98.  S. Deerwester, S.T. Dumais, G.W. Furnas, T.K. Landauer, and R. Harshman, “Indexing by latent semantic analysis,” J. Am. Soc. Inf. Sci. , vol. 41, pp. 391–407, Sep. 1990.  T. Hofmann, “Probabilistic latent semantic analysis,” in Proc. 15th Conference on Uncertainty in Artiﬁcial Intelligence , Stockholm, Jul. 1999, pp. 289–296.  J. Yoo and S. Choi, “Probabilistic matrix tri-factorization,” in Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing , Taipei, Apr. 2009, pp. 1553–1556.  A. Dempster, N. Laird, and D. Rubin, “Maximum likelihood from incomplete data via the EM algorithm,” J. R. Stat. Soc. - Ser. B , vol. 39, no. 1, pp. 1–38, 1977.  G.-R. Xue, W. Dai, Q. Yang, and Y. Yu, “Topic-bridged PLSA for cross-domain text classiﬁcation,” in Proc. 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , Singapore, Jul. 2008, pp. 627–634.  F. Zhuang, P. Luo, Z. Shen, Q. He, Y. Xiong, Z. Shi, and H. Xiong, “Collaborative Dual-PLSA: Mining distinction and commonality across multiple domains for text classiﬁcation,” in Proc. 19th ACM International Conference on Information and Knowledge Management , Toronto, Oct. 2010, pp. 359–368.  F. Zhuang, P. Luo, Z. Shen, Q. He, Y. Xiong, Z. Shi, and H. Xiong, “Mining distinction and commonality across multiple domains using generative model for text classiﬁcation,” IEEE Trans. Knowl. Data Eng. , vol. 24, no. 11, pp. 2025–2039, Nov. 2012.  F. Zhuang, P. Luo, P. Yin, Q. He, and Z. Shi, “Concept learn- ing for cross-domain text classiﬁcation: A general probabilistic framework,” in Proc. 23rd International Joint Conference on Artiﬁcial Intelligence , Beijing, Aug. 2013, pp. 1960–1966.  J. Blitzer, R. McDonald, and F. Pereira, “Domain adaptation with structural correspondence learning,” in Proc. Conference on Empirical Methods in Natural Language Processing , Sydney, Jul. 2006, pp. 120– 128.  R.K. Ando and T. Zhang, “A framework for learning predictive structures from multiple tasks and unlabeled data,” J. Mach. Learn. Res. , vol. 6, pp. 1817–1853, Dec. 2005.  X. Glorot, A. Bordes, and Y. Bengio, “Domain adaptation for large-scale sentiment classiﬁcation: A deep learning approach,” in Proc. 28th International Conference on Machine Learning , Bellevue, Jun. 2011, pp. 513–520.  P. Vincent, H. Larochelle, Y. Bengio, and P.-A. Manzagol, “Extract- ing and composing robust features with denoising autoencoders,” in Proc. 25th International Conference on Machine Learning , Helsinki, Jul. 2008, pp. 1096–1103.  M. Chen, Z. Xu, K. Weinberger, and F. Sha, “Marginalized denois- ing autoencoders for domain adaptation,” in Proc. 29th International Conference on Machine Learning , Edinburgh, Jun. 2012, pp. 767–774.  M. Chen, K.Q. Weinberger, Z. Xu, and F. Sha, “Marginalizing stacked linear denoising autoencoders,” J. Mach. Learn. Res. , vol. 16, no. 1, pp. 3849–3875, Jan. 2015.  B. Fernando, A. Habrard, M. Sebban, and T. Tuytelaars, “Unsu- pervised visual domain adaptation using subspace alignment,” in Proc. IEEE International Conference on Computer Vision , Sydney, Dec. 2013, pp. 2960–2967.  B. Sun and K. Saenko, “Subspace distribution alignment for unsupervised domain adaptation,” in Proc. British Machine Vision Conference , Swansea, Sep. 2015, pp. 24.1–24.10.  B. Gong, Y. Shi, F. Sha, and K. Grauman, “Geodesic ﬂow kernel for unsupervised domain adaptation,” in Proc. IEEE Conference on Computer Vision and Pattern Recognition , Providence, Jun. 2012, pp. 2066–2073.  R. Gopalan, Ruonan Li, and R. Chellappa, “Domain adaptation for object recognition: An unsupervised approach,” in Proc. IEEE International Conference on Computer Vision , Barcelona, Jun. 2011, pp. 999-1006.  M.I. Zelikin, Control Theory and Optimization I in Encyclopaedia of Mathematical Sciences, vol. 86, Berlin: Springer, 2000.  B. Sun, J. Feng, and K. Saenko, “Return of frustratingly easy domain adaptation,” in Proc. 30th AAAI Conference on Artiﬁcial Intelligence , Phoenix, Feb. 2016, pp. 2058–2065.  S.J. Pan, X. Ni, J.-T. Sun, Q. Yang, and Z. Chen, “Cross-domain sentiment classiﬁcation via spectral feature alignment,” in Proc. 19th International Conference on World Wide Web , Raleigh, Apr. 2010, pp. 751–760.  J. Blitzer, M. Dredze, and F. Pereira, “Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classi- ﬁcation,” in Proc. 45th Annual Meeting of the Association of Computa- tional Linguistics , Prague, Jun. 2007, pp. 440–447.  F.R.K. Chung, Spectral Graph Theory . Providence: American Math- ematical Society, 1997.  A.Y. Ng, M.I. Jordan, and Y. Weiss, “On spectral clustering: Analysis and an algorithm,” in Proc. 15th Annual Conference on Neural Information Processing Systems , Vancouver, Dec. 2001, pp. 849- 856.  X. Ling, W. Dai, G.-R. Xue, Q. Yang, and Y. Yu, “Spectral domain- transfer learning,” in Proc. 14th ACM SIGKDD International Confer- ence on Knowledge Discovery and Data Mining , Las Vegas, Aug. 2008, pp. 488–496.  S.D. Kamvar, D. Klein, and C.D. Manning, “Spectral learning,” in Proc. 18th International Joint Conference on Artiﬁcial Intelligence , Acapulco, Aug. 2003, pp. 561–566.  J. Shi and J. Malik, “Normalized cuts and image segmentation,” IEEE Trans. Pattern Anal. Mach. Intell. , vol .22, no. 8, pp. 888–905, Aug. 2000.  L. Duan, I.W. Tsang, D. Xu, and T.-S. Chua, “Domain adaptation from multiple sources via auxiliary classiﬁers,” in Proc. 26th In- ternational Conference on Machine Learning , Montreal, Jun. 2009, pp. 289–296.  L. Duan, D. Xu, and I.W. Tsang, “Domain adaptation from multiple sources: A domain-dependent regularization approach,” IEEE Trans. Neural Netw. Learn. Syst. , vol. 23, no. 3, pp. 504–518, Mar. 2012.  P. Luo, F. Zhuang, H. Xiong, Y. Xiong, and Q. He, “Transfer learn- ing from multiple source domains via consensus regularization,” in Proc. 17th ACM Conference on Information and Knowledge Management , Napa Valley, Oct. 2008, pp. 103–112.  F. Zhuang, P. Luo, H. Xiong, Y. Xiong, Q. He, and Z. Shi, “Cross- domain learning from multiple sources: A consensus regularization perspective,” IEEE Trans. Knowl. Data Eng. , vol. 22, no. 12, pp. 1664– 1678, Dec. 2010.  T. Evgeniou, C.A. Micchelli, and M. Pontil, “Learning multiple tasks with kernel methods,” J. Mach. Learn. Res. , vol. 6, pp. 615-637, Apr. 2005.  T. Kato, H. Kashima, M. Sugiyama, and K. Asai, “Multi-task learning via conic programming,” in Proc. 21st Annual Conference on Neural Information Processing Systems , Vancouver, Dec. 2007, pp. 737–744.  A.J. Smola and B. Schlkopf, “A tutorial on support vector regres- sion,” Stat. Comput. , vol. 14, no. 3, pp. 199–222, Aug. 2004.  J. Weston, R. Collobert, F. Sinz, L. Bottou, and V. Vapnik, “Infer- ence with the universum,” in Proc. 23rd International Conference on Machine Learning , Pittsburgh, Jun. 2006, pp. 1009–1016.  X. Yu and Y. Aloimonos, “Attribute-based transfer learning for object categorization with zero/one training example,” in Proc. 29 European Conference on Computer Vision , Heraklion, Sep. 2010, pp. 127–140.  F. Zhuang, P. Luo, H. Xiong, Q. He, Y. Xiong, and Z. Shi, “Ex- ploiting associations between word clusters and document classes for cross-domain text categorization,” Stat. Anal. Data Min. , vol. 4, no. 1, pp. 100–114, Feb. 2011.  F. Zhuang, P. Luo, C. Du, Q. He, Z. Shi, and H. Xiong, “Triplex transfer learning: Exploiting both shared and distinct concepts for text classiﬁcation,” IEEE T. Cybern. , vol. 44, no. 7, pp. 1191–1203, Jul. 2014.  M. Long, J. Wang, G. Ding, W. Cheng, X. Zhang, and W. Wang, “Dual transfer learning,” in Proc. 12th SIAM International Conference on Data Mining , Anaheim, Apr. 2012, pp. 540–551.  H. Wang, F. Nie, H. Huang, and C. Ding, “Dyadic transfer learn- ing for cross-domain image classiﬁcation,” in Proc. International Conference on Computer Vision , Barcelona, Nov. 2011, pp. 551–556.  D. Wang, C. Lu, J. Wu, H. Liu, W. Zhang, F. Zhuang, and H. Zhang, “Softly associative transfer learning for cross- domain classiﬁcation,” IEEE T. Cybern. , to be published. doi: 10.1109/TCYB.2019.2891577.  Q. Do, W. Liu, J. Fan, and D. Tao, “Unveiling hidden implicit similarities for cross-domain recommendation,” IEEE Trans. Knowl. Data Eng. , to be published. doi: 10.1109/TKDE.2019.2923904.  T. Tommasi and B. Caputo, “The more you know, the less you learn: from knowledge transfer to one-shot learning of object categories” in Proc. British Machine Vision Conference , London, Sep. 2009, pp. 80.1–80.11.  G.C. Cawley, “Leave-one-out cross-validation based model selec- tion criteria for weighted LS-SVMs,” in Proc. IEEE International Joint Conference on Neural Network , Vancouver, Jul. 2006, pp. 1661–1668.  T. Tommasi, F. Orabona, and B. Caputo, “Safety in numbers: Learning categories from few examples with multi model knowl- edge transfer,” in Proc. IEEE Conference on Computer Vision and Pattern Recognition , San Francisco, Jun. 2010, pp. 3081–3088.  C.-K. Lin, Y.-Y. Lee, C.-H. Yu, and H.-H. Chen, “Exploring ensemble of models in taxonomy-based cross-domain sentiment classiﬁcation,” in Proc. 23rd ACM International on Conference on Information and Knowledge Management , Shanghai, Nov. 2014, pp. 1279–1288.  J. Gao, W. Fan, J. Jiang, and J. Han, “Knowledge transfer via mul- tiple model local structure mapping,” in Proc. 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , Las Vegas, Aug. 2008, pp. 283–291.  F. Zhuang, P. Luo, S.J. Pan, H. Xiong, and Q. He. “Ensemble of anchor adapters for transfer learning,” in Proc. 25th ACM In- ternational on Conference on Information and Knowledge Management , Indianapolis, Oct. 2016, pp. 2335–2340.  F. Zhuang, X. Cheng, P. Luo, S.J. Pan, and Q. He, “Supervised representation learning with double encoding-layer autoencoder for transfer learning,” ACM Trans. Intell. Syst. Technol. , vol. 9, no. 2, pp. 1–17, Jan. 2018.  M. Ghifary, W.B. Kleijn, and M. Zhang, “Domain adaptive neural networks for object recognition,” in Proc. 13th Paciﬁc Rim Interna- tional Conference on Artiﬁcial Intelligence , Gold Coast, Dec. 2014, pp. 898–904.  E. Tzeng, J. Hoffman, N. Zhang, K. Saenko, and T. Darrell, “Deep domain confusion: Maximizing for domain invariance,” 2014, arXiv:1412.3474v1.  M. Long, Y. Cao, J. Wang, and M.I. Jordan, “Learning transferable features with deep adaptation networks,” in Proc. 32nd International Conference on Machine Learning , Lille, Jul. 2015, pp. 97–105.  A. Krizhevsky, I. Sutskever, and G.E. Hinton, “Imagenet classi- ﬁcation with deep convolutional neural networks,” in Proc. 26th Annual Conference on Neural Information Processing Systems , Lake Tahoe, Dec. 2012, pp. 1097–1105.  I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde- Farley, S. Ozair, A. Courville, and Y. Bengio, “Generative adver- sarial nets,” in Proc. 28th Annual Conference on Neural Information Processing Systems , Montreal, Dec. 2014, pp. 2672–2680.  J. Yosinski, J. Clune, Y. Bengio, and H. Lipson, “How transferable are features in deep neural networks?” in Proc. 28th Annual Confer- ence on Neural Information Processing Systems , Montreal, Dec. 2014, pp. 3320–3328.  M. Long, Y. Cao, Z. Cao, J. Wang, and M.I. Jordan, “Trans- ferable representation learning with deep adaptation networks,” IEEE Trans. Pattern Anal. Mach. Intell. , to be published. doi: 10.1109/TPAMI.2018.2868685.  Y. Grandvalet and Y. Bengio, “Semi-supervised learning by en- tropy minimization,” in Proc. 18th Annual Conference on Neural Information Processing Systems , Vancouver, Dec. 2004, pp. 529–536.  C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich, “Going deeper with convolutions,” in Proc. IEEE Conference on Computer Vision and Pattern Recognition , Boston, Jun. 2015, pp. 1–9.  K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” in Proc. IEEE Conference on Computer Vision and Pattern Recognition , Las Vegas, Jun. 2016, pp. 770–778.  K.P. Chwialkowski, A. Ramdas, D. Sejdinovic, and A. Gretton, “Fast two-sample testing with analytic representations of probabil- ity measures,” in Proc. 29th Annual Conference on Neural Information Processing Systems , Montreal, Dec. 2015, pp. 1981–1989.  M. Long, H. Zhu, J. Wang, and M.I. Jordan, “Unsupervised do- main adaptation with residual transfer networks,” in Proc. 30th An- nual Conference on Neural Information Processing Systems , Barcelona, Dec. 2016, pp. 136–144.  M. Long, H. Zhu, J. Wang, and M.I. Jordan, “Deep transfer learning with joint adaptation networks,” in Proc. 34th International Conference on Machine Learning , Sydney, Aug. 2017, pp. 2208–2217.  B. Sun and K. Saenko, “Deep CORAL: Correlation alignment for deep domain adaptation,” in Proc. European Conference on Computer Vision Workshops , Amsterdam, Oct. 2016, pp. 443–450.  C. Chen, Z. Chen, B. Jiang, and X. Jin, “Joint domain alignment and discriminative feature learning for unsupervised deep domain adaptation,” in Proc. 33rd AAAI Conference on Artiﬁcial Intelligence , Honolulu, Jan. 2019, pp. 3296–3303.  Y. Pan, T. Yao, Y. Li, Y. Wang, C.-W. Ngo, and T. Mei, “Trans- ferrable prototypical networks for unsupervised domain adap- tation,” in Proc. IEEE Conference on Computer Vision and Pattern Recognition , Long Beach, Jun. 2019, pp. 2239–2247.  G. Kang, L. Jiang, Y. Yang, and A.G. Hauptmann, “Contrastive adaptation network for unsupervised domain adaptation,” in Proc. IEEE Conference on Computer Vision and Pattern Recognition , Long Beach, Jun. 2019, pp. 4893–4902.  Y. Zhu, F. Zhuang, J. Wang, J. Chen, Z. Shi, W. Wu, and Q. He, “Multi-representation adaptation network for cross-domain image classiﬁcation,” Neural Netw. , vol. 119. pp. 214–221, Nov. 2019.  Y. Zhu, F. Zhuang, and D. Wang, “Aligning domain-speciﬁc dis- tribution and classiﬁer for cross-domain classiﬁcation from multiple sources,” in Proc. 33rd AAAI Conference on Artiﬁcial Intelligence , Honolulu, Jan. 2019, pp. 5989–5996.  Y. Ganin and V. Lempitsky, “Unsupervised domain adaptation by backpropagation,” in Proc. 32nd International Conference on Machine Learning , Lille, Jul. 2015, pp. 1180–1189.  Y. Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle, F.Laviolette, M. Marchand, and V. Lempitsky, “Domain-adversarial training of neural networks,” J. Mach. Learn. Res. , vol. 17, pp. 1–35, Apr. 2016.  E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell, “Adversarial discriminative domain adaptation,” in Proc. IEEE Conference on Computer Vision and Pattern Recognition , Honolulu, Jul. 2017, pp. 2962–2971.  J. Hoffman, E. Tzeng, T. Park, J.-Y. Zhu, P. Isola, K. Saenko, A.A. Efros, and T. Darrell, “CyCADA: Cycle-consistent adversarial domain adaptation,” in Proc. 35th International Conference on Machine Learning , Stockholm, Jul. 2018, pp. 1994–2003.  M. Long, Z. Cao, J. Wang, and M.I. Jordan, “Conditional adver- sarial domain adaptation,” in Proc. 32nd Annual Conference on Neural Information Processing Systems , Montreal, Dec. 2018, pp. 1640–1650.  Y. Zhang, H. Tang, K. Jia, and M. Tan, “Domain-symmetric net- works for adversarial domain adaptation,” in Proc. IEEE Conference on Computer Vision and Pattern Recognition , Long Beach, Jun. 2019, pp. 5031–5040.  H. Zhao, S. Zhang, G. Wu, J.M.F. Moura, J.P. Costeira, and G.J. Gordon, “Adversarial multiple source domain adaptation,” in Proc. 32nd Annual Conference on Neural Information Processing Systems , Montreal, Dec. 2018, pp. 8559–8570.  C. Yu, J. Wang, Y. Chen, and M. Huang, “Transfer learning with dynamic adversarial adaptation network,” in Proc. 19th IEEE International Conference on Data Mining , Beijing, Nov. 2019, pp. 1–9.  J. Zhang, Z. Ding, W. Li, and P. Ogunbona, “Importance weighted adversarial nets for partial domain adaptation,” in Proc. IEEE Conference on Computer Vision and Pattern Recognition , Salt Lake City, Jun. 2018, pp. 8156–8163. 30  Z. Cao, M. Long, J. Wang, and M.I. Jordan, “Partial transfer learn- ing with selective adversarial networks,” in Proc. IEEE Conference on Computer Vision and Pattern Recognition , Salt Lake City, Jun. 2018, pp. 2724–2732.  B. Wang, M. Qiu, X. Wang, Y. Li, Y. Gong, X. Zeng, J. Huang, B. Zheng, D. Cai, and J. Zhou, “A minimax game for instance based selective transfer learning,” in Proc. 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , Anchorage, Aug. 2019, pp. 34–43.  X. Chen, S. Wang, M. Long, and J. Wang, “Transferability vs. discriminability: Batch spectral penalization for adversarial domain adaptation,” in Proc. 36th International Conference on Machine Learn- ing , Long Beach, Jun. 2019, pp. 1081–1090.  J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “ImageNet: A large-scale hierarchical image database,” in Proc. IEEE Conference on Computer Vision and Pattern Recognition , Miami, Jun. 2009, pp. 248–255.  M. Maqsood, F. Nazir, U. Khan, F. Aadil, H. Jamal, I. Mehmood, and O. Song, “Transfer learning assisted classiﬁcation and detection of Alzheimer’s disease stages using 3D MRI scans,” Sensors , vol. 19, no. 11, pp. 1–19, Jun. 2019.  D.S. Marcus, A.F. Fotenos, J.G. Csernansky, J.C. Morris, and R.L. Buckner, “Open access series of imaging studies: Longitudinal MRI data in nondemented and demented older adults,” J. Cogn. Neurosci. , vol. 22, no. 12, pp. 2677–2684, Dec. 2010.  H.-C. Shin, H.R. Roth, M. Gao, L. Lu, Z. Xu, I. Nogues, J. Yao, D. Mollura, and R.M. Summers, “Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer Learning,” IEEE Trans. Med. Imaging , vol. 35, no. 5, pp. 1285–1298, May 2016.  M. Byra, M. Wu, X. Zhang, H. Jang, Y.-J. Ma, E.Y. Chang, S. Shah, and Jiang Du, “Knee menisci segmentation and relaxometry of 3D ultrashort echo time cones MR imaging using attention UNet with transfer learning,” Magn. Reson. Med. , Sep. 2019, doi: 10.1002/mrm.27969.  X. Tang, B. Du, J. Huang, Z. Wang, and L. Zhang, “On combining active and transfer learning for medical data classiﬁcation,” IET Comput. Vis. , vol. 13, no. 2, pp. 194–205, Feb. 2019.  M. Zeng, M. Li, Z. Fei, Y. Yu, Y. Pan, and J. Wang, “Automatic ICD-9 coding via deep transfer learning,” Neurocomputing , vol. 324, pp. 43–50, Jan. 2019.  G. Schweikert, G. Ratsch, C. Widmer, and B. Scholkopf, “An empirical analysis of domain adaptation algorithms for genomic sequence analysis,” in Proc. 22nd Annual Conference on Neural Infor- mation Processing Systems , Vancouver, Dec. 2008, pp. 1433–1440.  R. Petegrosso, S. Park, T.H. Hwang, and R. Kuang, “Transfer learning across ontologies for phenome-genome association predic- tion,” Bioinformatics , vol. 33, no. 4, pp. 529–536, Feb. 2017.  T. Hwang and R. Kuang, “A heterogeneous label propagation al- gorithm for disease gene discovery,” in Proc. 10th SIAM International Conference on Data Mining , Columbus, Apr. 2010, pp. 583–594.  Q. Xu, E.W. Xiang, and Q. Yang, “Protein-protein interaction prediction via collective matrix factorization,” in Proc. IEEE Interna- tional Conference on Bioinformatics and Biomedicine , Hong Kong, Dec. 2010, pp. 62–67.  A.P. Singh and G.J. Gordon, “Relational learning via collective matrix factorization,” in Proc. 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , Las Vegas, Aug. 2008, pp. 650–658.  S. Di, H. Zhang, C. Li, X. Mei, D. Prokhorov, and H. Ling, “Cross- domain trafﬁc scene understanding: A dense correspondence-based transfer learning approach,” IEEE Trans. Intell. Transp. Syst. , vol. 19, no. 3, pp. 745–757, Mar. 2018.  H. Abdi, “Partial least squares regression and projection on latent structure regression (PLS Regression),” Wiley Interdiscip. Rev.- Comput. Statist. , vol. 2, no. 1, pp. 97106, Jan. 2010.  S.D. Pietra, V.D. Pietra, and J. Lafferty, “Inducing features of random ﬁelds,” IEEE Trans. Pattern Anal. Mach. Intell. , vol. 19, no. 4, pp. 380–393, Apr. 1997.  C. Liu, J. Yuen, and A. Torralba, “Nonparametric scene parsing via label transfer,” IEEE Trans. Pattern Anal. Mach. Intell. , vol. 33, no. 12, pp. 2368–2382, Dec. 2011.  C. Lu, F. Hu, D. Cao, J. Gong, Y. Xing, and Z. Li, “Transfer learning for driver model adaptation in lane-changing scenarios using manifold alignment,” IEEE Trans. Intell. Transp. Syst. , to be published. doi: 10.1109/TITS.2019.2925510.  D.J. Berndt and J. Clifford, “Using dynamic time warping to ﬁnd patterns in time series,” in Proc. Knowledge Discovery in Databases Workshop , Seattle, Jul. 1994, pp. 359–370.  N. Makondo, M. Hiratsuka, B. Rosman, and O. Hasegawa, “A non-linear manifold alignment approach to robot learning from demonstrations,” J. Robot. Mechatron. , vol. 30, no. 2, pp. 265–281, Apr. 2018.  P. Angkititrakul, C. Miyajima, and K. Takeda, “Modeling and adaptation of stochastic driver-behavior model with application to car following,” in Proc. IEEE Intelligent Vehicles Symposium (IV) , Baden-Baden, Jun. 2011, pp. 814–819.  Y. Liu, P. Lasang, S. Pranata, S. Shen, and W. Zhang, “Driver pose estimation using recurrent lightweight network and virtual data augmented transfer learning,” IEEE Trans. Intell. Transp. Syst. , vol. 20, no. 10, pp. 3818–3831, Oct. 2019.  J. Wang, H. Zheng, Y. Huang, and X. Ding, “Vehicle type recog- nition in surveillance images from labeled web-nature data using deep transfer learning,” IEEE Trans. Intell. Transp. Syst. , vol. 19, no. 9, pp. 2913–2922, Sep. 2018.  K. Gopalakrishnan, S.K. Khaitan, A. Choudhary, and A. Agrawal, “Deep convolutional neural networks with transfer learning for computer vision-based data-driven pavement distress detection,” Constr. Build. Mater. , vol. 157, pp. 322–330, Dec. 2017.  S. Bansod and A. Nandedkar, “Transfer learning for video anomaly detection,” J. Intell. Fuzzy Syst. , vol. 36, no. 3, pp. 1967– 1975, Mar. 2019.  G. Rosario, T. Sonderman, and X. Zhu, “Deep transfer learning for trafﬁc sign recognition,” in Proc. IEEE International Conference on Information Reuse and Integration , Salt Lake City, Jul. 2018, pp. 178–185.  W. Pan, E.W. Xiang, and Q. Yang, “Transfer learning in collabora- tive ﬁltering with uncertain ratings,” in Proc. 26th AAAI Conference on Artiﬁcial Intelligence , Toronto, Jul. 2012, pp. 662–668.  G. Hu, Y. Zhang, and Q. Yang, “Transfer meets hybrid: A synthetic approach for cross-domain collaborative ﬁltering with text,” in Proc. 28th International Conference on World Wide Web , San Francisco, May 2019, pp. 2822–2829.  W. Pan, E.W. Xiang, N.N. Liu, and Q. Yang, “Transfer learning in collaborative ﬁltering for sparsity reduction,” in Proc. 24th AAAI Conference on Artiﬁcial Intelligence , Atlanta, Jul. 2010, pp. 230–235.  W. Pan and Q. Yang, “Transfer learning in heterogeneous col- laborative ﬁltering domains,” Artif. Intell. , vol. 197, pp. 39–55, Apr. 2013.  F. Zhuang, Y. Zhou, F. Zhang, X. Ao, X. Xie, and Q. He, “Sequen- tial transfer learning: Cross-domain novelty seeking trait mining for recommendation,” in Proc. 26th International Conference on World Wide Web Companion , Perth, Apr. 2017, pp. 881–882.  J. Zheng, F. Zhuang, and C. Shi, “Local ensemble across multiple sources for collaborative ﬁltering,” in Proc. 26th ACM International on Conference on Information and Knowledge Management , Singapore, Nov. 2017, pp. 2431–2434.  F. Zhuang, J. Zheng, J. Chen, X. Zhang, C. Shi, and Q. He, “Transfer collaborative ﬁltering from multiple sources via consen- sus regularization,” Neural Netw. , vol. 108, pp. 287–295, Dec. 2018.  J. He, R. Liu, F. Zhuang, F. Lin, C. Niu, and Q. He, “A general cross-domain recommendation framework via Bayesian neural net- work,” in Proc. 18th IEEE International Conference on Data Mining , Singapore, Nov. 2018, pp. 1001–1006.  F. Zhu, Y. Wang, C. Chen, G. Liu, M.A. Orgun, and J. Wu, “A deep framework for cross-domain and cross-system recommendations,” in Proc. 27th International Joint Conference on Artiﬁcial Intelligence , Stockholm, Jul. 2018, pp. 3711–3717.  F. Yuan, L. Yao, and B. Benatallah, “DARec: Deep domain adap- tation for cross-domain recommendation via transferring rating patterns,” in Proc. 29th International Joint Conference on Artiﬁcial Intelligence , Macao, Aug. 2019, pp. 4227–4233.  E. Bastug, M. Bennis, and M. Debbah, “A transfer learning approach for cache-enabled wireless networks,” in Proc. 13th Inter- national Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks , Mumbai, May 2015, pp. 161–166.  R. Li, Z. Zhao, X. Chen, J. Palicot, and H. Zhang, “TACT: A transfer actor-critic learning framework for energy saving in cel- lular radio access networks,” IEEE Trans. Wirel. Commun. , vol. 13, no. 4, pp. 2000–2011, Apr. 2014.  Q. Zhao and D. Grace, “Transfer learning for QoS aware topology management in energy efﬁcient 5G cognitive radio networks,” in 31 Proc. 1st International Conference on 5G for Ubiquitous Connectivity , Akaslompolo, Nov. 2014, pp. 152–157.  B. Guo, J. Li, V.W. Zheng, Z. Wang, and Z. Yu, “Citytransfer: Transferring inter- and intra-city knowledge for chain store site recommendation based on multi-source urban data,” in Proc. ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies , Jan. 2018, pp. 1–23.  Y. Wei, Y. Zheng, and Q. Yang, “Transfer knowledge between cities,” in Proc. 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , San Francisco, Aug. 2016, pp. 1905–1914.  U. Cote-Allard, C.L. Fall, A. Drouin, A. Campeau-Lecours, C. Gosselin, K. Glette, F. Laviolette, and B. Gosselin, “Deep learn- ing for electromyographic hand gesture signal classiﬁcation using transfer learning,” IEEE Trans. Neural Syst. Rehabil. Eng. , vol. 27, no. 4, pp. 760–771, Apr. 2019.  C. Ren, D. Dai, K. Huang, and Z. Lai, “Transfer learning of structured representation for face recognition,” IEEE Trans. Image Process. , vol. 23, no. 12, pp. 5440–5454, Dec. 2014.  J. Wang, Y. Chen, L. Hu, X. Peng, and P.S. Yu, “Stratiﬁed trans- fer learning for cross-domain activity recognition,” in Proc. IEEE International Conference on Pervasive Computing and Communications , Athens, Mar. 2018, pp. 1–10.  J. Deng, Z. Zhang, E. Marchi, and B. Schuller, “Sparse autoencoder-based feature transfer learning for speech emotion recognition,” in Proc. Humaine Association Conference on Affective Computing and Intelligent Interaction , Geneva, Sep. 2013, pp. 511– 516.  D. Xi, F. Zhuang, G. Zhou, X. Cheng, F. Lin, and Q. He, “Domain adaptation with category attention network for deep sentiment analysis,” in Proc. The Web Conference , Taipei, Apr. 2020, pp. 3133– 3139.  Y. Zhu, D. Xi, B. Song, F. Zhuang, S. Chen, X. Gu, and Q. He, “Modeling users’ behavior sequences with hierarchical explainable network for cross-domain fraud detection,” in Proc. The Web Con- ference , Taipei, Apr. 2020, pp. 928–938.  J. Tang, T. Lou, J. Kleinberg, and S. Wu, “Transfer learning to infer social ties across heterogeneous networks,” ACM Trans. Inf. Syst. , vol. 34, no. 2, pp. 1–43, Apr. 2016.  L. Zhang, L. Zhang, D. Tao, and X. Huang, “Sparse transfer man- ifold embedding for hyperspectral target detection,” IEEE Trans. Geosci. Remote Sensing , vol. 52, no. 2, pp. 1030–1043, Feb. 2014.  F. Zhuang, K. Duan, T. Guo, Y. Zhu, D. Xi, Z. Qi, and Q. He, “Transfer learning toolkit: Primers and benchmarks,” 2019, arXiv:1911.08967v1.  K. Saenko, B. Kulis, M. Fritz, and T. Darrell, “Adapting visual category models to new domains,” in Proc. 11th European Conference on Computer Vision , Heraklion, Sep. 2010, pp. 213–226.  Z.C. Lipton, “The mythos of model interpretability,” ACM Que. , vol. 16, no. 3, May 2018, pp. 1–27."
  },
  "tables": [
    {
      "page": 24,
      "table_index": 0,
      "content": [
        [
          "Orgs vs Places\nOrgs vs People\nFig.6.ComparisonresultsonReuters-21578.",
          "Or\nHIDC\nGFK\nCD-PLSA\nMTrick\nCoCC\nSFA\nmSLDA\nPeople vs Places Orgs vs People\nTABLE4",
          "gs vs Places\nSDA\nTriTL\nSCL\nTCA\nJDA\nTrAdaBoost\nBaseline\nPeople vs Places"
        ]
      ]
    }
  ],
  "images": [],
  "status": "completed"
}